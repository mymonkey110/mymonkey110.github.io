<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[架构师应该是一种角色，而不是一个职位]]></title>
    <url>%2F2017%2F06%2F03%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E5%BA%94%E8%AF%A5%E6%98%AF%E4%B8%80%E7%A7%8D%E8%A7%92%E8%89%B2%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E8%81%8C%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[昨天看到一篇关于“架构师”的文章，读后非常有感触。我个人比较认同作者的大部分观点，故决定将原文进行翻译，和国内的开发者一起分享。原文地址：“Architect” Should Be a Role, Not a Position”。 当一个资深的开发者变得更加资深时会发生什么事情？他们经常会被提拔做去“架构师”。有时一个架构师也不一定非要是开发者，如果他们能看到更大的蓝图。最终，总有一个人挂着“架构师”的头衔：他对要开发的系统和正在开发的系统做出架构上决策。在一些更大的公司，还有“架构师议会”，每个团队指定的架构师们聚在一起决定着一些明智的事情。 但我认为专门设立“架构师”的职位是一个糟糕的想法。架构师应该是建筑行业的一个职位，这是说的过去的，因为你不能在项目中期改变和调整架构。但是软件架构是十分灵活的，不应该预先就严格地定义好。而且开发工作和架构设计是如此的紧密关联，所以说某个人决定“什么要做”和“什么不要做”是不科学的。这会带来各种各样的问题，主要是因为架构师经常无法全面的考虑到具体的实现是怎么样。如果一个架构师长时间不写代码，他们更加倾向于忽略“实现细节”，转而仅仅考虑抽象设计。然而，抽象总是伴随着遗漏，只考虑抽象而不考虑特定的实现这样的解决方案很少行得通。 我的第一个论点就是：在不知道详细地编写所有代码地情况下，你无法在成为一个优秀的架构师。大多数情况下都不是“简单地编码”。如果你已经成为架构师多年，同时也多年没有写过代码了，那几乎可以肯定你不是一个优秀的架构师。 当然，你可能是一个优秀的架构师。或许在你所在的那个特别的公司里，有人坐在象牙塔中，指挥着码农去整合这个实现那个，这可能说的过去。但即使是这种情况，也有更好的方法。 架构师应该是一种角色。每个资深的团队成员都可以也应该扮演架构师的角色，不用每个团队指定一个人来当。实际上，最好有多个人来扮演架构师。在会议中讨论架构设计和讨论功能设计类似，如果你是那个要实现所有事情的人，那么你需要带着明确的想法去参会。任何的过度设计（大部分架构师经常会犯这个错误）需要在你面前证明是合理的——“我是否愿意去写这些模板代码，或者是否有一种更简单优雅的实现方式”。 职位可以使“软件工程师”，但角色可以是“敏捷大师”、”架构师”、”持续集成官”，等等。如果公司需要一个“架构师议会”去决定系统间更宏观的整合，开发者可以提名某个人去参与这些会议，这个人有可能是对这些系统最了解的人。 我知道现在架构师在想什么——有一些更加高层次的关注点开发要么不太能理解要么不应该为此被打扰。大错特错！如果你的开发不理解更高层次的架构规划，那么迟早你会遇到问题的。是的，因为他们要让代码适应你正在规划的更大的蓝图，他们需要被打扰。 还有一方面于团队成员的态度和动态的交流。如果某个不是特别优秀或者受人尊敬的开发被提升为“架构师”，那么可能破坏团队的和谐。另一方面，某些人被提升为“架构师”以后可能会过于自信，以至于他们会想当然的去做出设计决定，而不管那些反对他们的好的争论点。 所以，理想的情况（这是我的第二个论点）是取消架构师的职位。确保你团队中资深的成员能够参与架构设计和决策，那样他们可能会更有干劲，他们也会对他们开发的成果有一个更加清晰的规划。最为重要的是，架构决策不能脱离日常的“现实”的开发环境，否则它们会不必要的复杂化。 很久没有翻译了，有很多句子拿捏不准。如果有误翻的地方，还望指正，谢谢！]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>软件开发理论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[访问控制：为你的云上业务再加一把锁]]></title>
    <url>%2F2017%2F06%2F01%2F%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%EF%BC%9A%E4%B8%BA%E4%BD%A0%E7%9A%84%E4%BA%91%E4%B8%8A%E4%B8%9A%E5%8A%A1%E5%86%8D%E5%8A%A0%E4%B8%80%E6%8A%8A%E9%94%81%2F</url>
    <content type="text"><![CDATA[企业上云首当其冲的就是要解决安全性的问题，是否满足企业对安全的诉求成了影响其是否上云的一个十分重要的因素之一。安全是一个很大的话题，从底层资源数据的安全到上层应用访问的安全，从访问客体（资源或服务）的安全到访问主体（人或者第三方服务）的安全，这些都属于安全的范畴之内。访问控制正是从资源访问的主客体关系出发，解决企业对资源访问的权限控制的需求。 维基百科对访问控制的定义如下： 访问控制是指允许或禁止某人使用某项资源的能力。 云环境下的访问控制使得这个问题变得复杂，我曾写过一篇对云环境下访问控制系统的思考来阐述这个问题。从2.14号上线访问控制以来，接入访问控制的业务越来越多，截止目前已有六大业务支持访问控制；同时，访问控制还对云服务提供了支持，用户可以授权给易盾和视频云来访问其在NOS（网易对象存储）的数据资源。现在，你可以自定义访问控制策略，通过一套特定DSL语法来定义权限。根据自己的实际使用场景和组织架构来定义对权限的需求，这具有十分重要的意义。 举个例子，如果不允许某某子账号删除avatar桶中file-1.png的图片，而允许其对其他任何文件有所有的控制权限，那么可以定义如下的策略来达到这个目的。 1234567891011121314151617181920212223&#123; "version": 1, "statement": [ &#123; "action": [ "comb:nos:DeleteObject" ], "effect": "deny", "resource": [ "comb:nos:*:*:*:avatar/file-1.png" ] &#125;, &#123; "action": [ "comb:nos:*" ], "effect": "allow", "resource": [ "comb:nos:*:*:*:*" ] &#125; ]&#125; 通过语言来定义权限，用户将获得十分灵活的权限控制，当然也包含了细粒度的权限控制。使用DSL来定义权限的做法很早之前就存在了，可以追溯到2001年的XACML时代。目前主流的云计算厂商也均采用这种方式来描述权限。我们采用了业界相同的命名方式来降低用户的理解成本。这里对策略语法做一个简单的介绍。 策略语法就是有着一定约束关系的JSON格式数据，由version和statement两个部分组成。version目前只支持1，而statement则是描述策略的具体形式。statement由三个部分组成，action、effect和resource，这三个子句构成了访问控制最为核心的三个部分。 effect表示授权类型，只能是allow（允许）或者deny（拒绝）。 action表示动作，组成结构为product:service-name:action-name。product目前只支持comb，service-name代表基础服务（蜂巢）下的服务，目前已支持的服务如下： 服务代号 | 服务名称— | —nos | 对象存储nlb | 负载均衡rds | 关系型数据库mongodb | MongoDBncr | Redis缓存cdn | CDN action-name表示具体动作的名称，例如nos支持GetBucket、PutObject等动作，cdn支持CreateDomain、DisableDomain等等，具体的动作请参考对应服务的文档。 resource表示资源，组成结构为product:service-name:region:az:account-id:resource-descriptor。product和service-name和action中的意义相同，region表示地域，az表示可用域，目前只支持*，account-id是用户的主账号id，目前也只能填入*，resource-descriptor是具体资源的描述符。resource-descriptor根据具体的服务会有变化，整体上是树形结构的。例如：bucket-1/file-1.png可以表示nos中bucket-1的桶中的file-1.png文件，而instance/nlb-1可以表示nlb中实例名称为nlb-1的实例。具体的规则请参考对应服务的文档。 statement语句本身是一个Array，你可以在其中最多定义5条子句。这样就允许你将多条策略组合在一个策略里面，也可以根据需要将策略拆改，选择权在你手上。 通过上面的策略语言，企业完全可以根据自身的实际需要来定义权限，具有非常大的灵活性和自由度。如果你以前使用过其他云的访问控制产品，那么上手会很快。如果是第一次接触此类产品，也不用担心，我们提供了一个强大了“编译器”来检查你的策略语法是否合法，并提供简单直观的错误展示来帮你迅速定位问题，如下图所示。 另外，访问控制还提供了了子账号、组和角色来满足企业对访问主体描述性的需求，企业可以根据自身的组织架构和研发模式来组合使用这些身份。 掌握了授权策略后，理解鉴权的执行流程也是很重要的。鉴权流程按照Deny优先原则执行，如果有显式的Deny，那么直接拒绝；如果有显式的allow，那么则允许，否则也拒绝。具体流程如下。 在授权时请遵循最小权限原则，即根据用户的需要，将刚好能满足其需求的权限赋予给他，这样有助于规避一些越权执行的问题。除此之外，最佳实践还包含及时收回用户不再需要的权限，尽量通过组和角色来授权等等。详细的文档可以参考访问控制的官方文档。 通过以上的介绍，不知道你是否对访问控制有一个大致的了解。如果还是有些云里雾里，那不如自己去动手定义一个属于自己的访问策略吧！]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>访问控制</tag>
        <tag>DSL</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[评论从多说迁移到Disqus]]></title>
    <url>%2F2017%2F05%2F21%2F%E8%AF%84%E8%AE%BA%E4%BB%8E%E5%A4%9A%E8%AF%B4%E8%BF%81%E7%A7%BB%E5%88%B0Disqus%2F</url>
    <content type="text"><![CDATA[建站以来一直使用多说作为评论系统，我还是非常喜欢国人做的评论系统，简单实用接地气。但是不盈利的商业软件最终只能关闭，这方面国内对盈利模式得探索要不国外落后太多了。 虽然切换到Disqus以后免不了被墙，但目前我确实还没有找到称心如意的评论软件。如果网友们有好的评论系统，不放留言给我推荐，叩谢！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对云环境下访问控制系统的思考]]></title>
    <url>%2F2017%2F03%2F07%2F%E5%AF%B9%E4%BA%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景现在，云计算市场已是一片红海，不论是国内还是国外的云计算市场竞争都相当激烈。主流的云计算厂商在争夺企业客户方面都不留余地，因为企业用户对云计算的发展有着极为重要的意义，尤其是大企业客户。可以毫不夸张的说，没有企业用户，云计算的发展绝不会发展的如此迅速。 企业上云首当其冲的问题就是安全性，安全性已经成为企业上云最大的障碍。这里的安全性不光是基础设施的安全和稳定，比如虚拟机的高可用、RDS的高可靠等等，也包括应用层面的安全性，如WAF、证书服务、加密服务等等，还包括因为企业本身的IT架构/研发架构的复杂性带来的资源管控方面的安全性需求。毫不夸张地说，谁解决好了企业的安全性诉求，那么他就能在这片红海中立于不败之地。 安全是一个很大的话题，我不敢妄谈。最近我在做访问控制方面的工作，故此分享一下我对这个领域的一点思考。访问控制是安全中一块，也是十分重要的一块。有些云计算提供商甚至都没有将其划归到安全的范围，可能是没有意识到访问控制的重要性。AWS中访问控制的产品是IAM，可以说是云计算厂商中做的最早也最为完善的一个。IAM在其的产品分类中有一个词我觉得形容该产品最为合适——“合规性“。其实访问控制就是满足企业用户对于合规性的需求，说白了就是规范企业用户对云计算资源的访问。 既然这是一篇关于访问控制的文章，那么我们先来看看关于访问控制的定义。 维基百科关于访问控制的定义是：访问控制是指允许或者禁止某人使用某项资源的能力。这个定义中有几个关键点需要留意： 人 某项资源 允许/禁止 能力 虽说维基百科关于访问控制的定义略显简陋，但是这个定义我觉得已经勾勒出了访问控制系统的大致形态。首先是人，访问控制的主体是人，所以其最为重要的使用群体是用户，那就是说这个系统是一个面向用户的系统。其次是某项资源，资源是访问控制的客体，某项的限定词则表明资源的具体形式是未知的。再次是允许/禁止，这是访问控制对外提供服务的最为直观的表现形式，用一个更为专业的名称来形容的话就是“鉴权”。最后是能力，为什么我把能力专门拿出来作为一个关键点来说，因为这是理论和实践的一个关键区分点之一。访问控制的理论为我们设计对应的系统和产品指明了方向，但是在生产环境中使用的还是遇到各种各样的现实问题。有一点需要特别注意的是，访问控制系统作为一个通用的公共服务，它需要提供的是一种能力，而不是针对特定环境和产品，否则只为沦为某个特定的专家系统。 维基百科关于【访问控制】的定义在理论层面已经颇为全面，然而从系统的设计到角度来看还缺少一个关键点，那就是——动作。这里的动作（可以也称之为操作）可以理解为具体系统所开放的能力，或者用户可以对系统执行的操作。例如，RDS产品需要开放createDataBase\listDataBase\deleteDatabase等等动作，又如NOS（网易对象存储）需要开放listBucket\createBucket\listObject\putObject等等动作。就算脱离云计算的环境，动作也是访问控制中不可缺少的要素之一，因为任何给人使用的产品都会伴随与人的交互，而这些交互的细粒度表现就是这些动作。 既然现在我们已经了解了访问控制的基本理论，那是否可以开始设计系统开始编码了呢？千万不要这么做，想清楚再做远比边做边想要节约时间。这听上去有点和现在的“敏捷开发“不太符合，实际上恰恰相反，”敏捷开发”虽然强调持续集成、快速迭代，但是这却是建立在前期良好的架构设计的基础之上的。言归正传，这是一篇关于访问控制实践探究的文章，在我们设计系统之前，先看看以前的访问控制系统一般是怎么做的。 传统的访问控制模型在访问控制系统的设计中，有两种设计模式是十分重要，也是得到广泛应用的，那就是访问控制列表（ACL）和基于角色的访问控制（RBAC）。 1.访问控制列表（ACL）访问控制列表是早期的一种访问控制技术，其原理十分简单，就是记录哪些用户对这个资源能进行哪些操作，有类似如下的二维表维护在文件中： User Create Update Query Delete 张三 √ √ √ × 李四 √ √ √ √ 王五 × × √ × 这种访问控制的方式好处显而易见，就是简单直观，易维护。这种设计在操作系统、路由器、交换机和工业控制系统中都得到了广泛的使用。不过，ACL的缺点也是显而易见的，那就是当用户、资源和操作组建增长时，维护这张表的代价会异常庞大，另外，这种设计模式将用户对资源的控制权限直接绑定，十分死板，灵活性不够，无法满足云环境下动态资源授权的需求。 2.基于角色的访问控制（RBAC）基于角色的访问控制将用户按其属性进行分类构建出一个个具体的角色，而将权限授权角色，用户通过扮演角色来间接地获取对应的权限。RBAC非常适合现实环境，尤其是企业，因为使用资源的使用者一般并不是资源的拥有者，资源的所有者属于企业。在云环境中更是如此，可能使用RDS的人是公司的开发或者PE，而RDS的归属者是对应的企业。RBAC从访问控制的主体的角度出发，很好使适应了企业的组织结构，同时也将用户和权限分离开了，用户只需要通过扮演不通的角色就能获得对应的权限，这种方式解决了云环境下动态授权的权限需求。 那是否RBAC能解决我们所有的问题了？显然不是。现实的问题往往是复杂的，不会像非黑即白这样简单。RBAC将人和权限分离的方法确实解决了一部分灵活性的问题，但是也增加了使用成本，同时它对细粒度的权限控制没有很好的应对之法。 云环境下面临的挑战现在我们也知道了主流的访问控制模型一般是怎么做的了，那么如何应用在云环境中呢？我觉得在云环境下的访问控制系统主要面临以下几个挑战： 1.资源标识的灵活性访问控制的系统的立项一般都晚于云计算中的其他产品，因为它本身属于支撑产品。但随着其他产品形态组建完善，如何很好地描述各个产品的资源就成了一件非常令人头疼地问题。在一些IaaS的产品形态中，很大一部分是以实例(instance)的方式来提供服务的；而在某些PaaS的产品形态中，有些是实例的方式来提供服务，而又有一些有着很强的特殊性，比如上文提到的NOS，它们的资源描述是需要以树形方式来表达的。SaaS产品用统一的访问控制系统来管理一般不太可能，因为每个Software的产品形态和使用方式千差万别，你很难去做到统一。在对访问控制系统的设计过程中我发现了一个很有趣的现象，当你考虑的产品越接近应用层面（上层服务），访问控制系统就越接近专家系统。这样很好理解，越上层的服务它的特殊性越强，所以通用性越差，只能做成专家系统。 2.细粒度的权限控制访问控制系统的有一个比较困难的点，那就是细粒度的权限控制。这一点在访问控制模型中你找不到答案，它们只是在比较宏观的层面讨论了人和权限的关系。细粒度的权限控制是现实中存在的一个需求，比如一个企业有若干台虚拟机，有一些虚拟机用作webserver，而有一些虚拟机用作数据库，还有一些作为中间件服务器，比如Zookeeper等等。而使用这些虚拟机的人各不相同，他们能看到并操作的虚拟机也应该得到严格地监管，否则可能会引起安全事故。细粒度地权限控制关键点在于“多细”，越细致地控制会导致你的系统复杂度成倍增加，不利于的系统地可维护性。我的建议是只做到实例级别，但有一个例外，那就是对象存储。能做到多细的程度很大一部分取决于第一点中你地资源标识地方式，如果你的资源描述方式得当，那么更加细粒度地访问控制并不会增加你系统地复杂度。这个我会在下文中提到。 3.身份的多样性如果一个云计算厂商想吃下一个大客户，满足其业务架构只是其一，还有一个十分重要的条件就是满足其组织架构。大企业绝对有实力也有能力解决其本身的业务架构，其实上不上云更多地是战略性的考虑，他们更加看重云服务的稳定性、安全性和可维护性。同时，其本身的组织架构也十分复杂，要想让其没有阻力地上云，解决其员工的身份问题首当其冲。所以现在主流的云厂商都会提供多种身份的表示方式，例如：子账号、组和角色。 4.权限的描述方式权限的描述方式也是十分重要的一个点，可以说这个点设计得好坏决定了你后期能否悠然地应对业务方的接入还是每天火急火燎地和各个业务方定协议定接口。我们知道所有需要访问控制的云产品必然有其支持的动作（Action），每个产品资源(Resource)的描述方式也各不相同，同时允许（Allow）还是禁止(Deny)针对某个资源的操作也是需要明确给出来的。这三个点构成了权限描述的三个要素。如果在前期的设计中没有充分思考这个问题，那么恭喜你，你很有可能给自己埋了一个深坑。你很有可能设计几张大表，来表示各个业务方支持的动作，资源以及用户和他们的关系。出现这样的设计是因为没有真正理解访问控制系统的业务领域。当你在设计这几张表的时候其实意味着访问控制系统在“理解”各个产品的功能，这对一个通用的访问控制系统是致命的。访问控制系统作为一个底层/共享的通用系统，对外输出地只能是能力，而不是去理解各个产品它们自己地业务领域。说到这里，我还是推荐所有的技术人员都有必要学习一下DDD的理论，就算不用自己写代码，系统性地学习其战略模式也会让你收益颇多。 5.动态的授权体系这一点相比以上4点来说要简单，这是因为如果你的访问控制系统已经很好地解决上面的挑战，那么你也就自然而然得获得了动态的授权体系。之说以是动态的，是因为云环境下用户和权限的关系往往不是一成不变的。用户在某个时刻希望获得A授权，而在另外一个时刻又希望获得B授权，而且有时授权还带有时效性，当过了截至时间授权也就自动失效了。这种动态性的需求是真实存在的，但我认为满足这个需求依赖于针对前4点的设计，如果把前面的设计做好了，那么系统也就自然而然地满足了动态性的需求，这是一个水到渠成的过程。 业界是如何处理这个问题说实话，当我去设计蜂巢的访问控制系统的时候并没有像现在考虑的这么全面。我意识到了一些问题的棘手性，也调研了现在业界做访问控制的方法，可以说做的最好的还是IAM。IAM将用户身份划归为子用户、组和角色，基本上这三种身份标识可以满足身份多样性的要求了。我觉得IAM关于权限描述的方式令我耳目一新，它使用了领域专用（DSL）语言来描述权限，具体的形式如下： 12345678&#123; "Version": "2012-10-17", "Statement": &#123; "Effect": "Allow", "Action": "s3:ListBucket", "Resource": "arn:aws:s3:::example_bucket" &#125;&#125; 这是我第一次接触DSL的概念，当时对这种设计模式是完全懵逼的，也不太理解其设计思想。随着考虑的问题越来越多，我发现了DSL的强大之处。因为云环境下的访问控制系统最令人头疼的问题就是资源和权限的描述方式，这种极致的灵活性很难通过设计表格来获得。因为任何的以表为中心的设计方式都会映射到某个具体的领域模型上，又因为各个业务的权限控制各不相同，难道说我要根据各个业务来建立模型？前面也说过了，这是万万不可取的，这样设计只会让你深陷无尽的加班和调试之中。用DSL来将访问控制和具体的权限理解分隔开了是最为合适的方式。 通过一套约定的DSL语法来描述权限，访问控制系统可以获得极大的灵活性，同时也不需要理解具体的权限。对权限的理解还是由各个业务方自己控制，这样系统就获得了最大程度的解耦。访问控制系统只用维护这套DSL语法就可以无限的扩展性，多么完美的方案啊！有时间我会专门写一篇关于DSL的文章来对其应用场景进行分析。 实际上，用DSL语法来描述权限也不是IAM首创，早在2001年就出现了响应的规范——XACML（可扩展的访问控制高标识语言），该规范现在已经发展到3.0了。其大致的鉴权流程如下图所示，如果对其原理由兴趣的同学可以查看对应的资料。 以上就是我对云环境下访问控制系统的一点理解，如有不严谨的地方，还望指正。总而言之，云环境下的访问控制系统面临的挑战很多，充分理解访问控制的原理有助于理解代码背后的意义，让我们的系统设计不至于走偏。基于DSL的访问控制模型已经成为业界的主流，但各个云计算厂商自身的业务场景和面向目标人群又各有不通，如何制定适应自身环境的DSL成为了一个关键。后续有机会我会分享网易蜂巢在访问控制系统方面的实践。 参考资料：访问控制访问控制模型ACL和RBACDSL]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>cloud</tag>
        <tag>访问控制</tag>
        <tag>DSL</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot反序列对象失败]]></title>
    <url>%2F2016%2F12%2F21%2FSpring-Boot%E5%8F%8D%E5%BA%8F%E5%88%97%E5%AF%B9%E8%B1%A1%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[现在Spring Boot这个项目很火，尤其是微服务的流行，Spring Boot作为Java语言最热门的微服务框架之一，它极大地简化了Spring的配置过程。只需要一个注解就可以把整个工程拉起来，大大地降低了Spring的学习成本。我记得Spring Boot的某个开发人员说过，Spring Boot最令开发者激动的功能是可以自定义banner，哈哈，我也非常喜欢这个功能。 言归正传，开始介绍今天我遇到的一个诡异的问题。我使用Redis来缓存一些数据，但是这些数据在反序列的时候报错了。由于原工程涉及一些敏感信息，我新建了一个demo工程来说明这个问题。报错信息如下： java.lang.ClassCastException: com.netease.boot.dal.Product cannot be cast to com.netease.boot.dal.Product 看到这个报错我就懵逼了，以致于我对了好几遍来确认眼睛没有看花。经过若干次重试，还是一样的错误。有人可能会对Product的实现产生怀疑，是不是没有加serialVersionUID，作为一个专业老司机，这点错误我还是不会犯得。我贴一下相关的代码： Product类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Product implements Serializable &#123; private static final long serialVersionUID = -5837342740172526607L; @Size(min = 1, max = 32) private String code; @Size(min = 1, max = 16) private String name; @Size(max = 255) private String description; @NotNull private EMailAddress principalEmail; public Product(String code, String name, String description, EMailAddress principalEmail) &#123; this.code = code; this.name = name; this.description = description; this.principalEmail = principalEmail; &#125; public void changeName(String newName) &#123; this.name = newName; &#125; public void changeDescription(String newDescription) &#123; this.description = newDescription; &#125; public void changePrincipalEMail(EMailAddress newPrincipalEMail) &#123; this.principalEmail = newPrincipalEMail; &#125; public String getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125; public String getDescription() &#123; return description; &#125; public EMailAddress getPrincipalEmail() &#123; return principalEmail; &#125; @Override public String toString() &#123; return "Product&#123;" + "bizCode='" + code + '\'' + ", name='" + name + '\'' + ", description='" + description + '\'' + ", principalEmail=" + principalEmail + '&#125;'; &#125;&#125; redis service相关的代码如下： 123456789101112131415161718192021222324252627282930313233343536 @Overridepublic void put(String key, Serializable content) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] contentBytes = SerializationUtils.serialize(content); jedis.set(key.getBytes(ENCODING), contentBytes); &#125; catch (Exception e) &#123; LOG.error("Put error:&#123;&#125;.", e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125;&#125; @Overridepublic &lt;T&gt; T get(String key) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] valueBytes = jedis.get(key.getBytes(ENCODING)); if (valueBytes == null || valueBytes.length == 0) &#123; return null; &#125; return SerializationUtils.deserialize(valueBytes); &#125; catch (Exception e) &#123; LOG.error("Get error:&#123;&#125;.", e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125;&#125; 实在没办法，这尼玛是什么问题。因为我以前这么使用过，而且工作的非常好，为毛这次就不行了。没办法了，加debug代码，我让get方法返回Object，再外面强转，（冥冥中有一种感觉，像是泛型的问题）。修改后的代码如下： 1234567891011121314151617181920@Override public Object get(String key) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] valueBytes = jedis.get(key.getBytes(ENCODING)); if (valueBytes == null || valueBytes.length == 0) &#123; return null; &#125; Object o = SerializationUtils.deserialize(valueBytes); return o; &#125; catch (Exception e) &#123; LOG.error("Get error:&#123;&#125;.", e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125; &#125; 在反序列化之后加断电debug，观察变量o，得到如下所示的图： WTF! IDE都识别出来了变量o是Product类型，但是后续的强转还是失败。经过我的测试发现所有的通过redis反序列化出来的类都有这个问题。万般无奈之下，我陷入了深深地沉思之中…之中…中… 我开始怀疑是序列化的姿势不对，但是为毛以前可以啊。不管了，先加一段测试代码： 123456789101112131415161718Product product = new Product("comb","蜂巢","云计算基础设施产品",new EMailAddress("hzxx@corp.netease.com")); /*FileOutputStream fileOutputStream = new FileOutputStream("/home/mj/work/product.data"); fileOutputStream.write(SerializationUtils.serialize(policyContext)); fileOutputStream.flush(); fileOutputStream.close();*/ ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("/home/mj/work/product.data")); oos.writeObject(product); oos.flush(); oos.close(); /*FileInputStream fileInputStream=new FileInputStream("/home/mj/work/product.data"); byte[] rawPolicyContext=new byte[fileInputStream.available()]; fileInputStream.read(rawPolicyContext); PolicyContext pc = SerializationUtils.deserialize(rawPolicyContext); System.out.println(pc);*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream("/home/mj/work/product.data")); Product pc = (Product) ois.readObject(); System.out.println(pc); 在倒数第二行打点，截图如下： 没截图没毛病啊，很正常啊。我还专门测试了SerializationUtils版的序列化方式(把上面的注释去掉)，发现结果也很正常，这尼玛到底是怎么回事。实际上，SerializationUtils也就是jdk自带的ObjectOutputStream和ObjectInputStream的简单封装。 在我走投无路之际，正准备研究instanceof的工作原理的时候，脑中闪过一道灵感——难道是classloader的问题？说干就干，debug得到如下情况： 终于发现问题所在了，原来两个classloader不一样，而instanceof是对同一个classloader而言的。再确定原因后，借助强大的google发现了这是Spring Boot DevTools的一个限制，相关的文档链接: http://docs.spring.io/spring-boot/docs/1.4.2.RELEASE/reference/htmlsingle/#using-boot-devtools-known-restart-limitations 原话是这样的： Restart functionality does not work well with objects that are deserialized using a standard ObjectInputStream. If you need to deserialize data, you may need to use Spring’s ConfigurableObjectInputStream in combination with Thread.currentThread().getContextClassLoader().Unfortunately, several third-party libraries deserialize without considering the context classloader. If you find such a problem, you will need to request a fix with the original authors. DevTools是Spring Boot中一个很有用的工具，可以自动帮你重启应用，而不用你每次重启应用来debug，提高了生产效率。具体的用法可以参考相关的文档。这里的限制条件说的很清楚了，重启功能不能和使用标准的ObjectInputStream来反序列对象一起使用，如果你非要使用，那么请从线程的上下文中来获取classloader。 看到这里我瞬间明白了。因为devtools使用两个classloader，你工程中使用的第三方jar包被一个叫”base”的classloader所加载，而你正在开发的代码被一个叫”restart”的classloader所加载。如果检测到你的classpath路径下文件有变化，restart就会重新加载你工程的类。这样做以后能提高你的类加载速度，这在开发阶段是很有用的一个功能。 既然知道了原因，就很好解决了。因为我目前的工程比较小，而且只是一个restful后端应用，所有devtools对我的应用帮组不大。注释掉devtools依赖后就解决了上面的问题。如果你想使用这个工具，同时又有反序列化的需求，有两种方式解决： 自定义一个ObjectInputStream，重写resolveClass方法，也可以使用Spring提供的ConfigurableObjectInputStream类。然后从Thread.currentThread().getContextClassLoader()获取classloader就可以解决该问题。 配置spring-devtools.properties文件，把你使用的第三方序列化工具也加入restart classloader的控制范围内就行了。 这两种方法均可以在Spring Boot的官方文档中有详细描述：http://docs.spring.io/spring-boot/docs/1.4.2.RELEASE/reference/htmlsingle/#using-boot-devtools。 总结，从发现问题到定位原因耗时两个多小时，还是要加强对基础概念的深入理解才能快速定位原因啊！ 文本的示例demo我已上传到github，有兴趣的同学可以下载自己debug一下：https://github.com/mymonkey110/boot-demo.git 参考资料: Spring Boot官方手册spring-boot issueredis serializationclasscastexception]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>springboot</tag>
        <tag>deserialized</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构为什么会腐化]]></title>
    <url>%2F2016%2F12%2F15%2F%E6%9E%B6%E6%9E%84%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E8%85%90%E5%8C%96%2F</url>
    <content type="text"><![CDATA[架构腐化一词我已经忘了从哪本书上看到的了，但是这个词给我留下了非常深刻的印象。关键在于“腐”一词，充分而又形象的描述了架构是怎样一步一步从简单清爽走向复杂污秽的。请允许我用“污秽”一词来描述一个糟糕的架构，因为糟糕的架构就像是一潭散发着臭味的淤泥，让你不想靠近，一旦涉入其中就会难以自拔，苦不堪言。 我相信所有的开发者都不希望自己的参与项目是一潭淤泥，但是为什么会出现这么多糟糕的架构呢？难道是项目最初的设计者经验不够，又或者项目开发周期太赶？我认识事实并非如此。现在，软件开发者的水平都普遍提高了，因为我们有前人那么多经验可以借鉴，连刚毕业的大学生也知道用MVC模式来搭建框架。难道是MVC模式太挫了，不够用，实际上80%的项目用MVC模式足以应对。那到底是什么原因导致了项目腐化呢？我认为有以下三个原因： 1. 不理解项目的业务价值实际上，几乎所有的软件（尤其是商业软件）都有其所属的业务价值，理解你所开发的软件的业务价值对项目的成功来说至关重要。我发现很多程序员对业务需求不屑一顾，而对那些所谓的非功能性需求盲目的崇拜和追捧，其实这是一种本末倒置的行为。 现实世界是一个商业的世界，而商业世界则会充斥着各种各样的业务逻辑。理解这些业务逻辑会极大地增加你的见识、拓宽你的视野。如果你是一个在金融行业工作的程序员，那么长时间在金融领域工作的精力将极大地提高你的市场竞争力。但是如果你不愿意花时间去学习金融领域的知识，而是去盲目的追求最新的技术，那么其实你是丢芝麻捡西瓜，浪费了这个行业带个你的附加价值。我不是不鼓励程序员瞎折腾，实际上我自己有时候也喜欢瞎折腾，倒腾一些新玩意，这视乎是程序员的一种天性。我的意思是说不要放弃了解自己所在行业/领域的知识视为不见，而盲目的追求其他的“高大上”的技术。 为什么说理解项目的业务价值至关重要呢，那是因为只有理解了其业务价值你才能识别出来这个项目的核心领域所在，这样这个项目才不会走偏。传统的软件开放流程中有一个非常重要的角色存在，叫做“业务分析员”，他的工作在项目的概要设计和详细设计解决十分重要。虽然我也没见过有专职的人员干这个，但是这却是非常重要的一个角色。他会帮你分析你的业务，和产品经理沟通，理解产品的真正意图。在这个沟通过程中，你的领域模型也就逐渐的清晰起来了，哪些是核心哪些是支撑部分也就清楚了。 有些程序员在接到产品需求后立马就开始工作了，吭哧吭哧地撸袖子上阵，我认为这是十分要不得的。接到产品需求的第一反应不是要想着我要建哪些表哪些字段，而是要多问问自己这个需求是干啥的，产品经理真正的意图是啥，为什么要我来做，跟我的系统有啥关系。千万不要盲从产品经理的话，实际上有些时候他们自己也不知道自己要干啥，为啥要这么干。这个时候必要的交流是不可少的，随着对话的深入，你和产品对真是的需求都会有着更深地认识。新人和实习生在这方面经验往往不足，此时最好找一个比较资深的程序员帮你梳理一下业务流程。 相反，如果你不知道你的系统的业务价值或者核心所在，什么需求你都来着不拒，那么恭喜你，你的系统正在腐化。当你在抱怨说“为什么这个业务要放在我这里”，“这个我有什么关系”之类的话的时候就可以闻到一丝“腐化”的闻到。你可能会说项目工期紧、人手太少、需求太多之内的外部原因，所以临时地先加到系统中搞一下。Ok，这没有任何问题。但是我还是要说，你知道你的系统的核心价值所在吗？如果你的回答是Yes，那么恭喜你，你是一名合格的程序员了。否则，你可能需要学习一下技术之外的东西的了－那就是沟通。 2. 过度设计软件开发的头号敌人就是复杂度。现在软件开发是如此的困难，动不动就有十几万行代码出现，但是现实世界就是如此的复杂，不会因为你采用某种架构或者奇淫巧技就能把代码行数降下来。好的架构设计会将系统的复杂度控制在一个合理的范围之内，因为人所能驾驭的代码行数最多也就几十万行，如果一个系统的代码行数达到百万行，那么这个系统就很危险了。现在微服务架构如此火爆，不得不说有这方面的原因。 如果你在设计一个新系统，那么我需要提醒你一定要控制好复杂度。一个好的系统的核心域往往是简单的、直观的，其他人很快就能理解其核心的工作原理。如果一开始系统设计的十分复杂，那么这个系统的扩展性就会很差，后续的维护将不可想象。但是是不是在设计之初就完全不考虑后续的变化了呢？我的建议是你只需要把你的核心领域模型建好，多问问自己系统最核心的价值是提供什么服务的，照着这个方向去设计，那么你的系统就不会走偏。灵活性和可扩展型往往只是领域模型的延伸，这是一个水到渠成的过程。 非要给个度的话，我认为5%刚刚好。不要出现超过5%的跟你本次需求无关的概念和行为，而且这5%还是你能确定在不久的将来就会使用的扩展。 还是那句话，好的设计往往是简单的，复杂是万恶之源。 3. 懒于重构过度设计不好，完全不设计也不行，尤其是随着敏捷开发的流行，持续交付优于提前设计的思想逐步流行。现在软件交付速度是如此之快，很有可能刚刚设计好的系统，下个月就全变样了。应对这种变化的唯一方法就是持续重构。 没有任何设计能预料到未来的变化，代码可能会发生变化。新的功能会持续的添加进来，老的功能也在持续的改变。而且每次迭代或者交付，都可能会对核心领域产生影响。千万不要对这种影响视而不见，因为它在改变着你的领域模型。正确地方式是经常调整领域模型以适应新功能所带来的变化，虽然每次调整的幅度可能很小，但是这却能让你的领域模型处于健康的工作状态。没有领域模型或者系统在一开始就是完美的，之所以它们能在后续的迭代过程中良好的工作离不开不断地重构。 重构不是等到你的系统无药可救的时候才想到的事，而是应该在其不断开发过程中一直进行的工作。如果说持续交付提高了你系统的竞争力，那么持续重构则是这种竞争力的有力保障！ 以上三点是我认为架构腐化最致命的原因，很多思想来源于DDD、重构和敏捷开发。linus torvalds曾经说过： Talk is cheap. Show me the code. 我认为Talk is not cheap, 好的思想和开发方式价值连城，想好了再做会提高你的工作效率，从而提升你的生活品质。 这篇文章从下笔到完成，拖了半个多月了，期间琐事太多。对这个话题有兴趣的朋友我们可以留言讨论。]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[值对象的威力]]></title>
    <url>%2F2016%2F10%2F18%2F%E5%80%BC%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%A8%81%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[值对象是DDD中非常重要的一种技术，掌握这种技术让你写代码事半功倍，体会到OO的精妙。如果你是一名Java程序员，我相信你或多或少地见过值对象了，只是你没有意识到而已。 引用维基百科的解释： In computer science, a value object is a small object that represents a simple entity whose equality is not based on identity. 字面意思就是，值对象是一个小对象，它代表着一个简单的实体，而实体的相等性不取决于它的ID。 刚刚接触OO编程的新手看完上面的解释相信直接是懵逼的，跟我接触这一概念时一样。如何理解值对象了，我还是举一个栗子。比如我们在做一个短信推送的服务，需要根据目标用户的手机号推送到相应的短信网关。我们定义了一个根据手机号推送短信的interface，很有可能我们是这么设计： 1234567891011121314void sendMessage(String phone, String message) &#123; if(StringUtils.isBlank(phone) &amp;&amp; phone.length()!=13) &#123; throw new IllegalArgumentException("phone format error:"+phone); &#125; if(phone.starts("134")) &#123; sendMessageToChinaMobileGateway(phone,message); &#125;else if(phone.starts("130")&#123; sendMessageToChinaUnionGateway(phone,message); &#125;else if(phone.starts("189") &#123; sendMessageToChinaTelecomGateway(phone,message); &#125;else &#123; throw new RuntimeException("unknown phone range"); &#125;&#125; 上面的过程我们只考虑3个号码段，134(移动)\130(联通)\189(电信)，其他的号码短我们暂不处理。上面的处理方式有什么问题？ 如果我们的工程里面只有一个地方用的phone的概念，也只有一个地方对phone所属的号码短进行判断，那么没问题。上面的写法没有任何问题，因为它是一个简单问题。但是如果你在做一个短信推送的应用，在你的工程里面会只有一个地方会使用phone这个概念吗，也之有一个地方需要判断号码短吗？ 显然不可能。 有人可能会争论说，不就是判断号码归属吗？我可以搞一个类似PhoneQueryService之类的查询类，再提供一个Operator queryBelong(String phone)的interface不就搞定了吗？ 当然，这么做也没有问题。但是当你的问题域逐渐变得复杂的时候，你就会开始有些不舒服了。因为每一个出现phone的地方，你发现基本上都会需要PhoneQueryService，但是他们在代码上又是两个东西。这种做饭的滥用最终会导致Fat Service的出现，代码的复用性会急剧降低。 究其原因，是因为我们把phone这个概念和phone的行为给拆开了。你可以用String代表任何字符类型，可以是phone，也可以是name，基本上这种类型可以代表任何东西。使用你API的人无法从中得到任何信息，除了你把变量名称叫做phone以外。同时，判断手机号网段这个动作是和phone本身强相关的，为什么不把这个动作加到phone里面了？！ 现在，我们重构一下代码，得到类似下面的代码结构： 123456789101112131415161718192021222324252627282930313233class Phone &#123; private String phoneNumber; public Phone(String phoneNumber) &#123; if(!validate(phoneNumber)) &#123; throw new IllegalArgumentException("phone format error:"+phone); &#125; this.phoneNumber = phoneNumber; &#125; public static boolean validate(String phoneNmber) &#123; //验证逻辑 &#125; public boolean isMobile() &#123; return phoneNumber.starts("134"); &#125; public boolean isUnion() &#123; return phoneNumber.starts("130"); &#125; public boolean isTelecom() &#123; return phone.starts("189"); &#125; public String getRawPhone() &#123; return this.phoneNumber; &#125; public boolean isSameWith(Phone other) &#123; return other!=null&amp;&amp;this.phoneNumber.equals(other.getRawPhone()); &#125;&#125; 我们新增了一个叫Phone的类，并加入了判断网段归属的逻辑。引入这个类以后sendMessage()发生了什么变化呢？ 1234567891011void sendMessage(Phone phone, String message) &#123; checkNotNull(phone); if(phone.isMobile()) &#123; sendMessageToChinaMobileGateway(phone,message); &#125;else if(phone.isUnion())&#123; sendMessageToChinaUnionGateway(phone,message); &#125;else if(phone.isChinaTelecom()) &#123; sendMessageToChinaTelecomGateway(phone,message); &#125;&#125; 咋一看，代码好像没有怎么减少啊。对于这个interface来说代码确实没有减少，反而我们还新加一个类。但是现在看看我们获得了什么： 首先，方法签名变了。不在用String了，取而代之的是Phone类型。这对使用者的约束更强了，我们也再也不用判断phone是否合法了。 其次，判断网段归属和phone合在一起了，这样我需要判断归属运营商的时候直接调用phone的方法就行了。 现在，我们已经得到了一个值对象了，那就是Phone。它是一个小对象，代表了手机号这个概念，它的相等性是基于其业务属性的，而不是ID，而且值对象根本就没有ID这个概念。 值对象最大的好处在于增加了代码复用，同时它也是类型安全的（这一点和我之前提到了enum类似）。如果你只在一个地方使用值对象，那么你是不会体会到值对象带来的好处的。但是，每当你的代码应用一次值对象，你就会收获值对象带来的好处。用的越多，收益越大，这一点和单元测试比较类似。使用值对象的另外一个好处就是前置的安全校验，尤其是你在编写SDK或者开放接口的时候。因为你无法知道使用者会如何使用你的API，那么通过值对象来获得一个前置的安全校验有着非常大的好处。 值对象用在什么地方呢？ 我个人的经验就是，如果在你的工程中反复出现一个具体的概念（往往跟现实生活有关），而且这个概念中涉及的行为是某种确定性的（比如你知道了手机号，就知道对应的运营商一样），那么你可以考虑一下值对象。引用《实现领域驱动设计》中关于值对象特征的定义: 描述了领域中的一件东西 不可变的 将不同的相关属性组合成了一个概念整体 当度量和描述改变时，可以用另外一个值对象予以替换 可以和其他值对象进行相等性比较 不会对协作对象造成副作用 最为重要的就是它描述了领域中的某件东西，并且它是不可变的。值对象一旦创建就不会发生变化，如果你需要表示另外一个东西，用另外一个值对象来代替它。 值对象是DDD中非常重要的部分，我们应该尽可能对使用值对象来建模，因为它是易于使用和替换的。但是值对象的实例化确实一个令人头疼的问题，尤其是聚合中存在1对多的关系时。由于这些内容涉及到DDD的多方面的知识，我不在这里展开讨论了。后续会专门讲值对象的持久化问题。之所以在讲DDD之前首先讲值对象，因为它还是少数几个可以完全脱离DDD并不失其威力的利器。就算你完全不了解DDD，也可以非常顺手的使用值对象。 说了这么多，我相信你也对值对象有个具象的认识了。纸上得来终觉浅，不如看看你现有的代码中哪些可以用值对象来代替吧！ 参考文献： Wikipedia值对象的定义Martin Fowler值对象的解释实现领域驱动设计Power Use of Value Objects in DDD: 强烈推荐]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>Value Object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论Enum的重要性]]></title>
    <url>%2F2016%2F09%2F20%2F%E8%AE%BAEnum%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[我们都知道Java中有一种数据类型是枚举类，实际上很多强类型的语言都有枚举。但是很多人对枚举类不那么重视，或者不能正确地应用枚举，也就不能发挥其威力了。这里分享一下我对枚举的理解，及其常见的用法。 既然Java专门为枚举建立了类型，那么我们应该在什么时候去使用enum呢，我认为在以下两个场景中可以尝试使用。 1. 封装有限的的变化相信很多人都遇到这样一个场景，我们有一个父类，父类下面有几个子类，而这几个子类是可以确定的。我们并不想父类被不相干的类所继承，那么我们可以通过enum来限制子类。实际上你想把代码控制在预期的范围之类时，都可以通过enum来达到效果。 2. 状态代码我们经常会遇到使用状态码的情况，例如在任务处理过程中。我发现很多人喜欢使用int或者long来表示状态码，然后通过定义对应的变量来表示其意义。不是说这种方式不好，但我从中嗅出了一丝坏味道。如果通过int或者long来表示状态码，如果出现了不在业务范围内的值该怎么办？为什么状态码不能直接表示其意义，还需要通过文档来说明呢？我一直比较推崇Self-Explained的编程习惯，代码和文档合二为一。 那么使用Enum有什么好处了，我们为什么要用Enum呢？相比于int或者string，enum最大的优势就是有它是类型安全的。如何理解类型安全呢，我举一个例子：很多APP都有第三方登陆的功能，服务器要根据客户端传过来的登陆类型(type)来调用对应平台的接口来获取用户信息。我的代码是这样写的： 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class TPAccountRouterImpl implements TPAccountRouter &#123; @Resource @Qualifier("wbAccountResolver") private TPAccountResolver wbTPAccountResolver; @Resource @Qualifier("wxAccountResolver") private TPAccountResolver wxTPAccountResolver; @Resource @Qualifier("qqAccountResolver") private TPAccountResolver qqTPAccountResolver; @Override public TPAccount getAccountInfo(final String tuid, String accessToken, AccountType accountType) throws TPException &#123; TPAccountResolver tpAccountResolver; switch (accountType) &#123; case WB: tpAccountResolver = wbTPAccountResolver; break; case WX: tpAccountResolver = wxTPAccountResolver; break; case QQ: tpAccountResolver = qqTPAccountResolver; break; default: throw new TPException("unknown account type"); &#125; return tpAccountResolver.getAccountInfo(tuid, accessToken); &#125;&#125; TPAccountRouter是一个账号解析的路由器，根据AccountType来调用对应平台的解析器来解析。配合switch-case语法，利用策略模式我们就可以写出一个还算优美的代码。如果把accountType换成int会怎样？那么我们不得不加上一句及其烦人的123if(accountType&lt;0 || accountType&gt;3) &#123; throw new IllegalArgumentException("type illegal");&#125; 保护性代码，同时将case子句换成一个一个静态常量，最后还在API文档上配上说明，1,2,3各代表什么意义。我相信大家一定能感受出来两种代码写法带来的区别。 另外一个有点，我认为就是enum的self-explain特性，上面的例子中也直观的反应了这一点。Enum结合了int和String的优点，并将其发扬光大。 关于Enum怎么用，网上有很多的介绍，可以参考这篇文章：http://www.cnblogs.com/happyPawpaw/archive/2013/04/09/3009553.html，还是比较全面的。最常用的就是直接申明各个枚举值，基本上能满足大部分业务场景了。也有很多场景下，我们会在enum中加入成员变量，这是因为业务中存在和Enum相对应的文档和动作。再举一个我写过的代码例子：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class AbstractCheckedException extends Exception &#123; private static final long serialVersionUID = -3143228702981231790L; public AbstractCheckedException() &#123; &#125; protected abstract ErrorCode errorCode(); public int code() &#123; return errorCode().code(); &#125; public String msg() &#123; return errorCode().msg(); &#125; public static int successCode() &#123; return ErrorCode.SUCCESS.code(); &#125; public enum ErrorCode &#123; SUCCESS(1000, "success"), PARAM_ERROR(1001, "parameter error"), ILLEGAL_REQUEST(1002, "illegal request"), SYS_ERROR(1003, "system error"), NAMESPACE_NOT_FOUND(2001, "namespace not found"), NAMESPACE_ALREADY_EXIST(2002, "namespace already exist"), APP_NOT_FOUND(2003, "app not found"), APP_ALREADY_EXIST(2004, "app already exist"), TASK_NOT_FOUND(2005, "task not found"), TASK_ALREADY_EXIST(2006, "task already exist"), CRON_EXPRESSION_ERROR(2007, "cron expression error"), ZOOKEEPER_ERROR(3001, "zookeeper error"), NODE_NOT_EXIST(3002, "node not exist"), NODE_ALREADY_EXIST(3003, "node already exist"), UNKNOWN_ERROR(9999, "unknown error"); private int code; private String msg; ErrorCode(int code, String msg) &#123; this.code = code; this.msg = msg; &#125; public int code() &#123; return code; &#125; public String msg() &#123; return msg; &#125; public static ErrorCode getErrorCode(int code) &#123; for (ErrorCode it : ErrorCode.values()) &#123; if (it.code() == code) &#123; return it; &#125; &#125; return UNKNOWN_ERROR; &#125; &#125;&#125; 我在jscheduler中封装了高层了受检异常，这点收到了Zookeeper中KeeperException的启发。我在ErrorCode中加入了code和message，因为code和message是和这个枚举绑定的，放到枚举中再合适不过呢，我将之称为文档的绑定。还有情况是因为业务动作和枚举相关，比如第三方登陆的例子，我们完全可以第三方登陆接口的URL放到AccountType中，然后后续的解析方法直接从中取的URL进行调用就行，因为这个解析方法是和Enum一一对应的。这样的例子实在太多了，不胜枚举。 总之，如果你有一类相识的业务场景，并且这些业务场景只有有限的变化，是可以预期的，那么建议你考虑一下使用Enum。相信我，它值得尝试！]]></content>
      <categories>
        <category>Better code</category>
      </categories>
      <tags>
        <tag>enum</tag>
        <tag>OO</tag>
        <tag>代码技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDD-复杂问题解决之道]]></title>
    <url>%2F2016%2F09%2F18%2FDDD-%E5%A4%8D%E6%9D%82%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93%2F</url>
    <content type="text"><![CDATA[上个星期在团队内部进行了关于DDD的分享，分享链接：http://slides.com/fengchen/ddd-tackling-complex-problem#/。 分享的过程中发现还是有很多小伙伴对DDD不太了解，或者一知半解。DDD其实不是一个新的技术，实际上距离Eric Evans出版《Domain Driven Design》已经12年了。与其说DDD是一门编程技术，我更愿意将它称之为软件开发方法。我发现国内的技术分享两级分化比较严重，要么太过高大上——关于架构、新技术之类，要么太底层——关于数据库优化、底层性能优化之类，但很少有人来讲中间的那一层——软件编程方法。 在我看来，一个新人要成长为技术大牛，都要经历下面三个阶段： 1. Make It Work （1~2 年）刚刚踏入职场的新手程序员往往处于这个阶段，他们首要的工作是要让系统能正常工作。出于工作的需要，他们开始了解语言、框架、数据库、缓存。如果在大公司的话，可能会更早的接触服务框架、中间件等。但是他们的主要工作还是实现业务需求，对代码的质量没有过多的要求。有时候可能感觉到现在的写法可能不太好，但是又不知道怎么去组织代码才能让它们看上去更舒服，经常会刚到迷茫，好像刚工作一年就看到了未来十年的影子，这是十分令人沮丧的。这个阶段一般会持续1~2年。 2. Write better code (3~5 年)这个阶段是新手程序员向老司机转变的一个时机。他们已经能独立完成常见的业务需求，并给出自己的意见。写出的代码不仅是为了完成功能，更多地是在寻找一种平衡的美。这种美很难言明，它是介于现实逻辑和代码组织的一种完美结合。正好我也处于这个阶段，我会有时因为一次完美的解耦而欣喜，也会因为业务的妥协而忧伤。在这个时期，我在寻找一种“术”，一种能随心所欲驾驭代码的术。我开始了解到OO技术的精妙，开始理解设计模式的妙用，学着掌控整个项目的发展，只为达到软件的最高境界——“可复用”。这个阶段肯能持续时间很长，因为我们要细细去品味优秀代码的味道并为己所用，这需要时间的沉淀。 3. Create suitable architect (5年 ~ )当你能随心所欲的操纵代码时，你就会去寻找你还未涉及的阶段。这个阶段可能会产生多种分化，你可能会对项目的整体架构产生兴趣而走上架构师的道路，也可能对某些专有技术情有独钟而成为某一方面的技术专家。不论后面的发展方向如何，此时代码对你已经不是问题了，而成为了你的“工具”。国内的技术分享往往也集中在这个层面。好的架构往往有着相似的部分，但是每个架构又有它独有的业务背景，你需要剥离其中的业务部分，找出能为自己的项目有用的设计。没有完美的架构，只有最合适的架构，任何现实的架构都充满着妥协和折中。这个阶段持续时间可能更长，你也需要机缘能参与几个重大项目的架构设计。 说白了，软件开发还是一门需要经验的行业。我并不太相信天才的存在，因为没有长时间浸泡在代码之中项目之中，你是很难理解代码和业务的关系的，这需要大量的时间。现在“新技术”层出不穷，我的建议是，在没有成为真正的架构师之前，不要盲目的追逐这些“新技术”，这只会耗费你大量的精力。 言归正传，我认为DDD是一门教你Write better code的软件开发方法。就算你是底层的研发人员，我相信你也会从中收益。如果你是一名业务程序员（80%的都是），为什么不多花一些时间去真正理解你的业务呢？不要再去追逐那些“新技术”，多去思考一下我的代码该如何解耦、业务如何切分、代码怎么写才能更好的复用。如果你坚持这么做，我相信不出两年你对技术和业务的理解会发生质变。 学习DDD其实还是有一定的曲线的，如果你的团队中已经有人尝试过DDD了不妨向他取经，因为DDD的精髓更多的在于编程的思想，而不在于具体的代码。后期我会分享一些关于DDD、OO、Microservice方面的心得，如果你有这方面的心得和困惑也可以与我交流，分享是技术人成长的很重要的途径。 近期，我换了工作，加入了网易蜂巢团队。以前上研究生的时候就搞云计算，想不到时隔两年之后，又加入了云计算的浪潮之中，也算是殊途同归。]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper:distributed process coordination中文版]]></title>
    <url>%2F2016%2F08%2F02%2FZookeeper-distributed-process-coordination%2F</url>
    <content type="text"><![CDATA[最近使用zookeeper比较多，但是国内关于zookeeper方面的数据太少。能介绍其使用同时也讲解原理的书太少了。Zookeeper:distributed process coordination是一本关于zookeeper不可多得的好书。读完以后我对zookeeper有能一个非常直观的了解。 现在分布式应用开发越来越常见，基本上大部分的分布式应用都需要与其它应用进行协同。Zookeeper非常擅长于处理分布式协同。所以我决定利用工作之余的时间翻译这本书籍，完全出于个人兴趣。 GitBook阅读地址 GitHub阅读地址 由于本人第一次翻译技术书籍，肯定会有很多翻译不当的地方，欢迎大家能及时指正。如果有对本书翻译有兴趣的小伙伴，可以通过以下方式参与贡献： 参与讨论：邮件列表：&#x7a;&#107;&#95;&#116;&#114;&#x61;&#x6e;&#x73;&#108;&#x61;&#x74;&#111;&#x72;&#x40;&#x67;&#114;&#111;&#117;&#x70;&#x73;&#46;&#49;&#x36;&#x33;&#46;&#x63;&#111;&#109;，申请加入地址：http://163.fm/UJNWGHS 部分贡献：通过issue进行讨论，如果通过，我会进行修改。这种方式我无法统计贡献者的名字，建议使用下面的方式参与翻译。 在 GitHub 上 fork 到自己的仓库，如 user/zookeeper-book，然后 clone 到本地，并设置用户信息。 1234$ git clone git@github.com:user/zookeeper-book.git$ cd zookeeper-book$ git config user.name "yourname"$ git config user.email "your email" 修改代码后提交，并推送到自己的仓库。 123$ #do some change on the content$ git commit -am "Fix issue #1: change helo to hello"$ git push 在 GitHub 网站上提交 pull request。定期使用项目仓库内容更新自己仓库内容。 12345$ git remote add upstream https://github.com/mymonkey110/zookeeper-book.git$ git fetch upstream$ git checkout master$ git rebase upstream/master$ git push -f origin master PS: 2016/8/15 Update: 很遗憾，因为授权的问题，不得不停止翻译的工作。本书已经有中文版的译本了，我后来才得知，所以我也不会取得中文版的翻译授权了。因为本人第一次翻译，事先没有搞清这些事情，才导致了现在的情况。不得不说，十分遗憾，感谢关注本书翻译的伙伴。我相信已有的中文译本应该还不错，如果需要的伙伴可以去购买。So, that’s it, it’s over, thanks for your attention.]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让百度索引你的github的博客]]></title>
    <url>%2F2016%2F06%2F23%2F%E8%AE%A9%E7%99%BE%E5%BA%A6%E7%B4%A2%E5%BC%95%E4%BD%A0%E7%9A%84github%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[不知不觉中，写博客是一件很潮的事情，尤其是程序员。自然，我也是其中的一员。博客无非两种类型，一种是动态类型的，以Wordpress为代表；另外一种则是存静态的，以Hexo, Jekyll为代表。现在，程序员都喜欢把博客托管在github上。一来省去了买虚拟主机的费用，二来可以通过git工具来管理博客，用起来十分方便。我的博客就是用hexo搭建的。 首先，github是不支持动态博客的，它只能托管存静态的网页，也就是说你只能放置一些html,js,css,jpg,png…之类的静态文件。其次，github屏蔽了百度的爬虫，也就是说百度不能索引你的博客内容。虽说程序员基本上都用google，但是你肯定还是想能被百度搜索到的。想知道自己的博客是否被索引可以这样查询，在搜索引擎中输入：site: 你的博客域名。 解决github屏蔽百度爬虫的思路就是“迁出”我们的博客，让百度爬虫不直接访问github就行了。 方案一：利用CDN制作镜像网站我们知道cdn能缓存静态资源，如果我们利用cdn制作我们的镜像网站，再将百度索引的解析cdn上，那么爬虫就不会访问github服务器了，而是访问cdn缓存服务器。国内最火的cdn服务商就是七牛和又拍云了。我发现七牛不支持自动回源功能，而又拍云在这方面做得比较好，我们可以使用又拍云来做为我们博客的镜像网站。 我以本站为例，讲一下配置的流程： 1. 创建服务 2. 配置回源 3. 绑定域名完成上面的操作后，又拍云会自动分配一个域名给我。此时，我们就需要绑定自己的域名。添加需要绑定的域名： 如果你希望博客能以www的方式来访问，那你还需要添加www的二级域名 4. 配置解析添加完域名绑定后，此时我们就只需要配置dns解析到又拍云了。我使用的是阿里云的域名系统，下图就是我设置的域名解析配置。 因为github在国外访问速度还是很快的，所以对于海外的用户直接访问github就可以了，不用再访问又拍云了。添加解析后一般需要几分钟才生效，看自己添加的域名dns解析生效了没有可以使用nslookup命令： 123456789~/blog ᐅ nslookup michael-j.netServer: 192.168.199.2Address: 192.168.199.2#53Non-authoritative answer:michael-j.net canonical name = mj-blog.b0.aicdn.com.mj-blog.b0.aicdn.com canonical name = ctn.b9.aicdn.com.Name: ctn.b9.aicdn.comAddress: 183.134.101.194 此时，我发现michael-j.net的域名已经成功解析到了又拍云。 完成 完成以上步骤后，你会收到又拍云发给你关于域名绑定通过的邮件。此时你就可以在浏览器中访问你的博客啦！ 最关键的问题是，我们要验证百度是否能正常的抓取我们的博客？ 我们使用百度站长的测试工具来测试一下： 哈哈，现在百度终于可以正常爬去我们的网站啦，接下来就是耐心的等待了，一般最多七天百度就会收录了。 方案二：自己托管博客与利用cdn来制作镜像网站的思路一样，我们完全可以把博客托管在自己的服务器上，当然你得掏银子啦！💰 我个人觉得自己买一台属于自己的虚拟主机还是值得投入了，除了博客外你可以利用这台机器做很多事情，最低配的ecs也花不了多少钱，可以几个人合用一台。 Nginx是世界有名的反向代理服务器，同时它对静态文件的支持非常好，性能很高。我们完全可以利用Nginx来作我们博客的服务器。 1. 安装NginxUbuntu\Debian：apt-get install nginx Centos\Redhat: yum install nginx 其他系统自行google 2. 配置Nginx在/etc/nginx/conf.d新作配置，一定要以.conf结尾。我新建名为michael-j.net.conf的配置文件： 1234567891011server &#123; listen 80; server_name michael-j.net; location / &#123; root /home/michael/mymonkey110.github.io; index index.html; &#125; access_log /var/log/nginx/michael-j.access.log;&#125; 注意root是我们博客的目录，后面会提到。 3. 重启nginx执行nginx -s reload生效 4. 自动下载博客内容我希望每次博客仓库有更新的时候能自动重建本地仓库，为此我专门写了一个工具git-watcher: https://github.com/mymonkey110/git-watcher。当有新的内容push到你的仓库是，它会自动拉去并重建本地仓库。基本原理就是利用github的webhook功能，当有新的push事件发生时，github会发布相应的事件到指定的接口。git-watcher监听push事件，当接受到push事件去pull仓库。如果你觉得这个工具有点儿意思，Please star it. 4.1 安装git-watcher &amp; gitpip install git-watcher apt-get install git 4.2 启动git-watchergit-watcher -u https://github.com/mymonkey110/mymonkey110.github.io.git -s 654321 -u参数配置我们的博客仓库地址 -s参数是我们webhook的secret key git-watcher还支持其他一些参数配置，-h见说明 4.3 配置dns解析将默认的dns解析到我们自己的主机上 4.4 配置webhook进入仓库的settings －&gt; Webhooks &amp; services 设置：Payload URL，这里输入我们主机的地址，这里只能用ip地址。同时，还要设置Secret，这个是用来签名body内容用的，一定要与git-watcher中配置一致 注意，我们只选择发送push事件就可以了。 4.5 测试我们进行一些修改，然后push到博客的仓库，检测一下网站内容是否更新。如果正常更新，那说明已经大功告成了。这是可以再用百度的抓取工具进行诊断。 总结解决百度抓取github内容的问题基本思路都是让百度不直接访问Github，而是通过一个中间服务器来缓存内容。两种方式都需要付费，相对来说使用又拍云搭建镜像服务器在流量较小的情况下比较有优势，速度快，费用少；而自己租用主机在博客流量较大的时候比较经济，你可以选择按带宽计费的方式，同时你还获得了一台完全由你控制的主机，何乐而不为呢？！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客域名更新：michael-j.net]]></title>
    <url>%2F2016%2F06%2F17%2F%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[由于备案原因😢，弃用老的域名michael-j.xyz,正式修改为： http://michael-j.net 本博客主要纪录本人对技术、管理、生活的一些感悟。技术人一定要有沉淀，写博客是一个非常好的方式，我也经常鼓励团队中其他人写博客，记录自己的成长。 喜欢本站内容的同学可以加入收藏哦，也支持rss订阅！😊]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常的选择：Checked Exception还是Unchecked Exception ?]]></title>
    <url>%2F2016%2F06%2F07%2FJava%E5%BC%82%E5%B8%B8%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[曾经听到过关于老司机和新手程序员的区别，其中最大的一个区别就在于异常的处理。新手程序员总是天真得把世界想得太美好，基本上没想过会出现异常的情况，而一个经验丰富的老司机会把最坏的打算考虑进去，给出相应的解决办法，使得发生异常时对系统的影响降低到最小。对此，我深表认同。现实的情况总是复杂的，而且还有很多不怀好意的人时刻准备攻击你的系统。使用你系统的用户越多，这种潜在的风险也就越大。 异常处理是应对这些风险的最强有力的武器。在Java的世界里，异常有两种：受检异常(checked exception)和非受检异常（unchecked exception）。想必所有的Javaer都使用过这两种异常，但是何时使用哪个异常缺失经常困扰程序员的头疼问题。在此，我分享一下自己的看法，如果你有不同的意见，请留意探讨。 1.如果正常情况下会出现，那么使用Checked Exception；反之，则使用Unchecked Exception这条准则是我在决定使用Checked Exception还是Unchecked Exception的第一原则。如果API的使用者在正常使用的过程中都会出现异常，那么这种异常就属于Checked Exception。因为这种异常时属于程序执行流程众多分支之一，API的使用者必须意识到这种情况，并做出相应的处理。 举个栗子： 我希望向zookeeper中创建一个节点，那么这种情况就隐含了两个前提条件： 父节点已经被创建（如果有的话） 本节点还未被创建 那么，这个API的签名大致应该是这样： 1void createNode(String path,byte[] data) throws FatherNodeNotExist, NodeExist; API的使用者看到这个签名的定义时就会得到一个强烈的心理暗示，我需要考虑父节点不存在和本节点已存在的情况，那么他就不得不显示的去处理这两种异常。 有的朋友可能会争论说，我正常的情况下不会出现这种情况，因为使用这个API的前提就是先创建好父节点，而后创建本节点，那我就不用抛出两种异常了，使用者也轻松了许多。但事实真的如此吗？我们想当然的认为了使用者是自己人，他们会乖乖的按照我们的想法去先创建父节点，再创建本节点，如果是在一个很局限的使用场景下，每个人都说经过严格培训的，那么你可以去做这样的假设，但是我还是不推荐你这么做，因为这样设计使得系统是脆弱的，不稳定的。如果能通过系统能自己避免这些错误，为什么不呢？况且，如果你把这个API开放给第三方的使用者，那么情况会更糟糕，你根本不知道他们会怎样去使用API，这非常恐怖！ 有时候情况会变得很复杂，正常情况的鉴定变得很困难，你肯定会遇到这种时候，此时就需要结合你的业务场景去权衡其中的利弊。这依赖与你的经验和对业务场景的理解，我无法给你一个绝对的建议，那样是不负责任的。 我再举个常见的栗子：用户修改他拥有的资源信息。在菜谱APP中给出一个接口，让用户修改他菜谱的信息。那么这里一个隐含的条件就是用户修改他自己的菜谱信息，他是无权限修改别人的菜谱信息的。那么这个API的签名可能是这样的： 1void updateMenu(long menuId,long uid,String title,String description...); 如果用户尝试去修改不属于他的菜谱呢？我们是否需要throws UserPermissionException之类受检异常？我认为是不需要的。判断是这属于正常情况吗？我认为这不算是正常情况。正常情况下，客户端调用修改信息的接口，那么menuId一定是属于这个用户的。如果出现这种情况，要么是你系统设计的就有问题，要么就是不怀好意的人在破坏你的系统。前者需要重新设计我们的系统，而后者我们更不用关系，直接抛出一个RuntimeException就可以，因为他不算正常用户。 2. 调用者中能从异常中恢复的，推荐使用受检异常；反之，则使用非受检异常注意这里的一个关键词是推荐，决定使用哪种异常最为根本的还是第一条原则。如果第一条原则难以判断时，才考虑调用者。这条原则和Effective Java中的第58条很像，如果有这本书的朋友可以再拿出来读读。 我和Effective Java#58不同的观点在于，这条原则只能是推荐，另外，对于所有不能恢复的情况我都建议使用非受检异常。我对可恢复的理解是，如果API的调用者能够处理你抛出的异常，并给出积极的响应和反馈，并指导它的使用者做出调整，那么这就是可恢复的。不可恢复就是API的调用者无法处理你抛出的异常，或者仅仅只是打个LOG记录一下，不能对它的使用者做出提示，那么都可认为是不可恢复的。 还是最开始的栗子，如果调用createNode的调用者能响应FatherNodeNotExist，并把这种情况反应到终端上，那么使用受检异常是有积极意义的。对于不可恢复的情况，包括编程错误，我建议都是用非受检异常，这样系统能fail fast，把异常对系统的影响降到最低，同时你还能获得一个完整的异常堆栈信息，何乐而不为呢？！ 基本上，这两条原则就能帮你决定到底是使用受检异常还是非受检异常了。当然，现实的情况很复杂，需要根据你所处的具体业务场景来判断，经验也是不可或缺的。在设计API的时候多问下自己这是正常情况下出现的吗，调用者可以处理这个异常吗，这会很有帮助的！ 异常处理是一个非常大的话题，除了选择checked exception还是unchecked exception以外，还有一些一般的通用原装，例如： 只抛出与自己有关的异常 封装底层异常 尽量在抛出异常的同时多携带上下文信息 这些在Effective Java中都有详细的介绍，朋友可以认真读一下这本书，写的非常好！ 对异常处理有不同理解的朋友可以给我留言，一起讨论，共同进步！ 参考文献： Effective Java, 2nd Edition.pdf)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防范xss的正确姿势]]></title>
    <url>%2F2016%2F04%2F12%2F%E9%98%B2%E8%8C%83xss%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[xss攻击是web攻击中非常常见的一种攻击手段。如果你还没有听说过xss攻击，可以先了解xss的相关知识和原理，例如:https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)。 防范xss攻击的方式也十分简单：转义！ 但是转义的时机？是在持久化之前转义呢，还是读数据之后escape呢？ 我开始想也没想就选择了第一种方式，因为这种方法看上去一劳永逸，但是我现在越来越倾向于第二种方式。 实际上选择第一种还是第二种需要根据你的实际情况来定。我们知道xss攻击是一种web攻击手段，它的运行环境是在用户的浏览器中，也就是说用户的运行环境是不可控的。那么在持久化之前进行转义看上去似乎不错，因为我们可以利用filter或者interceptor拦截所有的写入请求，统一进行转义。这样一来，我们的业务逻辑就完全不需要care转义的问题了，因为我们取到的数据已经都是转义的过的了。 如果用户的终端是可控的，比如：Native App，那么入库之前进行转义就显得多此一举，因为所有的输出方式都是在我们的App中展现的，自然也就不会出现了xss攻击的问题了。例如用户在评论中输入了&lt;哈哈&gt;，你觉得用户希望输出&amp;lt;哈哈&amp;gt;，还是&lt;哈哈&gt;呢？ 结果是显而易见的。 现实的情况往往是复杂的，不会只有黑和白、0与1、native和web，更多的是它们交织在一起，互相入侵对方的领域。基本上现在大部分的App都有分享功能，那么恶意的用户完全可以在评论中插入注入代码，再将该评论分享出去，那么其它被分享的用户就有被攻击的风险。解决的方法就是针对分享的数据进行全局转义，事实上已经很多模版系统已经帮我们考虑了这部分问题，例如Django和Jinja2的模版就是默认开启自动转义的。如果是前后端分离的场景，也可以有前端来进行escape。 我推荐使用“入库不转义读转义”还有一个原因，那就是前期转义格式的不确定性和后期输出的多样性。如果你正在正在开发一个rest服务器，你与App使用json格式通信。为了简单，在开始业务代码前，你对所有输入数据按照html格式进行转义。那么你可以十分放心分享出去的数据是安全的，因为所有的数据在持久化之前就已经转义了，同时你会痛苦unescape给App的数据。如果那天老板要求你以xml的格式输出这些数据（可能是其它系统的输入要求，也可能是打印报表），那么你会更加痛苦。因为xml和html的转义字符还是有些不同的，你不得不先unescape回原始数据然后再按照xml的格式escape一次。如果这样你觉得都还ok，那么我开始有点佩服你了。如果老板还要求你有更多的输出格式，那么你会更加痛苦，这还是在没有考虑输入格式变化的情况下。因为一个转义的问题导致逻辑变得复杂，影响系统的稳定性是得不偿失的。 最后，我总结一下这两种方式的优缺点： 转义方式 优点 缺点 入库前转义 一劳永逸 需要针对多端进行不同的输出，灵活性不足，无法应对后期数据格式的变化 读取前转义 简单，灵活，能应对各种数据格式的场景 需要对每个输出数据转义，人工处理容易遗漏 本人推荐第二种方式来防范xss攻击。虽然需要对每个输出数据都进行转义，但是如果你使用带自动转义的模版或者框架来处理的话，那么就可以极大的提高效率，又可以规避安全的问题。最后还是要提醒大家，安全无小事，即使你觉得没有人会攻击的系统，还是要规避这些风险，安全是系统的基石。 参考文献： Why escape-on-input is a bad idea When do you escape your data?]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下拳皇97黑屏问题的解决方法]]></title>
    <url>%2F2016%2F03%2F18%2FMac%E4%B8%8B%E6%8B%B3%E7%9A%8797%E9%BB%91%E5%B1%8F%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用Mac系统很久了，渐渐的已经依赖上了这个系统。虽然Mac OS能让我们更加关注于工作，但是偶尔我们还是希望能小小的娱乐一把。我就比较喜欢玩一些小游戏，比如拳皇97。 拳皇街机系列满载的我们80后慢慢的回忆啊！想玩97的朋友可以去：http://www.pc6.com/mac/112306.html下载。 按照提示方法，我发现运行一直是黑屏状态，十分蛋疼。Google了一番后最终找到了解决方法： 打开MAME的Preference -&gt; 切换到Video -&gt; Rendering Option中的Render frames using切换到 OpenGL模式 重新载入游戏就大功告成啦！！！ 祝大家游戏愉快～ 还搞不定可以参考下面这篇帖子👇： https://www.reddit.com/r/mac/comments/3nr2gr/mame_135_on_el_capitan_loads_black_screen_when/]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现领域事件]]></title>
    <url>%2F2016%2F01%2F19%2F%E5%AE%9E%E7%8E%B0%E9%A2%86%E5%9F%9F%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[当你的系统或者业务变得日益复杂时，DDD的模式是一种非常值得尝试的架构模式。DDD让你更加关注于你的业务领域，思考你的业务模型，帮组你理清繁杂的业务关系。我推荐所有还没有了解过或者接触过DDD的后端工程师都去学习一下该架构模式。本文主要关注DDD中的领域事件，以及一种可能的实践方式。 我们知道领域模型的变化会产生领域事件。例如，用户在完成注册后，系统会发出一封带有确认信息的邮件到用户的邮箱；用户关注的好友发送动态后他会收到相应的通知等等。在业务比较简单或者不用考虑性能的情况下，我们可以直接把对领域事件的处理嵌入到领域服务中。考虑这样一个场景：用户回复了某条评论，那么被回复的那个用户（也就是那条评论的所有者）需要收到一个PUSH消息。这个场景比较简单，我们可能直接写出类似下面的代码： 1234 void reply(long fromUserId,long toUserId,String content) &#123; saveReply(fromUserId,toUserId,content); sendPush(toUserId,content); &#125; 这样一来，我们就直接把发送PUSH的动作嵌入到了回复的逻辑中。这样做有以下两个问题： 回复动作处理了它不关心的逻辑。发送PUSH不是回复的强关联逻辑，也就是说即使push发送不成功也应该让回复动作成功。上面的代码将回复和发送PUSH耦合在了一起。 如果出现了多个对回复动作感兴趣的业务方，那么上面的代码将不可维护。比如，我们有一个回复的计数器，它要统计回复的总量。如果把增加计数器的动作写在回复中，那么将不可维护，因为每次出现新的业务方都要修改回复逻辑。这显然返回了开闭原则。 解决上诉问题的方法很简单，就是使用领域事件。领域事件很好理解，说白了就是与领域相关的事件。事件的产生往往伴随着相应的动作，例如上面所提到的回复动作。有了领域事件，每个领域本身就只需要关系其自己的业务逻辑，并在处理完自身逻辑的同时抛出相应的领域事件。对这些领域事件感兴趣的业务方可以订阅该事件，然后进行后续的处理。这与观察者模式和发布订阅模式是十分相像的。我更倾向于发布订阅这个词，它更好的表达了发布者和订阅者的一种解耦。 发布订阅模式有很多种的实现，有很多开源框架和类库也实现了这种模式。例如Spring中的事件，Guava中的EventBus都是很好的实践。直接采用这些工具会有两个问题： 无法灵活的处理同步事件和异步事件。Spring框架自带的事件机制是同步的，那么领域事件的发布者的执行流程就和订阅者的处理流程在一个调用堆栈中了，在某些情况下这事不可接收的。EventBus是支持同步和异步两种模式的，但是它要求在初始化时就指定好事件是同步的还是异步的，这对于使用方不够灵活。 订阅方无法控制事件的订阅与取消。出于解耦和灵活性的考虑，我们往往把事件注册的动作放倒订阅方。Spring框架让这种订阅关系变得模糊，因为事件的注册是通过事件ApplicationListener接口完成的，那么订阅方就无法获得事件发布者的引用，进而无法取消事件的订阅。当然，取消事件订阅的情景并不常见，所以这种情况在大部分场景下也是可以接受的。 无论是出于对事件发送同步异步的控制，还是处于订阅方更高的灵活性要求，自己在这些框架和工具上再进行封装都还是要必要的。下面我给出我的一种实践方案。 我推荐在guava的EventBus上面进行封装，因为它已经实现了同步和异步的模式，并且使用注解的订阅方式对程序员也十分友好。 首先，我们需要定义一个领域事件的抽象基类。 这个抽血基类中定义了发生时间和identify的一个抽象方法，该方法用来标示事件。下面我们就可以定义领域事件的发布器了，如下图所示。 我先定义了领域发布器的一个通用接口，主要包括四个方法： identify() 发布器标示，用来区分不同的发布器。 register(Object) 注册接口，订阅方调用该接口来订阅事件。 publish(T event) 同步发布事件接口 asyncPublish(T event) 异步发布事件接口 同时，我给出了一个基于Guava的实现，如下： 12345678910111213141516171819202122232425/** * Guava事件发布器实现 * Created by Michael Jiang on 16/1/12. */public abstract class GuavaDomainEventPublisher implements DomainEventPublisher &#123; private EventBus syncBus = new EventBus(identify()); private EventBus asyncBus = new AsyncEventBus(identify(), Executors.newFixedThreadPool(1)); @Override public void register(Object listener) &#123; syncBus.register(listener); asyncBus.register(listener); &#125; @Override public void publish(DomainEvent event) &#123; syncBus.post(event); &#125; @Override public void asyncPublish(DomainEvent event) &#123; asyncBus.post(event); &#125;&#125; 我在实现中初始化了两个eventBus，一个是同步的syncBus，用于发布同步事件；另外一个是异步的asyncBus，用于发布异步事件。其中我将异步线程池硬编码为1个线程，基本满足大部分情况，也可酌情修改或者开放这个参数，有各个领域事件的发布器来实现。 具体的领域事件发布器直接继承GuavaDomainEventPublisher，并覆盖identify()方法后就可以使用了。 这里我并没有专门去设计订阅方，因为Guava提供的注解方式已经十分方便了。我设计了一个简单的demo放倒了github上面，有兴趣的朋友可以直接查看源代码。如果你有更好的设计方法或者思路，可以直接留言进行讨论。 Demo地址：https://github.com/mymonkey110/event-light]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>领域事件</tag>
        <tag>event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[评论设计]]></title>
    <url>%2F2016%2F01%2F05%2F%E8%AF%84%E8%AE%BA%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[本文主要分享了我在设计评论模块中的一些心得，希望对读者有些许帮助。 需求分析现阶段评论做的最好的我想应该是网易新闻（app）里面的评论模块了，其“盖楼”的方式让人印象深刻，评论已经成为该app的核心功能之一了。市面上大部分app的评论模块设计的还是相对简单的，这是可以理解的，因为评论模块不是这些app的核心功能之一。 在设计评论模块前可以和pd或者boss沟通，我们的评论功能是核心功能之一吗？实际上，90%的app采用简单的评论设计就可以了，也就是采用一问一答，类似于如下的设计。 这种设计十分简单、直接，也满足了用户评论、回复的基本要求，对于没有大量用户评论或者评论不是核心功能的app来说就够用了。暂且把这种场景称之为场景A。 如果你是新闻类或者咨询类的app，有着大量的用户评论，那么设计“盖楼”的效果还是可取的，这样能帮助用户找到该条评论或者回复的上下文情景。但是根据“盖楼”的显示效果不同，设计上也是有很大的差别的。如果是以评论为主的显示方式，类似于下面的显示方式。 这里可以把评论分为评论和回复，所有的回复均挂在评论下面，类似于树状结构。把这种场景称之为场景B 最后就是类似于网易新闻的评论设计了，贴一张截图 这种场景下设计最为复杂，因为回复和评论是同等级的，回复还可以引用完整的回复路径，就是可以溯源到最开始的评论上。这种场景我将至称为场景C。 数据库设计由于我 一直使用mysql，我就以mysql为例谈一下针对上面三种场景的设计。 场景A这种场景下一般评论数量较少，评论不为活跃，可以把不区分评论和回复，而统一看成评论。区别在于有的评论是直接评论主题(每个评论都挂在某个主题下，如文章、帖子等)，而有些评论是@其他用户的，为了能cover这两张场景，使用一张表就可以达到效果，评论表如下设计： 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id to_uid 评论目标用户id 为了能复用评论模块，我们引入一个topic_type字段来区分主题的类别。 from_uid表示评论人的id，通过该id我们可以检索到评论人的相关信息。 to_uid 是评论目标人的id，如果没有目标人，则该字段为空。 出于性能的考虑，往往我们会冗余评人的相关信息到评论表中，比如评论人的nick、头像等，目标用户也是如此。这样一来我们就只用查询单表就可以达到显示的效果。 有时，目标用户有多个，那么可以将to_uid字段修改为to_uids，保存时用分隔符来分割用户id，而目标用户的信息再去查询缓存或者数据库。也可以简单的将多个目标用户的信息一起存成json格式，可以应付简单的展现需求。 场景B在以评论为主的树形显示的情况下，数据库的设计十分灵活，可以使用单表，添加一个parent_id字段来指向父评论。如果数据库本身支持嵌套查询，那么还是比较方便的，SqlServer、Oracle都支持，但是mysql不支持，那就只能通过存储过程来实现。在互联网应用中，能不使用触发器 ｀存储过程`的话，尽量不要去使用，因为其对性能有影响。 我们还可以将评论拆分为评论表 和 回复表，评论挂在各种主题下面，而回复都挂在评论下面。 评论表的设计如下： 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id 回复表的设计如下： 表字段 字段说明 id 主键 comment_id 评论ID reply_id 回复目标id reply_type 回复类型 content 回复内容 from_uid 回复用户id to_uid 目标用户id 由于我们拆分了评论和回复，那么评论表就不再需要目标用户字段了，因为评论均是用户对主题的评论，评论表的设计更佳简洁了。 回复表我添加了一个comment_id字段来表示该回复挂在的根评论id，这样设计也是出于性能方面的考虑，我们可以直接通过评论id一次性的捞出该评论下的所有回复，然后通过程序来编排回复的显示结构。通过适当的冗余来提高性能也是常用的优化手段之一。这里给出一段我通过来评论id来查找并组织所有回复的代码： 1234567891011121314151617181920212223242526272829303132333435public List&lt;ReplyDTO&gt; getReplyListByRid(Long rid) &#123;List&lt;ReplyDO&gt; replyDOList = replyDAO.queryReplyByCid(rid); if (replyDOList == null || replyDOList.size() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;ReplyDTO&gt; replyDTOList = new ArrayList&lt;&gt;(); List&lt;ReplyDTO&gt; parentList = new ArrayList&lt;&gt;(); for (ReplyDO replyDO : replyDOList) &#123; ReplyDTO replyDTO = convertReplyToDTO(replyDO); if (replyDTO.getReplyType() == ReplyType.COMMENT) &#123; replyDTOList.add(replyDTO); parentList.add(replyDTO); &#125; else &#123; boolean foundParent = false; if (replyDTOList.size() &gt; 0) &#123; for (ReplyDTO parent : parentList) &#123; if (parent.getId().equals(replyDTO.getReplyId())) &#123; if (parent.getNext() == null) &#123; parent.setNext(new ArrayList&lt;ReplyDTO&gt;()); &#125; parent.getNext().add(replyDTO); parentList.add(replyDTO); foundParent = true; break; &#125; &#125; &#125; if (!foundParent) &#123; throw new RuntimeException("sort reply error,should not go here."); &#125; &#125; &#125; return replyDTOList; &#125; reply_type表示回复的类型，因为回复可以是针对评论的回复(comment)，也可以是针对回复的回复(reply)， 通过这个字段来区分两种情景。 reply_id表示回复目标的id，如果reply_type是comment的话，那么reply_id＝commit_id，如果reply_type是reply的话，这表示这条回复的父回复。 在数据结构的设计上，我在replyDTO中设计了一个List&lt;ReplyDTO&gt; next属性，这样在形成了一个树形的结构，类似如下结构。 客户端可以直接根据该结构来进行树形结构的显示。 场景c要达到网易新闻中评论的效果我还没有特别好的建议。这种场景中评论和回复是同级显示的，回复不在显示结构上不用挂在一个评论下面。双表的设计在这里就不太合适了，因为涉及到评论和回复的混排，使用双表则会导致查询的逻辑过于复杂。所以建议还是采用单表的设计，不区分评论和回复会简化应用层的逻辑。我们统一都看成评论，而有些评论是可以引用其他评论的。本人推荐采用闭包表的设计，例如： comment表设计 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id parent_children表 表字段 字段说明 id 主键 parent_id 父id child_id 子id comment表保存所有评论内容，而parent_children表则记录评论表中各个评论的父子关系。 查询时往往会按照时间排序，我们可以直接按id或者创建时间降序排列查询comment表即可。如果用户想查询一条评论的完整引用，则可以通过parent_children来找到对应的路径。向上查找到评论只需要可执行： select parent_id from parent_children where child_id=${id} and parent_id != ${id} 向下查找所有的子孙评论可执行： select child_id from parent_children where parent_id = ${id} and parent_id != ${id} 闭包表在查询时非常方便，但是插入的性能稍差，因为除了插入评论表以外，还需要把该条评论所有的父子关系插入到父子关系表中。插入性能会随着评论层级的加深而线性下降。 海量数据优化如果你的系统每天都会有成千上万条评论，那么单表的设计肯定是不行，优化的方式也有很多。 分库分表。分库分表是最为常用也最有效的优化方式，建议按照主题来分库分表。这样同一个主题下面的评论就会落到同一张表里，避免了跨表查询。 适当的数据冗余。如果你需要显示评论人的相关信息，那么在插入评论时就把这些信息写入评论表中，避免多次查询。实际上，如果是纪录数据，都可以冗余对应的数据信息，因为它们的数据的实时行和一致性要求并不高，用户不会因为评论中的头像没更新而撕了你，哈哈。 附加幂等数据只允许单项操作。如果pd要求你能给评论点赞，那么你可以告诉他只能点赞，不能取消。因为从幂等性的要求来说，每个赞都是一条记录。评论的赞数如果都从点赞表中统计得出，那么性能开销会十分巨大，而且点赞如此轻量级的一个操作一定会加剧点赞表的竞争操作。所以建议直接在评论表中添加一个like_count的计数器，该字段只增不减。 热门评论加缓存。类似于网易新闻的热门评论，读取频度非常高，可以专门开接口给客户端，同时该接口做缓存。 参考文献： 逻辑数据库设计 - 单纯的树(递归关系数据) 在数据库中存储层级结构 What are the Options for Storing Hierarchical Data in a Relational Database]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>评论系统</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Debug:Tomcat deploy twice]]></title>
    <url>%2F2015%2F10%2F30%2FTomcat%20deploy%20twice%2F</url>
    <content type="text"><![CDATA[最近写了一个分布式时间调度系统，用于调度集群类的定时任务程序。架构如下： 有一个集中化的Scheduler来调度集群中所有的job,集群中的job只负责实现具体job内容，而Trigger的定义和管理均在Scheduler中实现。Trigger通过MQ将触发消息发送到集群中的某台机器上。 在部署Scheduler的过程中观察日志如下出现以下奇怪的现象： 我们发现在同一时刻Scheduler对一个Job触发了两次，而在集群的某台机器上发现一个Job被触发了4次： 当我在自己的机器上始终无法复现该问题。由于是同一个war包，故排出了代码的问题。不同之处在于，我本机启动的方式是用jetty的插件直接启动的，而服务器上则是用的是tomcat容器。经过一番排查发现，是tomcat重复部署的问题，tomcat的官方文档有如下说明: Any Context Descriptors will be deployed first. 因为我想讲应用直接部署在/下，所以在server.xml中的localhost节点下加入了context的配置。根据tomcat的官方文档，如果host下面有context的配置则会先部署，而后容器再部署一次。也就是说，应用被部署了两次。这也就解释了为什么scheduler会触发两次，而job会触发4次了。 解决的方法是将deployOnStart设置为false，autoDeploy设置为false。 参考： http://stackoverflow.com/questions/7223108/quartz-job-runs-twice-when-deployed-on-tomcat-6-ubuntu-10-04lts]]></content>
      <categories>
        <category>踩过的那些坑</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>tomcat</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btrace Sample Scripts]]></title>
    <url>%2F2015%2F10%2F19%2FDebug-Tomcat-deploy-twice%2F</url>
    <content type="text"><![CDATA[Btrace is very powerful tool for online debugging, here is the sample scripts in tar btrace. The scripts are very useful, so I decide to upload them. Here is the scripts below: AWTEventTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AWTEventTracer.java AllCalls1.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls1.java AllCalls1Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls1Sampled.java AllCalls2.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls2.java AllCalls2Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls2Sampled.java AllCalls3.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls3.java AllCalls3Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls3Sampled.java AllLines.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllLines.java AllMethods.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllMethods.java AllMethodsSampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllMethodsSampled.java AllSync.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllSync.java ArgArray.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ArgArray.java Classload.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Classload.java CommandArg.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-CommandArg.java DTraceInline.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-DTraceInline.java DTraceRefDemo.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-DTraceRefDemo.java Deadlock.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Deadlock.java FileTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-FileTracker.java FinalizeTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-FinalizeTracker.java HistoOnEvent.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-HistoOnEvent.java Histogram.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Histogram.java HistogramBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-HistogramBean.java JInfo.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JInfo.java JMap.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JMap.java JStack.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JStack.java JdbcQueries.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JdbcQueries.java LogTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-LogTracer.java MemAlerter.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-MemAlerter.java Memory.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Memory.java MultiClass.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-MultiClass.java NewArray.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-NewArray.java NewComponent.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-NewComponent.java OnThrow.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-OnThrow.java ProbeExit.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ProbeExit.java Profiling.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Profiling.java Sizeof.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Sizeof.java SocketTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SocketTracker.java SocketTracker1.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SocketTracker1.java SubtypeTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SubtypeTracer.java SysProp.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SysProp.java Test.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Test.java ThreadBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadBean.java ThreadCounter.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadCounter.java ThreadCounterBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadCounterBean.java ThreadStart.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadStart.java Timers.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Timers.java URLTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-URLTracker.java WebServiceTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-WebServiceTracker.java You can access them with curl or wget, wish you happy debugging!]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Autoconfig打包Java WEB应用]]></title>
    <url>%2F2015%2F10%2F17%2F%E5%88%A9%E7%94%A8Autoconfig%E6%89%93%E5%8C%85Java-WEB%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介： 本文主要介绍常用的后台应用打包的几种方式 后端应用上线前都需要经过重新打包，可千万别小看了这个阶段，这个是非常非常重要的！如果打错了包或者使用错了配置文件，结果可能是毁灭性的！ 我们都知道每个软件项目或者公司都会维护几套隔离环境，例如以前在阿里就会有日常测试、日常、预发和线上几个环境，还有根据特殊需要配置的独立环境，如性能环境等等。 当然，对于小公司或者创业公司来说不需要准备这么多套环境，但至少是需要测试和线上两套环境的。多套环境的可以有效的隔离线上和线下，提高开发人员的工作效率，又不至于将不稳定的代码带到线上。其中最重要的一个环节就是打包，我主要介绍两种简单的打包方式。 利用Spring配置现在Java WEB应用可以说90%都使用了Spring框架，而Spring框架早就帮我们考虑了这个问题。我一开始也是使用这个配置方式，在Spring配置文件中引入一下配置： Spring是支持classpath和file的，个人推荐使用file模式来查找外部配置文件，因为这样我们就不必将配置文件引入到工程目录中了，因为工程目录对所有的开发人员都可见，这样会降低配置文件的安全性。引入外部配置文件一个常见的做法就是使用环境变量，我们新建一个APP_HOME的环境变量来区分不同的环境。 在使用配置文件的地方利用placeholder进行配置即可，例如以下方式： 123456&lt;bean id="dataSource" class="org.apache.commons.dbcp2.BasicDataSource"&gt; &lt;property name="driverClassName" value="$&#123;db.driverClass&#125;"/&gt; &lt;property name="url" value="$&#123;db.url&#125;"/&gt; &lt;property name="username" value="$&#123;db.username&#125;"/&gt; &lt;property name="password" value="$&#123;db.password&#125;"/&gt;&lt;/bean&gt; 在Spring启动以后，它会去查找你配置的外部配置文件，并逐个替换使用的配置中的placeholder。 这种方式的优点就是简单，灵活，但是缺点也是很明显的： 只支持Spring配置文件的替换，不支持其他框架配置文件的替换。 如果你想替换logback.xml中的某个配置，例如日志输出目录或者日志输出级别，它是做不到的。 大规模部署不方便。如果只有一两机器这样部署还是比较方便的，但是如果有几十台甚至上百台这样打包就十分麻烦了。如果改动一个配置项，就需要保持所有机器的同步的，所以一般大一点的公司都会有专门负责配置的服务，例如阿里的ConfigServer。 利用AutoConfig打包AutoConfig 是阿里内部使用的一个打包工具，十分方便，也十分强大，这里有它的介绍：http://openwebx.org/docs/autoconfig.html 下面是我利用AutoConfig打包的步骤： 添加不同环境的配置 为了直接利用Maven打出不同环境的包，我们在需要打包的module的pom中添加下面的配置： 1234&lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.dev&lt;/autoconfig.properties&gt; &lt;env&gt;dev&lt;/env&gt;&lt;/properties&gt; 然后加入profile配置： 1234567891011121314151617181920212223242526&lt;profiles&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.dev&lt;/autoconfig.properties&gt; &lt;env&gt;dev&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.test&lt;/autoconfig.properties&gt; &lt;env&gt;test&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;online&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.online&lt;/autoconfig.properties&gt; &lt;env&gt;online&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 添加autoconfig maven插件支持 123456789101112131415 &lt;plugin&gt; &lt;groupId&gt;com.alibaba.citrus.tool&lt;/groupId&gt; &lt;artifactId&gt;autoconfig-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;configuration&gt; &lt;userProperties&gt;$&#123;user.home&#125;/conf/$&#123;autoconfig.properties&#125;&lt;/userProperties&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;autoconfig&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 其中,userProperties属性就是我们使用的配置文件。 利用Maven进行打包 进入到需要打包的module中，然后执行mvn package -P&lt;env&gt;，其中env代表不同的环境，在上面的配置中env只能为dev、test和online.我们可以将最终的包名也带上环境名称，以区分打出来的不同环境的包，如下配置： &lt;finalName&gt;包名-${env}&lt;/finalName&gt; Tips:如果开发人员使用的是jetty插件来进行本地开发的，那么需要将jetty:run改为jetty:run-war，因为autoconfig是需要执行package才会进行触发的，而jetty:run不会执行package阶段。可以参考一下配置： 1234567891011121314151617&lt;!-- jetty插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;7.6.16.v20140903&lt;/version&gt; &lt;configuration&gt; &lt;webAppSourceDirectory&gt;src/main/webapp&lt;/webAppSourceDirectory&gt; &lt;scanIntervalSeconds&gt;3&lt;/scanIntervalSeconds&gt; &lt;connectors&gt; &lt;connector implementation="org.eclipse.jetty.server.nio.SelectChannelConnector"&gt; &lt;port&gt;8080&lt;/port&gt; &lt;maxIdleTime&gt;60000&lt;/maxIdleTime&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;war&gt;target/包名-$&#123;env&#125;.war&lt;/war&gt; &lt;/configuration&gt; &lt;/plugin&gt;]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>package</tag>
        <tag>autoconfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java也能玩转WebSocket]]></title>
    <url>%2F2015%2F05%2F30%2FJava%E4%B9%9F%E8%83%BD%E7%8E%A9%E8%BD%ACWebSocket%2F</url>
    <content type="text"><![CDATA[本篇介绍使用Netty来实现Websocket，为实践篇，不涉及原理性讨论。 1. 什么是Websocket? WebSocket 是H5提供的一个基于TCP链接全双工的通信协议，可以简单HTTP协议的长链接升级版。 为什么要用websocket、使用websocket的好处已经websocket的原理这里就不再赘述了，上面的两篇文章都介绍的非常清楚了。 2. 准备工作 升级Nginx Nginx从1.3.13版本开始支持WebSocket协议，由于集团里面使用的是Tengine，所以需要先查看Tengine版本号。使用下面命令即可： /home/admin/cai/bin/nginx-proxy -v 执行完后发现：Tengine version: Tengine/1.4.6 (nginx/1.2.9) ，nginx版本太低。升级Tengine就行，较新的Tengine都以支持Websocket. 升级Tengine命令执行：sudo yum install -b current tengine 会安装最新版的Tengine。 安装配置的过程还是由很多坑的。 接下来就是配置nginx了，配置很简单，按照一下配置即可。 123456location /chat/ &#123; proxy_pass http://127.0.0.1:9999/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade";&#125; 如果你想更加灵活的配置可参考: http://nginx.org/en/docs/http/websocket.html 最后，重新加载nginx配置就可以了，sudo sh nginxctl reload。 升级WEB容器 这一步并不是必须的，如果你使用的Websocket的实现依赖于WEB容器，那么就必须升级WEB容器来支持。 JSR356规范制定了Websocket的标准，只要是实现了JSR356规范的容器均支持Websocket。Tomcat从7.0.47版本开始支持JSR356标准，并且要求JDK版本至少为1.7。 由于升级WEB容器带来的变化太多，本人并没有采用这种方式。 3. Java对Websocket的支持 JavaEE 7开始全面支持Websocket协议 Spring4.0才实现了JavaEE 7标准，那么如果希望Spring直接支持Websocket协议，那么必须将Spring升级到4.0以上。使用Spring框架来支持Websocket的好处就是可以使用它大量的注解和服务，而且可以很好的与现有业务相结合。 WEB容器对Websocket的支持 前面提到了JSR356标准指定了Websocket规范，在这个标准出来后很多WEB容器都纷纷实现了该标准，以支持Websocket。该阶段处于Websocket的初期，各个容器的实现方式也各不相同，如果不想升级到Spring4而又想使用Websocket，那么就可以利用容器的特性了。如果你有这方面的需求可以参考：http://blog.fens.me/java-websocket-intro 、http://redstarofsleep.iteye.com/blog/1488639 利用Netty来实现Websocket Netty是一个Java语言实现的非常高效的基于事件的网络库，感谢师兄告诉我这个框架。我也是刚接触这个框架不久，原理我就不谈了。如果你有Linux下的开发经验一定对这种框架不会陌生，这些框架的底层都经历了select\poll到epoll的转变，在Linux下有Libev\Libevent之类相似的框架，以及Node底层的Libuv也是如此，这方面的资料也是非常多的。 我们要用Netty是不仅是因为它是一个高效的网络库，而且它还是实现了很过高层的网络协议，其中就包括Websocket。Netty对Websocket有很好的支持，而且它对Websocket的处理是原生的，不依赖于底层容器，那么我们就可以在不升级底层容器已经改变Spring框架的基础上来编写基于Websocket的应用了。 4. Netty来创建Websocket链接 启动Websocket服务器 12345678910111213141516171819202122232425262728293031323334353637public class WebSocketServer &#123; private int port; private final EventLoopGroup workGroup = new NioEventLoopGroup(); @Resource private ChannelPipelineInitializer channelPipelineInitializer; private static Logger logger = LoggerFactory.getLogger(WebSocketServer.class); public void init() throws Exception &#123; InnerWebSocketServer wsServer = new InnerWebSocketServer(); new Thread(wsServer).start(); &#125; public void setPort(int port) &#123; this.port = port; &#125; class InnerWebSocketServer implements Runnable &#123; @Override public void run() &#123; try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(workGroup).channel(NioServerSocketChannel.class) .childHandler(channelPipelineInitializer); ChannelFuture future = serverBootstrap.bind(new InetSocketAddress("127.0.0.1",port)).syncUninterruptibly(); logger.info("WebSocket Server is running on " + future.channel().localAddress()); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; logger.error("Start Websocket error:&#123;&#125;.",e.getMessage(),e); &#125; finally &#123; workGroup.shutdownGracefully(); &#125; &#125; &#125; &#125; Tips:注意为了让Netty在Spring初始化的时候启动，我指定了init方法为这个bean的初始化方法。而Netty的监听方法是一个同步调用(sync方法),这会阻碍Spring继续初始化，导致初始化失败。所以我在初始化方法中启动了另外一个线程来完成WebsocketServer的初始化。 注册处理Pipeline Netty的处理请求的方式与Webx的很相似，连名字都叫Pipeline。我们先要注册一系列的Handler来完成对一个Websocket的请求的处理，类似于Spring里面Interceptor的概念。 1234567891011121314151617 @Component public class ChannelPipelineInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Resource private WebSocketFrameHandler webSocketFrameHandler; @Resource private HttpRequestHandler httpRequestHandler; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline=ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(64*1024)); pipeline.addLast(httpRequestHandler); pipeline.addLast(new WebSocketServerProtocolHandler("/ws/")); pipeline.addLast(webSocketFrameHandler); &#125;&#125; Tips:httpRequestHandler和websocketFrameHandler是自己实现的处理Handler。前者会负责对请求做一些基本校验已经获取SESSION的动作，而后者是则是消息处理的Handler，实现了各种事件的处理逻辑，也是跟业务紧密相关的地方。 实现WebSocketFrameHandler 一般情况下我们只用实现SimpleChannelInboundHandler就可以了. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 @Component @ChannelHandler.Sharable public class WebSocketFrameHandler extends SimpleChannelInboundHandler &#123; @Resource private WebSocketHandlerFactory webSocketHandlerFactory; private static Logger logger = LoggerFactory.getLogger(WebSocketFrameHandler.class); @Override @SuppressWarnings("unchecked") protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &#123; WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.read(ctx, msg); &#125; @Override @SuppressWarnings("unchecked") public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; super.channelInactive(ctx); logger.info("Client " + ctx.channel() + " disconnected!"); getWebSocketHandlerByChannel(ctx.channel()).disconnect(ctx); &#125; @Override @SuppressWarnings("unchecked") public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; super.channelActive(ctx); WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.connect(ctx); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt == WebSocketServerProtocolHandler.ServerHandshakeStateEvent.HANDSHAKE_COMPLETE) &#123; logger.info("Client " + ctx.channel() + " connected!"); &#125; &#125; @Override @SuppressWarnings("unchecked") public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; logger.error("Caught WebSocket Error,error:&#123;&#125;.", cause.getMessage(), cause.getStackTrace()); super.exceptionCaught(ctx, cause); WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.caughtException(ctx, cause); &#125; @SuppressWarnings("unchecked") private WebSocketHandler getWebSocketHandlerByChannel(Channel channel) &#123; String topic = channel.attr(WebSocketConstants.TOPIC).get(); WSTopicIdentify topicIdentify = WSTopicIdentify.getTopicFromValue(topic); if (topicIdentify == WSTopicIdentify.UNKNOWN) return null; return (WebSocketHandler&lt;ChannelHandlerContext, Object&gt;) webSocketHandlerFactory.getWebSocketHandler(topicIdentify); &#125;&#125; Tips:为了让Websocket与具体业务分离，建议对不同的业务实现自己的WebsocketHandler,而这里总的handler根据业务的标识符路由到不同的业务handler即可。 5. 让Netty更好的于业务结合 与Spring结合 由于业务上基本都是使用Spring框架，为了在Spring中使用Netty，需要将Netty的启动Server配置为一个Bean, 由Spring服务初始化。注意Netty启动会阻塞本身线程的问题。那么跟Netty相关的Pipeline子handler均要定义为bean，这样就可以使用原有的业务系统中的服务了。 按业务路由 考虑到以后会有其他业务使用Websocket的场景，那么我们必须将websocket的能力按照业务进行区分。本人的建议是从URL上来区分业务，不同的业务使用不同URL。去掉通用websocket的前缀后，根据后门的URL来区分业务。ctx.channel().attr(WebSocketConstants.TOPIC).set(msg.getUri().substring(WebSocketConstants.wsUriPrefix.length())); 建议设置一个Websocket的ENUM TOPIC，不同的业务拥有不同的TOPIC，这样就可以根据URL来区分业务了。 6. 后记 使用Netty处理websocket还是非常方便的，加上其本事强大的网络处理能力，使得上层应用无需关系底层实现。虽然和Node.js这样技术比起来还是比较笨重，但随着业务的发展，我相信Java的优势会渐渐体现出来。 使用websocket本事不难，难得是在分布式环境下使用长链接技术。其中涉及到业务状态的保存与恢复、服务器间通信的问题、停机维护的问题、状态跟踪的问题等等，如果业务比较复杂，那么异常处理的情况都会非常复杂。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Tair实现分布式并发锁]]></title>
    <url>%2F2014%2F12%2F23%2F%E5%88%A9%E7%94%A8Tair%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80%E5%B9%B6%E5%8F%91%E9%94%81%2F</url>
    <content type="text"><![CDATA[最近大量使用到了Tair来控制并发，有点心得，总结如下。 利用Tair实现全局并发锁 现在基本上线上服务器都是集群环境，那么当我们需要对中心化数据（例如:Tair、数据库）的同一内容进行读写时就会碰到并发问题，这是一种非常常见的需求。解决并发问题的方法无非有两种，在并发点控制并发或者在并发源头控制。 图画的有点丑。并发点控制最常用的一种方式就是使用锁，每个需要访问数据的线程都需要先获取锁，然后才能去访问数据库。根据获取锁的策略的不同，又可以根据不同纬度分为乐观锁、悲观锁，忙等、闲等，互斥锁、读写锁等等。 在并发源头控制就是利用第三方的工具，一般是消息队列来将并发访问串行化，然后由统一的数据操作者来访问数据。消息队列的使用不在本文的讨论范文内。比较有名的开源消息队列有,RabbitMQ,ZeroMQ。当然,公司内部也有对应的产品，如Notify,MetaQ。 由于在分布式环境中，要实现全局的并发锁，那么我们必须借助第三方的服务来进行协调。数据库和缓存经常会成为我们的优先选择。出于性能的考虑，一般选用缓存来实现全局并发锁，其中的关键也就是借助Tair的Version控制，相比已经有很多人已经在这样做了。Tair提供了以下API： ResultCode put(int namespace, Object key, Serializable value, int version, int expireTime) 利用该API实现并发控制轻而易举,伪代码如下： 1234567891011 //加锁 public boolean lock(String key, int timeOut) &#123; ResultCode rc = tairManager.put(NAMESPACE, key, DEFAULT_VALUE, INIT_VERSION, timeOut); return rc!=null&amp;&amp;ResultCode.SUCCESS.equals(rc)?true:false; &#125; //解锁 public boolean unlock(String key) &#123; ResultCode rc = tairManager.invalid(NAMESPACE, key);return rc!=null&amp;&amp;ResultCode.SUCCESS.equals(rc)?true:false; &#125; 这主要是利用了Tair的VERSION特性。如果KEY不存在的话，传入一个固定的初始化VERSION，Tair会在保存这个缓存的同时设置这个缓存的VERSION为你传入的VERSION+1；然而KEY如果已经存在，Tair会校验你传入的VERSION是否等于现在这个缓存的VERSION，如果相等则允许修改，否则将失败。 其过程如下图所示： 这是一个很通用的过程，但是却能涵盖大部分的场景。其实理解这个过程非常简单，这里可以把其想象成受精卵形成的过程。虽然有成千上万个精子会进入卵巢，但当第一个精子和卵子结合以后就会形成一层隔离层，以阻止其他精子的进入。而这里的隔离层就类似于TAIR的VERSION。如果想知道更多过程可以参考VERSION的文档。 利用Tair实现全局TOP-N并发锁 全局TOP-N并发锁是我自己想出来的一个名字，有点不明觉厉吧。实际业务中我们可能会遇到这样一种情况，在短时间内会有大量的并发来获取某种资源，但是我们这个资源又有数量限制。例如，抢火车票，在某一时刻将1000张火车票发出去，假如有大量的用户在同一时间来抢这些火车票就会形成并发，同时我们又有着很高的性能要求。以抢火车票为例，下面是我的思考过程。 因为我需要控制并发，要告诉第1001个用户你没有抢到，那么我肯定需要一个计数器来保存火车票发售的实时情况，那么很容易就写出了以下伪代码： 12345678910if(get(ticker_counter)&lt;1000)) &#123; bool lockFlag=lock(key,60); if(lockFlag) &#123; int counter=get(ticker_counter); if(++counter&lt;1000) &#123; set(ticker_counter=counter) &#125; unlock(key); &#125;&#125; 首先获取当前计数器的值，如果&gt;=1000则直接失败返回,表示已经被抢完了，但是如果&lt;1000，表示还没被抢完，则尝试去获取全局锁，如果获取成功则增加计数器的值，注意此时是需要再获取一次计数器的。但是这样会有一个明显的问题，就是当A获取了锁，正在执行增加计数器操作时，B也去尝试获取锁，此时必然是失败的。但是我现在就应该告诉他你已经失败了吗，你没有机会获得这张火车票了吗？显然不是。因为我们允许获取的资源是一个范围，那么当没有明确地表示现在资源已经超出这个返回了或者没有资源了，那么现在所有尝试得到资源的线程或者用户都是有机会的。此时，书中的一个概念浮现出来——信号量。这种业务场景正好是信号量技术能够解决的。但是在分布式环境下如何解决这个问题呢。 我想到了Linux环境下编程时的很多技术。其中就有一个很这个业务场景非常相似的API，就是POSIX系列里面的pthread_cond_wait()和pthread_cond_signal()。前者会一直阻塞直到等待的资源变为可用，而后者会唤醒一个正在等待某个资源的线程。如果有有这两个语义的API存在的话就会变得非常简单，伪代码将变为： 123456789if(get(ticker_counter)&lt;1000)) &#123; pthread_cond_wait(); int counter=get(ticker_counter); if(++counter&lt;1000) &#123; set(ticker_counter=counter) &#125; pthread_cond_signal(); &#125; &#125; 只可惜在分布式环境下没有这两个语义的API操作存在，那么久不得不转化思维。之所以我需要这两个语义的API存在是因为我希望在A线程完成工作以后，将这个状态/消息通知到其他在等待的线程，并且这些线程是分布式的。其实这里是可以使用到消息模型的。notify会选择集群中的一台服务器投递消息，这就可以作为唤醒操作。所有的worker一开始都去监听notify的消息，直到其中一个worker收到，然后去checkAndInc(counter)，最后再发出一个消息，如此循环就能达到目的。最后只需要增加一个Trigger,在最开始执行的时候直接去执行，而不用等待notify消息，就能完成完整的流程。但是，如此简单地一个功能，真的要实现的这么复杂吗？当然不行，什么时候都要坚持KISS原则。 其实，我最终的目的很简单，就是增加一个计数器的值，然后达到某一上线时希望能够得到一个错误返回。因为在做以前一个项目时使用到了Tair中计数器的功能，带着侥幸的心理重新去找Tair的API，居然发现了这个重要API: `Result&lt;Integer&gt; incr(int namespace, Serializable key, int value, int defaultValue, int expireTime, int lowBound, int upperBound)` 当我看到这个API的时候感悟良多，在此还是要感谢一下设计这个API的作者，因为这个API的设计就是为这种业务场景而生的。这个incr()操作可以指定一个范围段，如果value值不在这个范围段中就会报错。有个这个API那么伪代码就简化成以下： 12result = tairManager.incr(NAMESPACE, key, 1, 0, 60, 0, 1000); return ResultCode.SUCCESS.equals(result.getRc())? true : false 这个多么的简洁和优雅,而且又有着很高的性能。如果有着类似的业务场景，推荐大家不妨试一下这个API。 一点思考 现在分布式计算越来越受到重视，随着去IOE的深入，大型机的时代一去不复返。但是分布式计算的流行使得程序员思考问题的方式也在发生改变，以前在单机上运行很好地系统，拿到分布式环境下可能就会出现各种问题。虽然整体架构发生了很大的变化，但是单机时代的很多思想还是值得我们去借鉴的。就比如信号量计算，PV操作。以前这些技术靠操作系统去实现就好了，但是在分布式环境下就很难实现这些以前看似很自然的功能。从某种程度上，这又为我们的中间件技术指明了发展的道路。如果哪一天业务程序员能在分布式环境中像在单机环境里编程，那分布式技术的发展就达到了一个新的高度。]]></content>
      <tags>
        <tag>distributed lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#网络编程初步之TCP]]></title>
    <url>%2F2011%2F10%2F03%2FC%23%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%AD%A5%E4%B9%8BTCP%2F</url>
    <content type="text"><![CDATA[阅读背景：本文针对有C#的初学者而写的，主要讲解如何利用C#进行网络编程。如果你已经有一些网络编程的经验（只需要懂得网络编程的基本常识即可），并且理解C#的基本语法，那么这篇文章可以很快地带你进入C#网络编程的世界。如果你的基础不好，也不要紧，我相信这篇文章也会有你需要的内容。 网络编程基础复习： 图1. TCP编程基本模型 相信很多人看到图1应该不会陌生，这是一个利用TCP进行通信的经典模型图。我想大家都应该把这张图记在心中。 在此我就不讲述上图中每个API的意思了，百度一下，你就知道。我想说的是，难道你不觉得这么编程很累吗? 我们需要去调用每个API函数，然后每个判断返回值是多少，如果你忘记了哪个API的参数形式还得去查MSDN，这种时间花费是巨大的，尤其当你做应用层的快速开发时。 图2是利用UDP通信时的编程基本模型，这个模型较为简单，但是应用极为广泛，相比TCP而言，我本人觉得利用UDP通信是一门更为高深的技术，因为它是无连接的， 换言之，它的效率与灵活度就更高些。 图2. UDP编程基本模型 在此我补充一点，关于何时利用TCP通信、何时利用UDP通信的问题。他们的特性其实已经决定了他们的适用范围。 在进行大数据量、持续连接时，我们使用TCP，例如FTP协议；而在进行小规模数据、突发性高的通信时，我们使用UDP，例如聊天程序。 但是，这并不是绝对的事情。例如流媒体通信，它是大数量、持续的通信，但是使用的是UDP协议，为什么呢？ ——因为我们不关心丢失的帧，人的肉眼是无法识别出少量的帧丢失的。那么使用UDP通信就可以大幅度提高效率，降低网络负载。 C#之TCP编程如何创建一个套接字? 我们先来看看利用Winsock2是如何建立一个套接字的： 首先，我们要加载套接字库，然后再建立套接字。大致代码如下： WORD wVersion=MAKEWORD(2,2); WSADATA wsaData; if(WSAStartup(wVersion,&amp;wsaData)) { WSACleanup(); returnFALSE; } m_sock=WSASocket(AF_INET,SOCK_DGRAM,IPPROTO_UDP,NULL,0,0); if(m_sock==INVALID_SOCKET) { MessageBox(&quot;创建套接字失败！&quot;); return FALSE; } 难道你不觉得利用Winsock2创建一个套接字很费劲吗？如果你在Linux环境中变成倒是可以省掉加载套接字的部分， 但是却只能反复的调用API，这样也是很费时的事情。那我们再看看看利用C#是如何帮你简化工作的。这里我会介绍TCPClient类。 以上是从MSDN上截取的一段话，可见我们利用TCPClient还处理与TCP通信相关的操作。TCPClient有四个构造函数，每个构造函数的用法是有不同的。这里我补充一个知识，那就是端地址在C#中描述。 我们知道，我们用一个IP地址和一个端口号就可以表示一个端地址。在C#中我们利用IPEndPoint类来表示一个端地址，本人经常利用如下的构造函数来创建一个IPEndPoint类。 IPEndPoint localEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); 这样来表示一个端地址是不是比创建一个struct sockaddr_in的结构体来的快呢？ 如何绑定一个端地址？ 我们已经创建了一个端地址，也构造了套接字（TCPClient类），那么如何将二者绑定起来呢?也许你已经发现了，在建立TCPClient的时候我们其实就可以绑定端地址了。 如果你使用的TCPClient tcp_Client=new TCPClient()的构造函数来创建的TCPClient,那么系统会认为你没有人为的制定端地址，而会自动帮你制定端地址，在创建客户端的TCPClient时我们常常这样做， 因为我们不关心客户端的端地址。如果是服务器监听呢？在服务器监听时我们会使用例外一个类，叫做TCPListener，接下来我会讲到。我们可以利用TCPClient(IPEndPoint)来构造一个绑定到固定端地址的TCPClient类。例如： TcpClient tcp_Client = new TcpClient(localEP); 如何监听套接字？ 到现在为此我们还没讨论如何监听一个套接字。在传统的socket编程中，我们创建一个套接字，然后把它绑定到一个端地址，而后调用Listen()来监听套接字。而在C#中，我们利用TCPListener来帮我们完成这些工作。让我们先来看看如何在C#监听套接字。 IPEndPointlocalEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); TcpListenerListener = new TcpListener(localEP); Listener.Start(10); 我们首先创建需要绑定的端地址，而后创建监听类，并利用其构造函数将其绑定到端地址，然后调用Start(int number)方法来真正实施监听。这与我们传统的socket编程不同。以前我们都是先创建一个socket，然后再创建一个sockaddr_in的结构体。我想你应该开始感受到了C#的优势了，它帮我们省去了很多低级、繁琐的工作，让我们能够真正专注于我们的软件架构和设计思想。 如何接受客户端连接？ 接听套接字后面自然就是接受TCP连接了。我们利用下面一句话来完成此工作： TcpClient remoteClient =Listener.AcceptTcpClient(); 类似于accept函数来返回一个socket,利用TCPListener类的AcceptTcpClient方法我们可以得到一个与客户端建立了连接的TCPClient类， 而由TCPClient类来处理以后与客户端的通信工作。我想你应该开始理解为什么会存在TCPClient和TCPListener两个类了。 这两个类的存在有着更加明细的区分，让监听和后续的通信真正分开，让程序员也更加容易理解和使用了。 这里我还得补充一点：监听是一个非阻塞的操作Listener.Start()，而接受连接是一个阻塞操作Listener.AcceptTcpClient。 说了这么多，还不如来个实例来的明确。接下来，我会通过一个简单的控制台聊天程序来如何使用这些。先贴代码吧！ 服务器端： using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Net; using System.Net.Sockets; namespace Demo { class Program { static void Main(string[]args) { byte[]SendBuf = Encoding.UTF8.GetBytes(&quot;Hello,Client!&quot;); //发给客户端的消息； IPEndPointlocalEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); //本地端地址 TcpListenerListener = new TcpListener(localEP); //建立监听类，并绑定到指定的端地址 Listener.Start(10); //开始监听 Console.WriteLine(&quot;Server is listening...&quot;); TcpClientremoteClient = Listener.AcceptTcpClient(); //等待连接（阻塞） Console.WriteLine(&quot;Client:{0} connected!&quot;,remoteClient.Client.RemoteEndPoint.ToString()) ; //打印客户端连接信息； remoteClient.Client.Send(SendBuf); //发送欢迎信息； remoteClient.Close(); //关闭连接； } } } 客户端: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Net; using System.Net.Sockets; namespace Demo_Client { class Program { static void Main(string[] args) { byte[] RecvBuf=new byte[1024]; //申请接收缓存； int RecvBytes = 0; //接收字节数； string recvmsg=null; //接收消息； IPEndPoint remoteEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6666); //远程服务器端地址； TcpClient remoteServer = new TcpClient(); //创建TCPClient类来与服务器通信； remoteServer.Connect(remoteEP); //调用connect方法连接远端服务器； Console.WriteLine(&quot;I&apos;m using {0}.&quot;, remoteServer.Client.LocalEndPoint); //打印自己使用的端地址； RecvBytes=remoteServer.Client.Receive(RecvBuf); //接受服务器发送过来的消息； recvmsg=Encoding.UTF8.GetString(RecvBuf,0,RecvBytes); //将接受到的字节码转化为string类型； Console.WriteLine(&quot;Server says:{0}.&quot;, recvmsg); //打印欢迎信息； } } } 在C#网络编程中，我们要用到两个名空间，分别是System.Net和System.Net.Socket。 可能有人会有这样的疑惑，干嘛要申请一个Byte数组。我们知道，在传统socket编程中，我们都是用char来发送或者接受消息的， 其实char和Byte[]是同源的。他们都是一个Byte，而使用Byte[]能更易于人们理解和转化为其他类型。我们知道网络间传输的字节流，而Byte[]刚好符合了这个思想。 如果对以上类的用法不理解或者不熟悉的话，建议查看MSDN，上面讲解的很详细。 现在看看运行效果： 图3 运行效果（左为服务器，右为客户端） 好啦，到这里我们C#网络编程初步之TCP基本上算告一段落了，我只讲解了最为基础的部分，仅做抛砖引玉的作用。每个类的使用千变万化，希望你能找到最适合自己使用方法。现在你可以对比以前类似程序的代码了，看看我前面有没有说错。而且，越到后来你会越来越体会到C#人性化的一面。 后期的博文中，我会更新C#网络编程初步之UDP.本人更喜欢利用UDP来进行通信，至于为什么我已经说过了。以后，我会逐步写一些网络编程的高级内容，例如异步通信、多线程编程，并关注程序员经常遇到的一些棘手问题，比如TCP边界的确定等等。有机会，我也会同大家讨论网络编程中常用的软件设计思想与架构。 （本文图1、图2来自互联网，有部分信息来自MSDN。如需转载本文，请注明出处！谢谢）]]></content>
      <categories>
        <category>C#</category>
      </categories>
      <tags>
        <tag>C# tcp udp network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超小型局域网组建的方案]]></title>
    <url>%2F2011%2F09%2F03%2F%E8%B6%85%E5%B0%8F%E5%9E%8B%E5%B1%80%E5%9F%9F%E7%BD%91%E7%BB%84%E5%BB%BA%E7%9A%84%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[生活中我们经常会遇到需要组建一个超小型局域网共享上网的问题，比如在学校组建一个小型局域网共享上网，或者组建一个家庭网络共享上网等，在此过程中会碰到很多小问题，本人故撰此文，望能减少一些不必要的麻烦。 在学校上网，可以通过校园网，也可以通过电信宽带或者ADSL拨号上网（通过电话线上网）等。通过校园网上网，经济实惠，当然网速也是惊人的，尤其是喜欢玩游戏的同学就更悲剧了。通过校园网上网没有什么灵活性和扩展性，故在此不讲了。就以通过电信上网为例来进行分析与组建。如果你们寝室或出租屋有宽带接入，那么恭喜你了，你可以省下一个“猫”钱。4台PC以下共享上网的话，那必需购置一台4孔的交换机，一般在40~50元左右，然后购置网线若干，就是普通的直连线，一块钱一米的那种。(像我们学校水晶头都收钱，悲剧！)至此，所需的硬件就准备好了。 然后就是子网划分了，由于是超小型局域网，在这里可以使用C类IP私有地址，即192.168.A.B ,子网掩码为255.255.255.0，网关为192.168.A.1 。（网关最后一位可以改变，但一旦确定就不应更改。） 注意：0=&lt;A&lt;=254，A一旦确定也不应更改，1=&lt;B&lt;=254随着不同的PC应不同，不应重复。显然，该子网划分可允许254台PC接入，完全满足超小型局域网组建的需要。子网划分完之后就是将相应的IP地址填入本地网络适配器中，可参照下图。 到此局域网以组建完毕，可以进行局域网的对战、文件交互等操作，如果想连上Internet,那就继续往下看吧！DNS应填写你所在区的DNS服务器的IP地址，例如你在湘大，可以填写首选DNS：208.67.222.222，备用DNS：202.67.220.220.填写完之后就单击确定。 在此强调，除IP地址最后一位外，其余的在不同PC配置时均不要更改，切记！ 接下来就是一些必要软件的安装，既然是通过电信上网，那就要装星空极速。然后在填入电信给你的上网账号就可以上网了，当然此时还只有你一个人能上网。其实有条件的同学可以包电信的“我的一家”这种上网业务，它允许多台PC共用一个账号上网。湖南电信这边上网是绑定MAC地址的，理应只允许一个账号让一台PC机上网，其实这是很不合理的。废话少说，要想多台PC共享上网，可以让交换机拨号，当然你买的交换机要支持拨号这种功能，具体操作可以上网BAIDU一下。也可以选择共享上网软件，在此我推荐湘大学长自己做的一款软件，拼卡啦，这是我用过的最好用的共享上网软件，简单，方便，我也感到蛮自豪的。在湘大上网用这款软件完全没问题，不过在其他地方上不上的了我就不知道了。关于这款软件的使用方法可以参照http://www.xiaorsz.com/lan-internet-sharing-software-pinkala-download/ 。在此说明一下，一台PC通过星空极速拨号上网后，然后在通过拼卡啦创建共享，其余的PC通过拼卡啦加入共享即可都上网了。网络上还有很多其他的共享上网软件，比如CCPROXY，不过需要一台PC充当服务器，像拼卡啦这样实现服务器切换这么方便的，我还没发现。好啦，现在我们已经可以多机共享上网啦！ 如果你是包年的用户，或者不计流量的那种，建议使用交换机、路由器、猫自动拨号上网，很方便，插上网线就能上！如果有流量限制，且共享上网的PC较多，（比如我原来寝室的6台PC共用一个账号上网的那些耻人们，呵呵，开个玩笑！）建议用共享软件上网，虽然每次都要拨号，不过可以省流量！如果你住在南苑，600块钱一年的那种难寝室，那就只用通过ADSL上网了，有得上就行！那你得乖乖的买个猫，二手的也行。把电话线连接分线器，分线器一端连接座机，一段连接猫。然后猫在连接交换机的普通以太网口，有的交换接有个WAN接口，不要连那个。然后PC在连接到交换机即可，其他配制方法同上。因为是共享上网，电信本着能赚就赚的原则肯定是不允许的。你会发现优势网页打不开但是QQ却登的上，这是因为电信查封了你们的80（HTTP服务使用的）端口，这是一个知名端口，而QQ是用随机端口，它就没办法了。此时，让那台拨号的PC端口重连一下就又可以打开网页了，因为这是换了个公网IP。好啦，写到这里也就结束了。我省略了很多细节，大家都可以Baidu的到，希望对想共享上网的同学有所帮助。 如果有其他的方案也可以留言，互相交流！]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>network engineering</tag>
      </tags>
  </entry>
</search>