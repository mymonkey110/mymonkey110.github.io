<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[扩展字段——编程心法（二）]]></title>
    <url>%2F2020%2F07%2F02%2F%E6%89%A9%E5%B1%95%E5%AD%97%E6%AE%B5%E2%80%94%E2%80%94%E7%BC%96%E7%A8%8B%E5%BF%83%E6%B3%95%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[难度等级：玄阶中级 适用场景扩展字段一般出现在实体的建模过程中，多用于对一个“不稳定”实体的建模。”不稳定”表示对这个实体的认知目前还不清楚，并不确定该属性是不是属于实体。 举几个例子： 在行列转化——编程心法（一）的Story-4中，小明设计了rule_1 rule_2 rule_3三个字段，这三个字段都属于扩展字段。这个阶段小明不确定Rule是否真的属于Lottery，但又不想过度设计，此时采用扩展字段的方式既能解决问题，改动内容有比较少。 在公有云的订单系统中，经常会出现下单时选择”到期自动续费/删除“的选项，但不是所有的产品都有类似的选项。当时，我们在订单系统中设计一个ExtraParams来存放这些附加参数。对于”到期自动续费/删除“这个需求，当时我们很难判别它是订单的必须属性还是演进过程中的一个临时需求，此时采用扩展字段的方式是合适。 关键点 扩展字段一定不是实体的必要属性。实体的必要属性在建模时就应该能清晰地辨识出来，而扩展字段对构成一个基本实体并不会产生较大的影响。随着实体的演化，扩展字段时有可能转化为实体的必要属性的。 不要滥用扩展字段。如果你能尽早的确定扩展字段的意义，那么就应该使用更有意义的描述词汇，而不是Extra Params之类的通用词汇。更加具象的词汇能更加清晰地反映你对模型的认识。 最佳实践 尽量不要使用扩展字段。正如前面所说，使用扩展字段正是源于我们对实体模型认识还不清晰，如果你准确的知道该字段的意义，那么就不应该使用扩展字段。 扩展字段不要太多。个人建议不要超过3个，如果超过这个值，可以参考行列转化——编程心法（一）的技巧将模型进一步拆分。 扩展字段的内容尽量简单。不要再扩展字段里面承载太多的内容，如前面所说的”到期自动续费/删除“、一个规则的参数等。如果在扩展字段里面承载过多的内容，往往意味着这里的模型设计存在某些问题，我们需要重新思考字段内容与实体间的关系。 变体扩展字段时常会和类型字段一同出现，如行列转换的Story-5中，规则(Rule)已经转化为了一条条具体的行。但是规则所需要的参数往往是动态的，例如我们需要对XXXPay的信誉值在(a,b)的用户做活动，而积分值要大于1000。那么规则表的设计如下： id type param_1 param_2 1 XXXPayRule a b 2 PointRule 1000 - param_1和param_2就属于扩展字段，他们针对不同的type有则完全不同的意义。 总结扩展字段在我们还对实体的某些属性还不清楚时是有帮助的。但从实体的整个演化周期来看，扩展字段是一种临时的过度手段，它会增加我们地技术债务。]]></content>
      <categories>
        <category>编程心法</category>
      </categories>
      <tags>
        <tag>编程技巧</tag>
        <tag>代码技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行列转化——编程心法（一）]]></title>
    <url>%2F2020%2F05%2F26%2F%E8%A1%8C%E5%88%97%E8%BD%AC%E5%8C%96%E2%80%94%E2%80%94%E7%BC%96%E7%A8%8B%E5%BF%83%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[难度等级：地阶中级 行列转化是我用的最多的编程技巧之一，不论是对领域建模还是表结构设计都大有裨益。适用于实体向聚合的转化阶段。我将通过一系列用户故事来描述其作用。 背景小明是某NB公司的后端开发工程师，最近NB公司发展十分迅猛，日活大涨，高层决定搞活动拉新。最后落地下来就决定以抽奖发红包的形式来搞。 Story-1PD：抽奖咋们也没搞过，只要满足XXPay实名认证就可以抽奖吧。 小明：这简单，给我一天。 于是乎就诞生了如下代码： 1234567891011class Lottery &#123; public Result execute(long uid) &#123; //检查XXXPay实名认证 if(!checkIsXXXPayCertifact(uid)) return Result.fail(); &#125; //执行真正抽奖逻辑 return doLottery(); &#125;&#125; 小明直接把XXXPay验证逻辑写道了抽奖流程中，作为前置流程。 Story-2PD：上次活动效果很好，拉新的目的达到了。我们要给高消费能力的人群再发红包，就再上次规则上加上积分大于1000的限制吧。 小明：好吧，你说什么就是什么咯。 1234567891011class Lottery &#123; public Result execute(long uid) &#123; //检查XXXPay实名认证 &amp;&amp; 积分大于1000 if(!checkIsXXXPayCertifact(uid) || !checkPointAbove1000(uid)) return Result.fail(); &#125; //执行真正抽奖逻辑 return doLottery(); &#125;&#125; Story-3PD：不好，上次活动引来了大批羊毛党，下次活动要接一下风控系统。 小明：WTF，搞个活动真麻烦。 12345678910111213141516171819class Lottery &#123; public Result execute(long uid) &#123; //检查XXXPay实名认证 if(!checkIsXXXPayCertifact(uid)) &#123; return Result.fail(); &#125; // 积分大于1000 if(!checkPointAbove1000(uid)) return Result.fail(); &#125; // 风控系统校验通过 if(!isPassRiskSystem(uid)) return Result.fail(); &#125; //执行真正抽奖逻辑 return doLottery(); &#125;&#125; Story-4PD: 老板们决定把抽奖做成常态工具，需要经常搞，你看看怎么弄。前置条件就那三个，但不一定都有。 小明：我就知道没啥好事。 小明认值考虑了下，这三个都是验证条件，返回结果只有true/false，我可以抽象一下提取成一个前置条件（Rule），得到如下代码。 12345678910111213141516171819202122232425262728class Rule &#123; private String name; Rule(String name) &#123; this.name = name; &#125; abstract public boolean check(long uid);&#125;class XXXPayRule extends Rule &#123; XXXPay() &#123; super("XXXPayRule"); &#125; @Override public boolean check(long uid) &#123; return checkIsXXXPayCertifact(uid); &#125;&#125;class PointRule extends Rule &#123; //省略&#125;class RiskRule extends Rule &#123; //省略&#125; Lottery实体加了3个属性， 12345678910111213141516171819class Lottery &#123; private Rule rule1; private Rule rule2; private Rule rule3; public Result execute(long uid) &#123; if(rule1!=null!rule1.check(uid)) &#123; return Result.fail(); &#125; if(rule2!=null!rule2.check(uid)) &#123; return Result.fail(); &#125; if(rule3!=null!rule3.check(uid)) &#123; return Result.fail(); &#125; //执行真正抽奖逻辑 return doLottery(); &#125;&#125; 表结构也修改为: id name rule_1 rule_2 rule_3 1 XXX拉新活动 XXXPayRule RiskRule NULL 经过这么一修改，小明十分满意，内心OS：还有谁！现在抽奖可自由配置规则，根据需要加载，比以前灵活度高了很多。 几个月内PD再没找过小明，小明也过了几天舒服日子。 Story-5PD：现在发展太快了，很多子产品都用我们的抽奖工具，他们的验证规则太多了。什么注册满7天，只能中一次，XXX等等。小明：这…让我想想。 看到这么多人用小明的抽奖系统，他内心很开心，但是这么多规则不知道如何承接。 这个时候其实就要用到 行列转换 这个技巧了。小明已经有意识的将规则抽象成了一个独立的类Rule，但是却没有建立专门的表。对于不确定数量的规则，可以在Lottery中加入规则的聚合List&lt;Rule&gt; rules来表示独立的规则，而每个Rule对于规则表中的一行记录。这样就把Lottery表中的列rule_123转化为了rule表中的一行记录。 受到启发后，小明最终做出了如下修改： 12345678910111213class Lottery &#123; private List&lt;Rule&gt; rules; public Result execute(long uid) &#123; for(Rule rule:rules) &#123; if(!rule.check(uid)) &#123; return Result.fail(); &#125; &#125; //执行真正抽奖逻辑 return doLottery(); &#125;&#125; 这样一来，Lottery的代码也清爽了许多，最后一丝坏味道也去除了。 回过头来看行列转化，本质上是实体(Lottery)演变成了一个聚合(Lottery)。总结一下该技巧的使用条件： 列转行适用时机：实体演变成聚合关键点：抽象聚合子类，建立独立表存储。行转列适用时机：聚合蜕变成实体关键点：与上述过程相反就我个人的开发经验来看，大部分情况下都是列转行，这样代表你的业务在进一步发展，很少遇到行转列。行列转化这其中有个阈值，个人觉得一般超过3个比较合适。]]></content>
      <categories>
        <category>编程心法</category>
      </categories>
      <tags>
        <tag>编程技巧</tag>
        <tag>代码技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[湘湖露营]]></title>
    <url>%2F2020%2F05%2F17%2F%E6%B9%98%E6%B9%96%E9%9C%B2%E8%90%A5%2F</url>
    <content type="text"><![CDATA[最近拒了一个不错的offer，对方公司发展势头很猛，给的待遇也相当诱人，唯一的缺点就是不在杭州。有了宝宝以后，发现自己更加念家了，可能真的老的吧。以前总是觉得要趁年轻多挣点钱，忽然间发现有些东西真心是钱替代不了的。看着我可爱的儿子一天天长大，我觉得应该要感到知足了。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持久化——DDD务实篇（一）]]></title>
    <url>%2F2020%2F05%2F15%2F%E6%8C%81%E4%B9%85%E5%8C%96%E2%80%94%E2%80%94DDD%E5%8A%A1%E5%AE%9E%E7%AF%87%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[持久化就是Java对象存储到数据库以及从数据库中构建出Java对象的技术。DDD中的持久化无非是对实体、值对象和聚合的持久化，这与传统的针对POJO的持久化还是存在一些差异的。我将从模块依赖、ORM框架和具体对象的持久化来说明DDD中持久化的技术与思考。 模块依赖DDD的模块划分一般如下： 其中领域层(Domain)是依赖基础设施层（Infrastructure）的。我个人认为实际上这个关系应该反过来，让基础设施层依赖领域层，而领域层不依赖任何其他的Module。 这样做的好处在于： 领域层更加纯粹。采用DDD项目的核心就在于领域层，这也是整个项目最有价值的地方。领域层的建设应该尽量排除基础设施的干扰，专注于业务逻辑的实现。 让领域层具有可移植性。虽然更换基础设施的概率不大，但还是需要考虑这样的问题。随着项目的不断发展，传统的RDBMS很可能适应不了持久化方面的要求，私有化部署可能要求依赖的开源软件固定在几个少数的数据库中，公司技术层面战略变化导致底层迁移等等这些可能的因素要求我们具有一定的前瞻性。 既然决定让Domain不依赖Infrastructure，那么Reposistory应该放到哪里？ 我推荐的做法是将接口放到Domain中，而Reposistory的实现放到Infrastructure里面。直接将Reposistory的Interface和业务模型放到同一个package下面就可以了，让业务模型和负责业务模型的存储接口放到一个目录下。但这里感觉有点“坏味道”的产生，好像存储层的内容“侵入”到了领域层。我举得这是可以接受的，因为在领域层的模型是以业务维度划分的，实体与存储库是可以共存。反而，如果让领域层依赖基础设施，那么这种侵入性将更加难以控制，很容易造成深度耦合。 持久化的时机领域层的实体和聚合说白了就是业务属性和业务行为的集合，业务属性对应表中的字段，而行为则反映了模型本身的能力。业务逻辑的实现从内存层面去看就是通过一系列计算来改变属性的值，但这个改变后的实体对象对应着本机内存的一个普通Java对象。那么在哪里对这个Java对象进行持久化呢？ 大部分情况下，一般在Application层调用Reposistory进行持久化。大部分项目主要是针对实体的CRUD操作，实体的行为基本局限在实体本身，通过调用一个或者少数几个实体方法就可得到满足要求的实体对象。这种情况下，在Application进行持久化是比较简单容易的。 Application的Service进行持久化的一般步骤如下： 检索出对应的实体 调用对应的实体方法 最后调用实体对应的Reposistory进行持久化 一个典型的Service方法如下所示： 12345678@Override@Transactionalpublic void changeRoleRemark(long primaryAccountId, String roleName, Stringremark) throws RoleNotFoundException &#123; Optional&lt;Role&gt; result = getUserRoleByName(primaryAccountId, roleName); Role role = result.orElseThrow(RoleNotFoundException::new); role.changeRemark(remark); roleRepository.update(role);&#125; 我们要修改Role（Role对应一个实体）的备注，上面是一个典型的Service实现。再调用完Role的changeRemark方法后，直接调用roleRepository的update方法将更新后的Role持久化到数据库中。 关系表的持久化也是一样的处理方式，如下所示。 123456789101112@Override@Transactionalpublic void deleteUserRole(long primaryAccountId, String roleName) throws RoleNotFoundException &#123; Optional&lt;Role&gt; result = getUserRoleByName(primaryAccountId, roleName); Role role = result.orElseThrow(RoleNotFoundException::new); RoleRelationParam roleRelationParam = new RoleRelationParam(); roleRelationParam.setPrimaryAccountId(primaryAccountId); roleRelationParam.setRoleId(role.getId()); roleRelationRepository.revokeRolePolicy(roleRelationParam); roleRepository.delete(primaryAccountId, roleName);&#125; 上诉的持久化方式可以满足大部分项目的需求，但是总有特殊情况。我在一些项目中发现，针对具有长流程的实体行为，持久化行为下沉到实体方法里面会更为合适。 举个例子，云服务中的IaaS和iPaaS服务的管控端一般都有着很多长流程的业务逻辑，如”创建一个云主机“，”对一个云主机实例升配“，”创建一个高可用版的RDS实例“等等。这些长流程的业务逻辑一般有一个个原子的步骤操作构造，如”共享镜像给租户”、”指定物理机创建VM”、”挂在硬盘”、”启动指定脚本”等等。做的比较好的管控端会将这些原子步骤抽离出来，形成预编码的Step；同时长流程过程做成一个抽象后的实体Process。一个Process由多个Step组成，Process控制着Step的运行过程。 这个例子中，Process具有一个Start或者Execute的行为方法，代表整个流程的启动和执行。在执行过程中，Process需要保存每个Step的执行上下文，为了执行过程异常中断后可继续整个执行流程。那么一个合理的持久化方式如下： 12345678@Overridepublic void execute() &#123; StepRepository stepRepository = BeanUtil.getBean(StepRepository.class); for(Step step: steps) &#123; step.execute(); stepRepository.save(step); &#125;&#125; 当然，我们也可以将Step的保存和Step的execut放到一起，这样Process就不需要关心如何对Step进行持久化了。 之所以长流程的持久化方式不同于短流程，其根本原因在于我们关心长流程运行过程中产生的中间变量。这些中间变量如果也是实体，那么我们就必须对齐进行持久化。对中间变量持久化已经成为了业务逻辑的一部分，所以我们需要将其放到领域层的模型中进行。 ORM框架如果可以，请在使用DDD的项目中使用更加自动化ORM框架，如Hibernate；MyBatis这种半自动化SQL映射工具对DDD项目来说不太友好。 由于我自己对Hibernate不熟悉，不适合做两者的对比。使用DDD架构模式的项目其核心在于领域模型的建模与演化，实质上是一种以Java对象为核心的开发方式。而三段式的开发方式中，持久化层是以表为核心的，Java对象（一般是POJO）只是表的容器而已。因为核心的关注点不同，导致在框架的设计理念是不一样的。Mybatis对DDD的领域模型侵入性比较强，而Hibernate对DDD中的实体和值对象都有着很好的支持。个人认为一款好的ORM框架是能最大程度地贴合你的领域模型，能灵活的支持模型对象的存取和模型间关系的映射。 目前我还无法细致的描绘ORM对DDD的影响，后期有机会在对其进行更加细致的分析。 实体持久化实体的持久化注意以下几点： 善用ConstructorConstruct在POJO中基本未被使用，而在DDD中它十分重要。因为我们的开发思维已经从面向表编程转变为面向对象编程，那么对象的每一个属性、构造器和方法我们都应该反复的思考与推敲。 Constructor代表了一个对象的开始，它是如何被构造出来的。在实体中，Constructor应该接受这个实体构造必不可少的参数，当然可以提供多个Constructor来接受更加丰富的参数。下面是一个UserGroup的实体对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 子账号用户组 * * Created by Michael Jiang on 16-12-5. */public class UserGroup extends Entity &#123; private static final long serialVersionUID = -3431132267526140851L; private static final int MAX_GROUP_NUMBER = 50; @Min(1) private long primaryAccountId; @Pattern(regexp = "^[a-z]([a-z0-9-]&#123;0,62&#125;[a-z0-9]$|[a-z0-9]?)", message = "组名称只能是英文字母，数字和中划线") private String name; @Size(max = 255) private String remark; @Size(max = 50) private List&lt;String&gt; subAccountList; public UserGroup(Long primaryAccountId, String name) &#123; this(primaryAccountId, name, ""); &#125; public UserGroup(Long primaryAccountId, String name, String remark) &#123; this.primaryAccountId = primaryAccountId; this.name = name; this.remark = remark; this.subAccountList = Lists.newArrayList(); &#125; public long getPrimaryAccountId() &#123; return primaryAccountId; &#125; public String getName() &#123; return name; &#125; public String getRemark() &#123; return remark; &#125; public void changeName(String newGroupName) &#123; this.name = newGroupName; &#125; public void changeRemark(String newRemark) &#123; this.remark = newRemark; &#125; public void addSubAccount(String subAccount) throws MaxGroupMemberException, AlreadyJoinGroupException &#123; if (subAccountList.size() &lt; MAX_GROUP_NUMBER) &#123; if (subAccountList.contains(subAccount)) &#123; throw new AlreadyJoinGroupException(); &#125; this.subAccountList.add(subAccount); &#125; else &#123; throw new MaxGroupMemberException(); &#125; &#125; public void removeSubAccount(String subAccount) &#123; this.subAccountList.remove(subAccount); &#125; public List&lt;String&gt; getSubAccountList() &#123; return subAccountList; &#125; protected void setSubAccountList(List&lt;String&gt; subAccountList) &#123; this.subAccountList = subAccountList; &#125; @Override public Set&lt;String&gt; validate() &#123; return Entity.validate(this); &#125; @Override public String toString() &#123; return "UserGroup&#123;" + "primaryAccountId='" + primaryAccountId + '\'' + ", name='" + name + '\'' + ", remark='" + remark + '\'' + ", subAccountList=" + subAccountList + '&#125;'; &#125;&#125; UserGroup提供了两个Constructor。由于一个UserGroup必须属于一个主账号，同时必须有一个组名称，那么我们一般需要提供这样一个Constructor。 public UserGroup(Long primaryAccountId, String name) 对应的MyBatis ResultMap如下： 123456789101112131415&lt;resultMap id="groupResult" type="userGroup"&gt; &lt;constructor&gt; &lt;arg column="primary_account_id" javaType="long"/&gt; &lt;arg column="name" javaType="String"/&gt; &lt;arg column="remark" javaType="String"/&gt; &lt;/constructor&gt; &lt;id column="id" property="id"/&gt; &lt;result column="gmt_create" property="gmtCreate"/&gt; &lt;result column="gmt_modify" property="gmtModify"/&gt; &lt;result column="is_deleted" property="isDeleted"/&gt; &lt;collection property="subAccountList" javaType="list" column="id" ofType="String" select="selectSubAccountUser" fetchType="eager"&gt; &lt;result column="sub_account_user"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; 戒掉SetterDDD推荐使用更有表现力的方法名称，例如上面UserGroup的changeName，而不是setName。这两者的语义与使用心智是不一样的。changeName表示我已经有一个name，而现在要接受一个新的name，而setName是看不出来任何的业务语义的。 不用setter带来的一个问题就是Mybatis无法正确的识别对应的反射方法，如果使用属性注入，那么Mybatis要求一定要存在对应的setter。 解决办法有两个： 如果这个属性是构造时可以附带的，那么就通过Mybatis的constrcutor进行注入，而不是property。 如果这个属性不合适放到Constructor中，那么增加一个protect级别的setter方法。这样一来就会有两个注入点了，这也是Mybatis不适合DDD的原因之一。 处理关联关系聚合里面一般多个其他实体或者值对象，这种关联关系时如何建立起来的呢？ 如UserGroup中的subAccountList属性，这个代表了用户组中的子账号集合。通过addSubAccount和removeSubAccount来增加和删除组中的子账号。通过setSubAccountList来完成MyBatis注入子账号的集合，对应ResultMap中的collection元素。下面会在值对象持久化中讲到如何利用值对象来保存关联关系。 值对象持久化值对象的持久化一般分为两种场景： 描述客观事物大部分值对象是用来描述一种客观存在的事物，如Email、Phone、Url等等。这些对象的持久化需要使用专门的TypeHandler。如处理EMail可使用如下的EmailAddressTypeHandler。 1234567891011121314151617181920212223242526272829/** * EMailAddress值对象 Type Handler * * Created by Michael Jiang on 16-12-6. */@MappedTypes(EMailAddress.class)@MappedJdbcTypes(JdbcType.VARCHAR)public class EMailAddressTypeHandler extends BaseTypeHandler&lt;EMailAddress&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, EMailAddress eMailAddress, JdbcType jdbcType) throws SQLException &#123; preparedStatement.setString(i, eMailAddress.email()); &#125; @Override public EMailAddress getNullableResult(ResultSet resultSet, String s) throws SQLException &#123; return new EMailAddress(resultSet.getString(s)); &#125; @Override public EMailAddress getNullableResult(ResultSet resultSet, int i) throws SQLException &#123; return new EMailAddress(resultSet.getString(i)); &#125; @Override public EMailAddress getNullableResult(CallableStatement callableStatement, int i) throws SQLException &#123; return new EMailAddress(callableStatement.getString(i)); &#125;&#125; 这种场景下值对象是在实体或者聚合内部的，没有专属的数据表，只需要使用对应的TypeHandler完成值对象的存取就可以了。 描述关联关系我们经常会遇到关联关系表，这种表对应着一种N:N的实体关系。我们可以利用值对象的特性来表示这种关联关系，因为关联关系一旦建立就不可改变直到你销毁它。 这种情况下值对象本身就对应了一张关系表，无法通过TypeHandler来完成持久化。我们需要使用IdentifiedValueObject这个带ID的值对象。 123456789101112131415161718192021222324252627282930/** * 带id的值对象 Created by jiangwenkang on 16-11-7. */public abstract class IdentifiedValueObject&lt;V extends IdentifiedValueObject&gt; implements ValueObject&lt;V&gt; &#123; private static final long serialVersionUID = -7815856088988915247L; protected Long id; protected Date gmtCreate; protected Long getId() &#123; return id; &#125; protected void setId(Long id) &#123; this.id = id; &#125; public Date getGmtCreate() &#123; return gmtCreate; &#125; protected void setGmtCreate(Date gmtCreate) &#123; this.gmtCreate = gmtCreate; &#125; @Override public String toString() &#123; return "IdentifiedValueObject&#123;" + "id=" + id + ", gmtCreate=" + gmtCreate + '&#125;'; &#125;&#125; 然后具体的关系值对象继承这个IdentifiedValueObject即可。之所以会存在这个IdentifiedValueObject是因为我们关系表中还会存在主键ID,创建时间之类的通用字段，我们把这些字段封装在这个带ID值的基类中，这样我们具体的值对象就不需要冗余这些字段了。 综上所述，DDD中的持久化要考虑的东西更多一些。从模块的依赖关系、持久化的时机、ORM的选型都需要仔细考量。大部分情况下我们都是对实体和聚合进行持久化，需要利用好Constructor、尽量避免使用Setter、利用Collection来加载聚合关联的实体对象。一般情况下值对象是跟着实体一起进行持久化的，某些情况下需要专门对值对象进行持久化，那么我们可以构造一个带ID的值对象基类来屏蔽技术层面的细节，从而保持具体值对象的纯粹性。 趁着最近换工作之际，可以静下心来写点DDD的东西了。最近微服务和中台概念的流行，似乎又让国内的开发者重拾DDD的开发理念，这让我感到有些兴奋。后续我将更多分享关于DDD落地方面的问题。]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网易PaaS On K8S实践]]></title>
    <url>%2F2019%2F12%2F24%2F%E7%BD%91%E6%98%93PaaS-On-K8S%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[背景随着Kubernetes日趋成熟与稳定，网易云将其列为最重要的基础设施，成为云计算的底座。在此背景之下，PaaS团队的目标自然也将适配K8S列为了其首要支持目标。但是在实际落地过程中，我们遇到了很多问题，本文将分享一下网易在PaaS服务在迁移上K8S过程中的问题和我们的应对之道。 调研众所周知，Kubernetes处理无状态应用最为合适，Pod的短生命周期特性和无数据本地存储都是为无状态应用而生的，但是有状态应用是否也适合上K8S呢？最开始我们对此是持怀疑态度的，直到发现Operator的存在。Operator是由coreos公司提出的一个概念，定位为一种打包、部署和管理Kubernetes应用的一种方法。关于Operator诞生的历史，可以参见这篇博文：OpenShift全力拥抱Operator：Kubernetes运维自动化背后的战争 Operator的工作原理并不复杂，如下图所示： Operator通过Watch ApiServer来捕获CR的请求，然后创建对应的资源来“组装”成我们需要的集群。CR所属的子资源的状态也通过ApiServer反馈给Operator，Operator来做相应的协调处理，整个过程清晰明了。 原理不复杂，关键在于Operator的开发模式与我们以前做PaaS管控的逻辑出入是很大的，主要表现在以下两个方面： 基于声明式的开发模式，而不是命令式。 假定资源的状态变化是高频的，而不是低频的。 对我们冲击最大的就是声明式的开发方式，它强调一开始就把最终的结果描述清楚，不管过程；而我们已经的开发模式基本上都是命令式的，由用户通过一些列的Restful“命令”来组装成他需要的集群。 声明式的优势: 强调结果，而不是过程 对使用者友好 简化开发工作 缺点也很明显： 性能。针对某些大规模的场景，声明式可能没有命令式处理高效。 但是对于PaaS服务的管控端而言，性能不是主要指标，稳定性和可维护性更加重要。所以声明式的开发方式应该是对PaaS的管控端开发更加友好。 另外，还一个显著的区别在于，相比于传统的VM架构，Kubernetes集群上的资源似乎更加“不稳定”。我们分析发现，这种不稳定性来源于多个方面： 混部。一个Kubernet集群可以承载的负载类型非常多，业务容器、PaaS容器和大数据相关的容器都可以跑在一个K8S集群中。虽然可以通过给Node打标签，配合一些调度策略将不通的业务隔离开，但出于提高利用率的考虑，又不会隔离的非常严格。这样就可能造成资源的抢占，从而带来风险。 Docker较弱的隔离性。Docker是共性操作系统内容，基于Namespace的隔离还不够完善，可能带来潜在风险。 复杂的Controller关系。Kubernetes的一大优势在于其高度的自治性，这种自治性通过各自各样的Controller来完成，同时Controller之间又存在着隐含的层级关系。 这种“不稳定”因素的存在迫使我们在设计之初就要考虑服务的自愈能力。实际上，K8S已经提供了非常强大的自愈能力，我们更多要考虑的是让PaaS如何利用这些能力。 在调研过程中，我们发现其实现在已经有非常多的PaaS服务迁移上了Kubernetes，awesome-operators上有众多开源的Operator项目，有官方的也有第三方开源的。这进一步坚定了我们选择Operator的决心。 标准化在云1.0和2.0的研发过程中我们发现了一个很大的问题，在于各个PaaS服务的管控端都是每个PaaS团队各自开发，基本上没有代码复用。有一两个团队出于自己代码维护性地角度方便，开发了一些SDK包来封装与IaaS之间的交互，但这些SDK包并没有经过良好的设计和抽象，导致其很难在其他PaaS之间共享。这样带来的一个直接问题就是研发效率低下。一个PaaS服务从立项、开发、测试和上线大概需要2~3个月的时间，这还不包括对接各种横向服务，如计费、SAM、资源池等。另外一个问题在于，管控端质量取决于PaaS人员的水平，一些共性的问题反复发生，没有集中性的技术手段来规避这些问题。 为了避免重蹈覆辙，在PaaS on K8S立项之初我们就强调通过标准化规范来约束PaaS Operator，通过“中台”小组来解决PaaS共性的问题。（这里的中台应该叫PaaS公共服务更为合适） 我们在充分调研的情况下，结合Redis和Kafka迁移上K8S的实际项目经验，制定了一套标准化的规范。该规范包含以下几个方面： 文档规范：必须包含需求文档、概要设计和详细设计，尤其是需求文档，一定是要从业务方的痛点出发，说明该项目的价值和意义。 设计规范：包括设计原则，最佳实践和CRD的详细设计要求。 开发规范：使用Go为开发语言，OperatorSDK为开发框架，Api设计遵循社区规范。 高可用要求：必须容忍单节点异常，多机房部署要容忍单机房异常。 部署规范：所有的Operator都需要发布到轻舟应用商店；镜像制作要使用统一维护的基础镜像，禁止使用latest标签；统一使用脚本管理系统来分发宿主机上的管理脚本等。 运维规范：定义Operator和人工运维的边界；日常巡检的内容；应急预案的要求。 测试规范：由QA团队制定，包含单元测试、e2e测试、功能场景测试、数据面稳定性测试、管控面和数据面异常测试、性能测试等。 监控报警：基础的监控指标、数据面的采集指标和采集方式、管控面的采集指标和采集方式、报警的规范和原则。 目前标准化的内容已经涵盖非功能性80%的内容，功能性大概40%左右，可以说做到了PaaS研发过程的基本覆盖了。有些内容很难通过标准化的规范来约束，我们通过白皮书的形式来进行说明，进一步覆盖实际开发过程中的可能遇到的问题。 扩展PaaS迁移上K8S的过程中遇到了很多问题，我们发现原生的K8S的能力还不能满足我们的需求。为此，我们和K8S团队合作，将我们的需求统一化，由K8S团队来实现这些扩展能力。 调度PaaS服务的调度与无状态应用还是存在很大的差别，主要在于PaaS对高可用的要求更高。比如，我们希望Redis Cluster不超过1/3的Pod分布到同一个Node上，不超过1/2的Pod分布到同一个机房里面等等。我们将这种扩展调度的需求放置到一个configmap里面，由K8S来实现统一的扩展调度器。 12345678910apiVersion: v1kind: ConfigMapmetadata: name: config-map-name namespace: cluster-namespace #实例集群所在的nsdata: cluster-size: 100 //集群大小 max-pod-on-node: 33 //单节点最多能调度的Pod（包含） max-pod-in-zone: 50 //Zone内最多调度Pod（包含） available-zones: cn-east-1a,cn-east-1b,cn-east-1c //必须调度的可用区 max-pod-on-node就可以限制整个集群在单个Node上调度Pod的数量 max-pod-in-zone可限制单个机房内调度Pod的数量 available-zone用来实现AZ的MUST IN语言，从而满足多机房特性 MUST IN语义的实现其实比较困难，这与K8S的调度机制有关。K8S是基于Pod进行调度，通过预选和优选来过滤出符合条件的Node。然而，PaaS服务很多时候需要有“全局视野”，局部调度最优但不代表全局调度就是最优的。 我们Redis Cluster采用了多个StatefulSet来管理分片，每个StatefulSet的0号Pod为主分片，1号Pod为复制分片，要求多机房的情况下主分片和复制分片不能在同一个机房。如果由K8S随机调度，那么有可能就会发生死锁问题，可调度的Node越少发生死锁的概率就会越高。下图详细说明发生这一问题的过程，已经目前我们的解决方法。 但是这种解决方式存在局限性和特殊性，并不能应用于所有的情况。问题的核心还是在于PaaS调度需要有“全局视野”，我们需要提前规划好Pod的分布情况，但是现有K8S的调度机制限制了这方面的能力，除非我们自定义PaaS的“专属调度器”。 本地盘很多PaaS服务都有存储的需求，这也有状态服务的一大特点。云原生架构推荐我们存储架构分离，但是这需要强大的网络支持，所以本地盘还是相对现实靠谱的方案。K8S原生对本地盘的支持不太好，主要在于Local PV需要手工管理和维护，为止K8S团队帮助我们开发了基于LVM的本地盘管理插件。 管理员只需要按如下方式来申明可用的盘和机器信息即可。 1234567891011121314apiVersion: node.netease.com/v1kind: LocalStoragemetadata: name: lsspec: disks: - /dev/sde node: 172.24.5.4 storageClass: localstorage-class vg: k8svgstatus: allocatable: 676475Mi capacity: 762491Mi phase: Active 通过自定义storageclass的方式给我们提供了相当高的灵活的和扩展性，可以满足共享盘和独立盘的功能，只需要建立不同storageclass即可。 IP保持IP保持K8S团队开发的扩展能力，它是在Pod重建以后还能保持以前分配的IP，从使用方式上表现得更像VM一样。实际上这种使用方式是违反K8S的设计理念的，但是出于调试、运维、查看日志等需求，业务方希望能保持POD的IP。我们使用这一功能是因为我们遇到以下的场景。 Redis集群中某个Pod挂掉以后，原先分配给该Pod的IP可能被其他集群复用，造成元信息混乱，客户端有可能连接到一个另外一个集群的Pod，造成访问异常。 这是一个合理的场景，如果PaaS的节点之间或者Client与服务节点之间缺少认证机制，仅靠IP地址来建立信任关系，确实会存在上诉的场景。但IP被错误的Pod复用的概率取决于可分配IP池的大小，如果IP池足够大，出现这种概率的情况还是极低的。 目前我们还没有找到一种相对简单的方式来规避该问题，但我们还是不推荐使用该功能。 产品化PaaS开发的Operator都将集成到轻舟平台的应用商店。标准化规范要求Operator统一使用OperatorSDK进行开发，它自动化生成CSV文件，而轻舟应用商店通过Operator Lifecyc Manager来统一管理和运维Operator，两者可以无缝对接，部署难度大大降低。 同时前端界面是一套，无须为PaaS服务做定制化开发，前端研发效率大大提高，使用方式也更加统一。业务方使用也是非常友好的。业务只需要在应用市场订阅所需要的Operator即可使用到PaaS服务。当然，在产品化集成方面，Operator离一个完整的产品还存在差距，但为了尽量剥离这些商业化逻辑，让PaaS Operator更加纯粹，我们正在开发Operator Assistor这样的统一适配组件，来满足权限、配额、计量计费的产品逻辑。 总结从今年8月开始做Operator，到年底已经上线了3个Operator（Redis Cluster、Kafka、Zookeeper），我们的研发速度大大提高。从大家的反馈来看也十分积极。经统计，编写Operator所需要的代码比起1.0和2.0的管控代码大概减少了80%以上，可用性提高的同时，运维成本还降低了很多。由于今年还未大规模部署，预计明年基于Operator托管的PaaS服务将遍地开花，我们人均的运维规模将大幅提升。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>kubernetes</tag>
        <tag>paas</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CQRS模式]]></title>
    <url>%2F2019%2F04%2F16%2FCQRS%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[原文链接：https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn568103(v%3dpandp.10) 通过使用不同的接口来分离读写操作，这种模式能最大化性能、可扩展性和安全性；能通过更高的灵活性来支持系统的演进；同时能在领域层面防止因更新命令引起的合并冲突。 背景与问题在传统的数据管理系统中，命令（更新数据）与查询（请求数据）是在相同的一组实体集在单个数据仓库下执行的。这些实体可能是传统关系型数据库（比如：SQLServer）中一张或者多张表的多行数据的一个子集。 典型的，在这些系统中，所有的创建、读取、更新和删除（CRUD)操作在同一个实体上执行。比如，一个“客户”的DTO对象通过数据访问层（DAL)从数据仓库中检索出来并展示到界面上。用户更新了DTO对象中的几个熟悉，然后DTO对象通过DAL层被存回了数据仓库中。像图一所示，同一个DTO对象既被用于了读操作又被用于了写操作。 传统的CRUD模式在针对数据的业务逻辑十分有限的情况下能比较好的工作。一些开发工具提供的脚手架机制能迅速的创建数据层的访问代码，然后能按需调整。 然后，传统的CRUD方法有几个弊端： 这通常说明对数据的读和写操作存在不匹配，比如附加的列或者属性必须正确的更新即使它们不是操作的必须部分。 在一个协作的领域模型（例如多个Actor并行操作相同的数据集）中，当记录被锁定在数据仓库中，或者因为并发更新引起的更新冲突，此时会存在数据争取的风险。随着系统的复杂度和吞吐量增加，这些风险也逐渐加大。另外，因为数据存储和数据访问层的负载较重，加之检索必要信息的复杂性查询，传统方法同样对性能有着负作用。 因为一个实体同时暴露了读写操作，有可能一不小心在一个错误的上下文中暴露了数据，从而使得管理数据的安全性和权限更加繁琐。 解决之道命令与查询责任分离是一种通过接口来区分开读数据（查询）与更新数据（命令）的模式。这表明用于查询的数据模型与用于更新的数据模型是不一样的。如图二所示，这些模型可以是独立的，虽然这不是必须的。 与基于CRUD系统中固有的单一数据模型相比，基于CQRS系统中分离的查询与更新数据模型能极大的简化设计与实现。然后，一个缺点是，不能像CRUD，CQRS代码不能通过脚手架的工具自动生成。 读数据的模型和写数据的模型可以访问相同的物理存储，可能通过使用SQL试图或者动态生成映射。然后，通常的做法是将数据分离到不同的物理存储，这样能最大化性能，可扩展性和安全性，如图三所示。 读存储可以是写存储的一个只读副本，也可以有完成不同的数据结构。使用多个只读副本可以提高查询性能和应用的UI响应性，尤其是在分布式的场景中，应用系统的实例可以与只读副本距离很近。某些数据库系统中，例如SQLServer，提供额外的副本故障转移功能来提高可用性。 分离读存储与写存储允许对方能独立的扩展来应对负载。例如，读存储一般都比写存储遇到的复杂要高得多。 当读模型包含非结构化的数据时，在读取应用系统中每个视图的数据或者从系统中进行查询时，性能将最大化。 问题与考虑当实现这个模式时应当考虑一下几点： 将数据存储根据读写操作划分为独立的读存储和写存储，这能提高系统的性能和安全性，但在弹性和最终一致性方面，它增加了相当大的复杂度。读存储必须更新以反映写存储的变化，同时，很难检查用户何时基于一个老旧的读数据发出请求，这意味着操作不可能完成。 考虑将CQRS应用到你系统中最有价值部分，同时从经验中学习。 采用最终一致性的一个典型做法是使用事件溯源（EventSouring）与CQRS相结合，这样读模型就是一些列追加的命令执行的事件流。这些事件用于更新充当读模型的物理视图。 适用场景该模式适用于以下场景： 协同的领域中针对同样的数据有多个操作并发执行。CQRS模型能在领域这个层次上提供最小化冲突的保证（任何出现的冲突都可以通过命令的方式来合并），即使是在更新同种类型的数据。 当时候基于任务视图的用户界面时（用户操作被引导为一些列复杂的步骤），同时你有一个复杂的领域模型，而且团队成员已经对DDD技术比较熟悉了。写模型拥有完整的完整的命令处理堆栈，包含业务逻辑、输入校验、业务校验，以确保写模型中每个聚合的所有内容是一致的。读模型没有验证逻辑或者验证堆栈，只需要视图模型需要的DTO对象。读模型与写模型是保持最终一致的。 在那些需要根据数据写入性能来微调数据读取性能的场景中，尤其是读写比非常高，需要水平扩容的时候。比如，在很多系统中，数据读取操作要比写入操作大几个数量级。为了适应该场景，考虑将读模型进行扩展，但是写模型只需要一个或者少数几个实例就可以了。少量的写模型能最小化冲突发生的概率。 一个团队可以专注于复杂的领域模型，而该模型是写模型的一部分；而另外一个相对缺乏经验的团队可以专注于读模型和用户界面。 系统期望能随着时间演进，同时能维持多个版本，或者业务逻辑会时常变化。 与其他系统进行集成，尤其是结合EventSouring，一个子系统临时的失败不应影响其他系统的可用性。 该模式不适用于以下场景： 领域模型或者业务逻辑很简单。 一个简单的CRUD风格的用户界面，以及其相关的数据访问操作就已足够。 实现跨越了整个系统。整个数据管理场景中特定组件使用CQRS可能很有用，但是需要考虑的是它经常会带来不必要的复杂性。 EventSouring与CQRSCQRS经常与EventSouring相结合。基于CQRS的系统使用独立的读写模型，它们是为其相关的任务量身定制的，而且经常会分不到不同的物理存储上。当使用EventSouring时，存储的事件就是写模型，并且这是信息的权威来源。基于CQRS的读模型提供了数据的物化视图，典型的是作为高度非规范化的视图。这些视图是为用户界面和应用展示需要高度定制化的，这样能最大化展示和查询性能。 相比于使用某个时刻点的实际数据而言，使用事件流作为写存储，能避免在单一聚合上的更新冲突以及最大化性能和扩展性。事件可用于异步生成物化视图，而这些视图是由读存储填充形成的。 因为事件存储是信息的权威来源，所以当系统演进的过程中或者读模型必须改变的时候，是有可能删除物化视图并重放过去的所有事件来重建一个当前状态的新描述。物化视图实际上是数据的一个持久化只读缓存。 当结合CQRS和EventSouring时，需要考虑以下问题： 与任何读写存储分离的系统一样，基于该模式的系统也是最终一致的。生产事件和保存由这些事件发起的操作结果之间会存在一些延迟。 该模式引入了额外的复杂性，因为必须写代码来初始化、处理事件，并组装或者更新因为查询或者读模型所需要的合适的视图和对象。当与EventSouring相结合的时候，CQRS内在的复杂性使得一个成功的实现更加困难。这需要重新学习模型概念，以及一个不同的系统设计方法。然后，EventSouring使得建模更加简单，也更加容易重建视图或者创建一个新试图，因为数据变化的本质得以保留。 通过重放和处理特定实体或者实体集合的事件来生成用于读模型或者数据映射的物化视图可能需要充足的处理时间和资源消耗，尤其当需要对长时间段内值做求和或者分析操作时，因为可能需要检查每个所相关联的事件。这可以通过在预定的时间间隔内打数据快照来部分解决，例如记录下某些操作发生的总次数，或者实体的当前状态。 个人观点CQRS是一种相当常见并且适用性相当广泛的架构模式，我曾经在多个真实的系统中见到该模式发挥巨大作用。该模式的核心观点在于将用于读和写的领域模型进行分割，根据实际的业务场景进行独立的开发和优化，这样带来的好处就是极高的扩展性和灵活性。我们再也不用纠结因为因为领域模型是一个而小心翼翼地处理并发、安全、性能等问题。但是任何架构都有两面性，就像文中所说的一样，该模式会引入额外的复杂性，如果你的业务场景比较简单，建议还是不要轻易尝试。至于EventSouring，个人持有保留意见，因为只保留事件记录的做法过于极端，即使通过快照优化，还是有点过于激进。我相信EventSouring会在少数几个关注于历史数据的业务场景中得到应用，例如审计、金融等，但这种业务相对比较特殊，适用性有限。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>CQRS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程技巧分享]]></title>
    <url>%2F2018%2F12%2F01%2F%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[为什么要写好代码？ 做一个有追求的Coder 好的代码能降低整个系统的复杂度 好的代码能提高系统的可维护性和可修改性 好的代码能提高整体的质量 好的代码能提高你得生活品质 最近和团队内的小伙伴分享了我个人的一些编程小技巧，特此对外分享一下。 分享链接：https://pan.baidu.com/s/1IWUlHadCYXE5M1ASTHPTkg 个人对写好代码的几点感悟： 写代码很难，写好代码更难 写好代码需要长时间、反复、刻意的练习 写好代码是一个高度自律的过程 每次写代码之前或者之后多问几个为什么？ 为什么要这么写？ 有没有更加简单直观的写法？ 这段代码其他人看的懂吗？ 这段代码好复用吗？ 世上无难事，只怕有心人，多总结，多沉淀、多分享！！！ 好的代码更像是一件艺术品，而不是机械化的产物，只有有心的人才能体会其中的精妙！]]></content>
      <categories>
        <category>编程感悟</category>
      </categories>
      <tags>
        <tag>编程技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[漫谈公有云计费]]></title>
    <url>%2F2018%2F05%2F29%2F%E6%BC%AB%E8%B0%88%E5%85%AC%E6%9C%89%E4%BA%91%E8%AE%A1%E8%B4%B9%2F</url>
    <content type="text"><![CDATA[公有云已经进入下半场公有云的发展已经进入下半场，无论是国外还是国内，市场格局已经基本确定，后来者很难再有机会打破现有的格局。纵观国内市场，阿里云一家独大，其他厂商都还在奋起直追，艰难的维持着自己的市场份额。虽然最近两年，不断有大的厂商宣布进军公有云领域，但我认为留给后来者的时间并不多了。公有云是一个强者恒强的行业，随着头部厂商的成熟，厂商锁定(vendor-lock)的现象会越来越凸显，进而越来越多的用户会投入头部厂商的怀抱。虽然，后来者可以在一些细分领域找到某些差异化的优势，但整体格局不会太多的影响。 相信排名靠后的公有云厂商都在思考一件事，我如何进行差异化的竞争？其实这是很难的一个问题，差异化竞争归根结底还是要建立在技术门槛之上，靠其他优势带来的差异化只能是短期的。技术门槛的建立不是一日之功，需要持续的投入和战略级别的支持，所以中小厂商是很难有机会“超车”的，只能争取头部厂商无暇顾及的领域，得以短暂的喘息。 差异化竞争除了在产品、技术方面的竞争，还有一个很容易让大家忽略但又十分重要的点，那就是公有云的计费模式。本人作为一个公有云产生的参与者与亲历者，想谈谈个人对公有云计费的看法。 计费的重要性不知道大家再刚接触云计算的时候是否听说过这样一句话： 云计算会像现在的水和电一样。 这是非常形象的一句话，也是对云计算最终形态的一种展望。但是大家有没有想过水和电是怎样收费的？每个月结束的时候（或者下个月开始的时候）有人上门来抄水表电表，然后根据你实际的使用量把账单给你，最后你根据账单付钱就可以了。 云计算里面有一个很重要的特性，就是Pay As You Go，意思是按你的实际使用量来付费。那现在有哪家云计算厂商做到这一点了呢？现实的答案是：None，没有一家云厂商做到了。你可能会疑惑，难道云厂商的”按量付费“不是按用户的使用量付费吗？还真的不是。用户去公有云厂商买一台云主机，云厂商会提供各种类型规格的主机供你选择，然后你根据自己”预期“的需要选择一台。大的云厂商可能会提供非常多种类的云主机，按用户的使用场景进行细分，是的云主机能更加贴合用户的真实场景，但这样做也仅仅是减少了你花的”冤枉钱“而已。你购买的绝大部分云服务以低负载的模式运行，而你用不到的那部分资源被无情的浪费了。当然，这种浪费是针对用户而言的，云厂商可不会因为你没有完全使用云主机而把多余的部分退还给你。这种现象在计算资源和带宽资源方面表现的尤为突出，存储相对而言要好一点。 现在情况相对来说要好点了，大型的云厂商开始提供”竞价型实例“来缓解这一现象。用户可以把自己多余的计算能力进行公开的售卖，而计算能力不足的用户也可从”市场“上买到价格合理的计算资源。这有点像股票市场，让用户来决定资源的价格，当然，这个市场也是受云厂商控制的。另外，越来越多的厂商提供”按秒计费“，也就是计费的时间粒度可以精确到”秒“，但这仅仅是时间维度的贴合，资源的实际使用量还是不会影响你的账单。也许，Serverless才是最终的计算形态，相对其他的计算形式，它可以更加接近Pay As You Go的宣言！本人也十分看好Serverless的发展。 但短期内，云主机并不会消亡，容器技术也在逐步成熟，如何调和用户对资源的诉求和成本控制之间的矛盾将成为公有云厂商一个有利的竞争点。我们知道，Dropbox因为成本问题，从AWS上迁移出来，自建数据中心，从其官方的说法中，它减少了巨大的成本。这是公有云厂商都会面临的一个问题，当用户使用的资源量达到一定的级别，它会发现自建的成本会比使用公有云的成本更低，而公有云厂商无法给出一个双方都能接受而又不扰乱市场的定价，最终只能一拍两散。实际上，这对双方来说损失都是很大的，因为”上云“需要成本，而”下云“更需要成本。造成这种结果的原因无疑是多方面的，其中的一个原因就是云厂商无法准确的评估用户的资源使用情况，而呆板的计费策略造成用户为大量的浪费资源而付费。 云计算发展到今天，很多技术已经相当成熟，各家云厂商的产品也越来越趋同。在产品同质化如此严重的情况下，提高云平台整体的”软实力“就相当重要。而公有云的计费无疑是”软实力“中最重要的一个因素。不得不承认，无论用户是创业公司还是像Dropbox和Netflix这样的明星公司，成本控制都是相当重要的一环。而产品的计费策略直接与成本挂钩。降价、打折、促销只能是短期吸引用户的手段，最为核心的竞争力在于产品的计费模式能多大限度的贴合用户的使用场景。一个好的计费策略可以极大的提高产品的竞争力，毕竟这将直接关系用户的钱。 售卖形式与产品定价IaaS、PaaS和SaaS的云服务的售卖形式有着巨大的差别，而且越接近SaaS形态，产品的售卖形式越特化。云服务的产品和负责人需要根据自身产品的特性，谨慎的思考产品的售卖形式。因为公有云的产品与其他的互联网产品有着一个显著的区别，那就是用户的使用方式将直接影到产品本身的开发。云服务的用户基本上都是高端用户，主要面向程序员、SA、PE等软件开发运维人员，他们将直接使用产品提供的OpenAPI、SDK，这就导致了使用方式与产品特性的深度耦合，从而使得云产品在后期的迭代过程中必须考虑向前兼容。售卖形式是云服务产品形态的重要一环，前期的小心设计大大降低后期产品在迭代过程中的兼容负担。我相信谁也不愿意在产品正式售卖之后，发现售卖形式完全错了，而已经在使用云产品的用户会让你大为头疼。 IaaS产品的售卖形式现阶段已经比较成熟，计算、存储、网络都有着比较标准的售卖模式，这些售卖形式已经被用户所接受，并形成了业界共识。IaaS产品基本上都是按资源的“占用量”来进行售卖的，但“占用量”这里面大有学问，各个云厂商都有着自己的超售比，而超售比是厂商的一个机密数据，用户永远不会知道自己的云主机运行在一个超售比多少的物理机上。前面也介绍过，按资源的“占用量”来售卖会造成用户为没有使用到的资源付费，最终得原因在于厂商无法精确得评估用户所需的计算资源以及能在获取短时间内调度大量计算资源的能力。所以云厂商最终把这个问题抛给了用户，让用户决定自己需要的计算资源。但这并没有解决问题，这仅仅是对厂商友好的一种计费方式而已。然而用户似乎比较满意现在的售卖模式，可能因为人都有“占有欲”吧，当然你需要为这种“占用”付出代价。 相比于IaaS，PaaS产品的售卖形式开始变得复杂了。不同于计算、存储、网络独立计费，PaaS产品“有机地”将三类资源进行组合，并根据产品本身的特性来提供“增值业务”。比如，RDS会提供高可用版或者集群版，除了底层独立占用几台云主机外，还会提供高可用、定时备份、数据操作、水平垂直扩容等服务。PaaS的核心价值也体现在这种高附加值的服务上。如果PaaS使用起来不方便，经常出问题，用户购买的PaaS服务的意义又在哪里呢？所以PaaS的定价一定不是在于底层资源的占用了，当然这是一个考量因素，但更为重要是PaaS产品提供的高附加值服务，这也是用户购买PaaS产品的初衷。一种简单的售卖形式就是将这些服务和底层资源全部打包在一起进行售卖，因为这些服务往往是建立在具体实例之上的。这种做法的一个明显缺点在于，这些高附加值的服务与底层资源绑定了，导致了这些服务无法独立的售卖，从而降低了整体的灵活度。可能用户仅仅需要RDS的高可用特性，而无须定时备份等功能，是否可以考虑降低用户的购买成本呢？ SaaS与PaaS的一个共同点在于他们都对用户屏蔽了底层资源。也许用户在使用PaaS服务的过程中还能零星的感知到底层资源的存在，但在SaaS服务中他们就已经完全感知不到底层的基础设施了。一个有趣的问题，大家是否认知的思考过，AWS的S3到底是IaaS、PaaS还是SaaS呢？相信不同的人会有不同的看法。随着云计算的成熟，必将会出现越来越多的难以简单划分的服务出现。因为SaaS产品已经完全对用户屏蔽了资源占用的概念，那么它的售卖形式肯定不再是以资源的维度来定价，而应该从SaaS产品本身提供的功能出发来定价。例如，某个搜索服务产品，它的主体功能提供了数据索引与搜索，那么它的售卖形式必然会以索引和搜索的数量来进行售卖。相比于IaaS和PaaS，SaaS服务更容易达到“Pay As You Go”的理念。令人遗憾的是，某些SaaS产品出于简单的需要，而仅仅将整个SaaS产品打包售卖，又回归到了以资源占用为维度的老路子上，这实际上是本末倒置的。 我一直觉得给产品定价是一项极具挑战的任务，因为涉及到的因素实在太多了。超售比、成本、调度策略、市场环境、产品特性等诸多因素都会影响产品最终的价格，而这些因素很难有一个简单的公司来调和。本人在这方面也没有多少经验，不敢妄言。但我还是建议厂商根据自己的实际情况来考虑自身的定价策略。大的厂商一定要有自己的定价逻辑，针对不同的产品线有不同的定价基准，而具体的产品可以在这个基准之上进行调节。而小的厂商尽量参考大厂商的定价逻辑，这有利于形成差异化的竞争力。但总体来说，产品定价还是一项十分复杂的工作，有能力的厂商需要建立自己的定价团队。好的定价策略会让你赢在起跑线上。 结算方式与计费策略国内与国外的云计算厂商在结算方式有一个明显的区别，国外的厂商更偏向于后付费，而国内的厂商更喜欢预付费。这可能与国内外的使用习惯，信用环境有关系，但这已经是一个既定的事实。国内的预付费方式无疑加重了计费系统的负担，因为预付费的收费逻辑与后付费的逻辑是完全不同的，况且真实的环境是两种方式的组合。 预付费的逻辑是期望能尽早地锁定用户，把钱先收进来，但先收的钱并不能纳入到厂商当前地实收中，因为大部分是未来预期地收入。这种做法的一个巨大的好处在于将用户锁定，一旦用户已经支付了未来的使用费用，那么他潜在的心智更期望能物尽其用，反过来进一步增加了用户粘性。国内的厂商基本上都极力推崇这种方式，甚至不惜以高折扣的方式来补贴用户，也希望能锁定用户。这实际上是技术上不成熟的无奈之举。 实际上，后付费是最符合”Pay As You Go”的理念的。用户只需要为他们使用的资源付费，如果还没开始使用，那有何来付费之说呢？排除国内外的差异因素，我觉得AWS一开始就走在了正确的道路上。虽然AWS也支持预留实例，但这仅仅是一种获取折扣的方式，大部分产品都是在使用后根据账单来结算的。后付费的另外一个优势在于它更有利于云产品与计费系统的解耦，因为用户无需在使用之前完成下单、支付与产品无关的交易行为。 采用预付费还是后付费，又或者是两者的组合，还是要根据产品本身的特性出发。我看到一些很复杂的产品，它实际上更加适合后付费模型，而偏偏采用预付费方式，造成用户在购买上面遇到了很多问题。一个简单有效的经验是，如果产品本身的构成比较简单，采用任何一种付费方式或者组合都是可以的；反之，如果产品的构成比较复杂，建议使用后付费。产品构成是指用户可感知的产品元素，举个Redis的例子，一个高可用版的Redis Sentinel可能由3台Sentinel和一对Master-Slave节点构成，但对用户暴露的仅仅是3个Sentinel的链接地址，那么用户感知到的产品构成是比较简单的。另外一个例子，比如托管型的ELK服务，该服务对用户暴露了ElasticSearch、LogStash和Kibana，产品构成就比较复杂了，如果采用预付费的收费模型，那么该服务在扩展时就会与订单与计费系统产生大量的交互行为，降低了用户体验。 谈到计费策略，可能让人首先想到的是“按量计费”、“包年包月”等词汇，这些词汇是厂商为了更好的进行销售而形成的一套特定用语。我们先抛开这些让人眼花缭乱的名词，思考一下为什么需要计费？如果用户选择后付费，那么我们需要记录用户资源的使用情况，然后根据产品的计费模型计算出用户的账单，这是计费最核心的功能。那么如果用户选择预付费呢？当然我们不需要计费了。 现实的情况是复杂的。某些产品的计费模型十分灵活，可以部分预付费部分后付费，那么就要求计费策略可以下沉到计费项这个级别。一个比较典型的例子就是，经典云主机可能在创建时获得一个公网IP，整个云主机可以包年包月购买，而公网IP部分又可以按流量计费。先不看技术上如何实现，需求层面是否合理。现在的一个趋势是，云产品越做越大，越做越细，越做越复杂，如果再将整个云服务打包卖个用户已经跟不上市场的节奏了。一个云服务的构成可能需要多种资源的配合才能完成，但是资源之间的配比和售卖形式是可以不一样的，按照资源粒度去售卖可以更加贴合现实的使用场景，降低用户的成本。总体来说，需求是合理的，也是一个必然的趋势。计费策略可以很灵活，但一定要形成统一的标准。只有在统一的计费模型上演化，系统的复杂度才可控，产品也能把握整体的一个节奏。 技术实现不得不承认，要做好公有云的计费非常难，这种难度在于对公有云行业的深入理解、对云服务产品计费模型的准确把握以及计费系统本身的非功能性要求。我分享一些此方面的一些经验。 抽象化与建模最开始的时候，计费系统并没有将云服务产品抽象化。在前期产品不多的情况下，我们还能针对一个个具体的产品编程，理解各个云产品的计费逻辑。但随着业务的加速发展，这种方式已经跟不上业务的要求了。我们意识到必须把产品的计费模型抽象化出来，我们根据这个抽象化的模型去编程，这样将大大提高系统的扩展性。后期的重构过程中，我们也确实是这么做的，并且达到了我们的预期效果。但是随着一些SaaS型或者复杂PaaS型产品的出现，我们第一版的抽象化模型已经很难适应了。那是不是我们需要进一步抽象化呢？其实不然。抽象化是有代价，当你提高了抽象化等级，结果只有一两个产品受益，大部分产品没有从中得到任何好处，其实这已经是过度抽象化了。解决这个问题的一个方式就是建立一个不同的模型。前期我们总想着只用一个模型就能解决所有产品的计费，实际上这总想法太天真了。每个产品的计费策略和模型都不一样，SaaS型产品和IaaS产品的计费方式差异巨大，如果想用一个模型搞定所有问题，只能得到一个难以理解和维护、需要处处小心、高度复杂的模型。所以，如果发现某些产品的计费方式与其他产品的差异巨大，去建立另外一个模型吧！ 定好规则计费系统很难做的原因之一就在于很难建立一个统一的计费模型。有人可能会说，使用规则引擎吧，还有流程引擎，但是这些技术都是建立在你有着一个相对统一的模型基础之上的，如果没有计费模型支持，那么整个系统只能是空中楼阁，就算能正常运行，也不能灵活扩展。 当你的系统为几十种其他系统服务时，定好规则就十分必要了，这也符合”中台“的思想。如果你建立了一种模型可以适应于多种计费场景，那么剩下的就是为这个模型定好规则，推动业务方按规则接入就行。在这个过程中，可能会遇到很大的阻力（可能有些业务方比较强势），但你也要坚持自己的原则，不要轻易动摇，更不要专门为单独的一两个业务去适配。因为一旦你这么做了，那就是噩梦的开始。 尽量解耦我一直在谈计费，但这里的计费其实包含了云服务完整的售卖过程，涵盖订单、优化、支付、计费、结算完整的售卖链路。每一步都可以独立拉出一个系统来做，也建议独立系统来做。如果人员不够，可以考虑先将系统拆分，由不同的人来维护几个模块。现在微服务架构十分流行，可以考虑使用微服务架构来解耦系统。除了系统内部的耦合，我们也需要交互流程上尽量解耦。AWS在这方面是有天然优势的，因为它主推后付费的模式，云服务和计费系统前台界面上基本没有交互过程。减少与云服务的交互过程，将极大地降低系统地复杂度，提高整体地稳定性，毕竟计费系统要服务于整个云平台。 总而言之，公有云计费很重要，也很复杂。做好公有云的计费需要投入大量的资源，更需要丰富的经验。现阶段的计费模式还存在诸多不合理的地方，还有很多可改进的空间。预计随着公有云的进一步发展，可能会逐渐淘汰目前计费方法，出现更多更灵活的计费模型。最终的发展方向肯定是实现”Pay As You Go“的终极理想！ 参考资料 Deceptive Cloud Efficiency: Do You Really Pay as You Use?]]></content>
      <tags>
        <tag>cloud</tag>
        <tag>云计算</tag>
        <tag>计费</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计入门]]></title>
    <url>%2F2018%2F04%2F23%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[最近在团队内部分享了一些关于架构设计方面的基础知识，特此分享一下。 分享链接：https://pan.baidu.com/s/1GXkudSSD-az03wRf6IXj2g]]></content>
      <tags>
        <tag>架构</tag>
        <tag>系统架构</tag>
        <tag>代码架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蜂巢计费系统架构升级之路]]></title>
    <url>%2F2017%2F12%2F15%2F%E8%9C%82%E5%B7%A2%E8%AE%A1%E8%B4%B9%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%8D%87%E7%BA%A7%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[项目背景蜂巢计费系统为网易云基础服务（网易蜂巢）提供整体的计费服务，业务范围涵盖完整的产品售卖流程，包含定价、订单、支付、计费、结算、优惠、账单等主体功能，支持十几种不同产品的售卖，产品形态上贯穿了IaaS、PaaS和SaaS类别。同时，计费方式还提供了了按量、包年包月、资源包等多种方式。该项目的业务范围之广，玩法种类之多，数据要求之严注定了它将成为一个烫手的山芋，而且还是一个吃力不讨好的工作。 该项目在人员上已经几经易手，就我所知，已经换过两拨完整的开发和测试团队了，而且已经全部离职。不得不说，该项目已经变得令人谈之色变，让人敬而远之。在这样的背景下，后期接手的开发和QA不得不硬着头皮上，踩着雷过河，小心翼翼的应对着不断涌来的业务需求。随之而来的是高居不下的bug率，越来越难以维护的代码，无法扩展的架构问题，我们开始意识到这样下去是不行的。于是我们从8月份开始了漫漫的架构升级之路。 重新出发在我们开始优化架构之前，我们重新梳理了计费系统完整的业务，得到了如下图所示的业务领域： 梳理以后发现，计费系统承载了太多非计费的业务，包含订单、账单、结算和代金券等，这些业务代码散落在各处，没有严格地业务边界划分，而是“奇迹般”的融合在了一个工程里面。造成这个局面的原因在于计费系统初版设计时，根本没有考虑到这些问题，当然也不可能考虑到，而在后面逐步地迭代过程中，也未能去及时地调整架构，架构腐化不是一天内完成的。当然，这方面有部分技术的原因，也有部分人为的原因所在，因为当时负责计费系统的开发就只有一人，还是刚毕业的同学。目前看来，也是难为这位同学了。 技术债务的问题不是小事，千里之堤毁于蚁穴。既然我们找到了问题的症结所在，那么解决的方式也就显而易见了，一个字：拆！我们分析了所有的业务，订单是最大也是最复杂的一个业务，而结算和账单考虑到后期有可能迁移到云支付团队，我们决定优先把订单系统拆分出去！ 拆分的阵痛订单拆分说起来容易，做起来难。套用一句业界常说的话，就是开着飞机换轮胎。因为在我们拆分的同时，不断地有新的业务需求进来，还有一些bug需要处理，所以不太可能让我们专门进行拆分的工作。因此，为了不影响正常的业务迭代，我们决定拉出独立分支进行开发。我们分出两人专门处理拆分的工作。 为了最小化风险，订单拆分我们分了两步进行：一，模块独立；二：系统独立。 模块独立模块独立是将订单的代码首先在工程内部独立出来，我们采用独立Module的形式，将订单独立成了一个Order的模块。它拥有完全独立的服务层、业务层以及持久化层。其他模块可以依赖Order，而Order不能依赖除公共模块外的其他业务模块。整体的模块划分如下图所示。模块的拆分过程中我们也发现了原先很多不合理的地方，例如：其他服务直接操作订单的持久化层(DAO)、模块直接依赖关系混乱、Service所在的Pacakge不合理、存在大量无用的代码和逻辑、随意的命名等。我们边拆分边重构，虽然进度比预期要缓慢一些，但整体上在向着合理的方向进行。 模块独立的过程中我们遇到了业务层级关系的问题。由于订单模块不再依赖于其他业务模块，而又有一些业务逻辑是由订单触发的，需要在计费模块完成，我们又不能直接调用计费模块的Service。针对这个问题，我们采用了领域事件的方式来解耦，简单来说就是订单通过发布事件的方式来与其他模块进行通信，当时实现的代码其实也相当简单，可以参考: https://gist.github.com/mymonkey110/aba58de452928bec2243848bb2c9b84a 我们并没有独立拆分web层，因为系统还没有独立，web层作为统一的打包入口也承载着订单的流量。而且，Controller层的逻辑相对比较简单，完全可以在系统独立时再做。通过大家的努力，8月底订单已独立模块的方式上线了，一切正常。 系统独立模块拆分完成后，仅接着就是系统独立，此时我们需要将订单系统独立部署。这里一个关键的问题是，独立部署意味着单独提供服务，而依赖订单系统的业务方非常之多，包含前端、主站、大部分的PaaS业务和计费，都有需要直接依赖订单接口的地方，冒然独立风险很大。针对这个问题，我们采用使用haproxy七层转发代理来将流量分发到不同的vip来解决。虽然，在上线过程中遇到了一些坎坷，但最终还是成功了。现在看来这个选择是非常对的，因为这样可以在业务方无感知的情况下平滑升级。但长远来看，最终我们还是以独立的vip对外保留服务。 订单和计费直接我们采用RabbitMQ来完成主体通信，关于采用MQ还是HTTP调用我们内部还进行了一番争论。之所以最终还是采用MQ来进行通信，是因为我们发现很多业务流程并不需要计费系统立即响应（大部分流程都是订单触发的），也就是我们常说的弱依赖。另外，职责上计费系统的响应的质量也不应影响到订单的主体流程，举个例子：用户支付了一个云主机的订单，如果计费系统此时无法响应，业务上相对来说可以接受过一小会儿计费再处理，而不是把订单直接退款给用户。MQ的引入在技术和职责层面都将订单和计费分的更开了。当然，强依赖的服务是我们无法避免的，其中之一就是结算模块还留在计费中，订单需要通过接口调用结算服务来完成支付。 前期，我们在模块独立时采用事件解耦的方式，在此时也获得了收获。我们通过一个统一的转化层，将那些事件直接转化层RabbitMQ可以识别的消息，这样代码的改造工作就大大减少了。 系统独立后一个直接的表象就是每个系统的代码行数大大降低了。独立前，整体的代码行数已经达到了12W行以上（包含配置文件），独立后，计费系统降低到了10W以下，订单维持在4W以下。代码行数的降低将直接提高系统的可维护性。个人认为如果一个工程里的代码超过10W行，那么维护性将大大降低，除非是那些有着严格自律意识的团队，否则，我建议还是尽量降低代码行数。 经过大家一个月的努力，订单系统终于已独立的姿态提供服务了。过程很艰辛，但是收获良多。 拆分的收获订单独立后，一个直接的好处就是我们能独立的思考问题了，这在以前是很难做到的一件事情，因为大家不得不小心翼翼的处理那些依赖，做事会畏手畏脚的。另外一个好处就是，我们的工作可以有侧重点的进行了。订单业务可以说是产品最为关注的业务，也是计费对外暴露的主要入口。下图就是我们在拆分后规划订单的业务架构，大家对后期的订单规划充满期待。 多Region的挑战公有云产商面临的一大挑战就是多Region环境的支持。普通的互联网行业出于高可用的考虑，往往会把核心系统部署到多个机房，然后根据自己的实际应用场景选择冷备、双活甚至三活。我们经常听到的“两地三中心”、“三地五中心”等等高大上的名词就是代多机房高可用的缩影。这些行业做多机房部署的主要目的是为了提高系统的可用性，不是其业务的必须属性。换句话说，他们不做多机房部署也可以，做了当然更好。而公有云产商不一样，多Region部署就是其行业属性之一。如果哪个云产商不提供多region产品的支持，那么它肯定是不完整的。不得不承认，我们在这方面的经验是比较欠缺的，在多Region的支持上走了一些弯路。 摸着石头过河今年上半年的时候，蜂巢开始计划启动北京Region，预计年中交付，当时对我们横向业务提出了很大地技术挑战。一是在于横向系统设计之初并没有考虑到对Region环境的支持，我们很被动；二是我们并没有跨Region系统设计的经验，我们很着急。计费系统面临的问题更加严重，因为它对数据的一致性要求更高，而且出错地影响范围也更大。而且当时计费的技术债务已经很高了，产品的需求列表也拍了很长，套用一句很形象的话说，“留给我们的时间不多了”。 在这种情况下，我们“胆战心惊”的给出了第一版的多Region设计方案，主体架构如下所示： 因为当时计费系统还没有拆分，所有的业务都在一个系统中完成的，就是我们常说的“大泥球”系统。这种情况下我们很难做到多Region部署，订单和账单其实只有在一个Region部署就可以了，而计费的数据采集和请求分发是要下沉到各个Region的，而计算过程可以集中完成。采用”双主”同步复制的方案实则是无奈之举。数据库的同步只能基于实例级别，而无法细分到表，我们各Region中计费数据库中存在资源的计量表，这个数据需要同步到杭州Region来完成。为了避免“脑裂”的问题，我们特别将该表的主键采用UUID的形式。存量表因为无法做大规模修改，我们通过限制北京MySQL用户的权限来避免写入和修改全局表。 这个设计很糟糕，但是当时的条件限制，我们也拿不出更好的设计了。虽然上线的过程有些曲折，当这个架构还是成功运行了，这是令我们最为欣慰的事情。因为为了适配这个架构，团队的小伙伴做了很多工作。不可否认，这个架构存在诸多弊端，其中最大的隐患就在于数据库的“双主”同步，这就像一颗随时会爆的炸弹萦绕在我们心头。当时专线还没有搭建好，所有的流量均通过外网隧道代理，糟糕的网络质量无疑放大了这个风险。为此，DBA们向我们吐槽了好久，幸好我们抗打击能力很强。 涅槃重生在做完双Region的支持以后，计费团队就继续做产品需求了，因为架构调整导致需求列表已经很长了。而且当时也说的是，短期内（至少今年）不会再有第三个Region了，我们也想着快点做完，多花点精力投入到重构中。但是计划赶不上变化，9月底我们被通知到第三个Region来了，而且已经被提高到第一优先级支持了。 有了第一版双Region的经验，这一次我们淡定了很多。当然，我们不可能在沿用第一版的设计了，因为DBA就会跟我们拼命的。回过头来梳理多Region支持面临的问题时，我发现一开始我们就自己给自己挖了一个坑，然后往里面跳。横向支撑系统显然都需要对所有Region提供支持，但这并不代表其需要在各个Region内部署(我还与团队其他的小伙伴分享了这方面的想法，网上应该还能找到这一次分享的ppt——《跨Region实践初探》)。因为公有云产商经常会提供多个Region的服务，有得甚至达到几十个Region，如果横向支持系统每个Region都要全量部署的话，那么我们花在运维上的精力就可以拖垮我们，更不要说还有最为困难的数据的一致性问题。 其实多Region的支持的问题我们总结出主要表现在一下两个方面，一是应用层面的接口互通；二是底层数据库的同步。 我们先说底层数据库的同步，对计费系统而言，数据的一致性是至关重要的，但多机房部署是在挑战CAP定律。是不是就没有了这样的数据库方案了呢，有，那就是Google的Spanner，号称可以在全球做到强一致的数据库。但是我们没有这样的数据库。其实我们也考虑使用NoSQL数据库——Cassandra，但是这个数据库运维起来太复杂，我们也没有这方面的经验，也就放弃了。还是回归到MySQL，受限于传统关系型数据库在扩展性方面的问题，我们不可能把整个库在各个Region都同步一份。但是计费原始数据又必须在各个Region内收集，于是我们决定——拆，把计费拆层两个部分，分为bill-agent(数据采集)和bill-central(数据计算)两个部分。 Bill-Agent负责Region内日志的收集和简单聚合。 Bill-Central负责日志收集外的全局事务处理。 通过这样的拆分，架构就清晰多了。再多加Region，我们只需要部署Bill-Agent就可以了。Bill-Agent将处理过的计费数据写入本地库的一张资源表，利用NDC（马进在网上分享过关于这个中间件的介绍）将资源表单向同步到Bill-Central的中央库，然后Bill-Central统一在对计费数据进行处理。有意思的是，这张资源表就是我们在第一版设计中新建的资源表，因为我们将主键修改为UUID，所有使用NDC同步表的方案是相当顺利的。当然，NDC在我们其他项目的跨Region支持上也发挥了重要作用，比如：跨机房缓存更新的问题。这一版的数据库方案在技术评审时大家都比较满意，DBA也肯定了我们的方案。 现在再来看跨Region调用的问题。在多Region的横向系统中，我们发现或多或少的存在着机房间的接口调用问题。这些问题有可能是某些Region的库不能写需要路由到主库来写导致的，也有可能是全局缓存的问题，还有就是Global业务向Region内服务发送指令。计费属于最后一种场景，我们有一些业务场景需要由杭州Region触发，然后调用各个Region内的服务的接口。在第一版的实现中，计费系统自己实现了跨Region代理部分，但是实现的不是很好，代码的可维护性比较差，加重了调试的难度。这一版的设计中，我们决定把跨Region接口代理单独拿出来重新做，结合多Region的应用场景，然后封装一些非功能性的特性，这就成了后面我们很重要的一个组件——RegionProxy。 RegionProxy最开始是为了解决跨Region调用的非功能性问题，简化应用系统处理的成本。但是设计上经历了比较大的调整。最开始的设计我们是希望Region内所有跨Region的HTTP调用都能通过RegionProxy来代理，RegionProxy之间能够发现对方并且相互通信，那么Region内的应用系统就只需要与本Region的RegionProxy通信就可以调到任意一个Region的应用系统了。但是在方案评审的过程中，我们发现如果都用RegionProxy代理，可能会导致跨Region调用多出一跳或者两跳，调试可能会比较困难。后来，我们放弃了这个方案。再后来，我们发现ServiceMesh的方案和我们最初RegionProxy的方案是十分相似的。 在RegionProxy的设计上我们进行了简化处理，我们将所有Region的业务系统录入到一个全局的配置中心(我们自己开发的ConfigCenter)中，然后通过一个自己开发的一个HttpProxy的Java库来与ConfigCenter通信来完成跨Region的调用。这样做的好处就是使用方用起来比较轻量，但是在网络连通性方面我们需要与所有Region的系统做到互通。在开发Proxy库的时候，我们不仅对跨Region的HTTP调用进行了封装，而且对普通的HTTP调用也加入了非功能性的封装，这样系统可以通过Proxy库完成所有的HTTP调用请求，极大的简化了代码的维护成本。后面，我们使用RegionProxy来代理请求后，确实删除了很多以前的无用代码，整体流程上也清晰了许多。 多Region的感悟经过两版多Region的改造，我们确实收货了很多宝贵的经验，非常难得。实际上，在多Region的支持上，大家需要清晰地认识到为什么要支持多Region，以何种方式去支持多Region，多Region支持与高可用的关系等基本问题。如果这些问题回到不好，或者不清楚，那么很容易就会掉到陷阱中去。另外一个感悟就是结合业务的实际场景，第二版的多Region架构我们之所以能够这么设计，就在于计费系统不需要实时出账，我们完全可以把数据保存下来，离线计算以后再出账，这是可以接受的。但这并不适用与所用情况，有些性能要求很高的横向业务就不适合这种场景。 拿来主义前面提过几次技术债务的问题，有些问题是可以通过工具来解决了，有些只能通过内部重构来解决。左耳朵耗子曾经说过一句话对我感触很大，大意是说有些公司在解决问题时偏流程，有些公司偏技术。我想我们既然是技术团队，在解决问题时能通过技术方式解决的就应该尽量用技术解决，流程和人都是不可靠的。 难以管理的配置文件计费项目面临的诸多问题之一就有配置文件的管理，因为业务流程的原因，计费系统有着大量的各种各样的配置。以前我们把配置文件放到工程里面，通过自动化部署平台来指定使用不同的配置文件。这样做的一个显著问题就是代码和配置耦合起来了，每次修改什么配置都得提交代码，而我们提交又有着一套严格地流程，导致整体效率不高。另外一个问题就是可视化的问题。往往QA在线下环境测试都是通过的，而上线以后出了问题，基本上都是配置导致的问题。针对这几个的问题，我们决定使用Apollo来管理我们的配置，通过整合Apollo，我们的两个项目（订单和计费）都做到了工程零配置，所有的配置都放到Apollo上进行管理，好处良多。 替换定时任务框架计费系统严重依赖于定时任务，有许多流程需要通过定时任务来推动。以前我们使用QUARTZ+MYSQL来作为我们分布式定时任务框架，但是这种做法的可维护性太差，而且对数据库侵入很高，对测试也不友好。在QA的不断吐槽中，我们决定替换掉现有的定时任务框架。在调研开源的定时任务框架后我们决定使用Elastic-Job来作为我们的分布式定时任务框架。目前，我们的两个项目的所有定时任务（除bill-agent外)都已迁移到Elastic-Job上来了。 抽象化设计如果你要问我做蜂巢计费最困难的地方是什么？我的回答肯定是业务太复杂了。这种复杂性不是因为我们架构设计的不好导致的复杂，而是业务本身就是十分复杂的。现在计费系统需要支持十几种产品的售卖形式，涵盖IaaS、PaaS和SaaS的绝大部分产品，同时各个产品的售卖和计费模式都存在或多或少的差异，这让我们很难通过一个统一的模型就涵盖所有的场景。我们找到了一条缓解这个问题的方式——抽象化。 横向系统或者支持系统如果需要服务多个产品，那么抽象化设计是不可或缺的一个缓解。如果越早进行抽象化，那么后期对接和维护的成本也就会越低，还能把系统的边界划分得更清晰。计费系统早期的设计在抽象化方面没有过多的规划，在后期的对接方面又处于比较弱势的一方，导致计费系统出现了大量的特化代码。这些特化代码对一个服务十几个产品的支持系统无疑是伤害巨大的。现在我们已经意识到了问题的严重性，也着手在做这方面的重构工作了。但是挑战依然很大，因为业务的复杂性是无法通过技术手段就能降低的，这方面我们只有和产品、运营和销售各方面一起努力，打造一个合理、灵活、稳定的新计费。 抽象化设计因为我们还在进行中，后期有机会再分享。 总结从八月底加入计费团队以来，收获良多，无论是在技术上，还是在对业务的理解上，都有了许多新的认识。最为给力的还是团队的小伙伴们，因为计费本身的需求非常多，处理这些需求人都只刚刚够。后来我们又做了两版跨Region改造、订单拆分、框架替换、抽象化等优化工作，迭代周期从两周一次压缩到了一周一次，开发和QA的小伙伴也都是任劳任怨。当然，大家能在这个过程中有所收获才是最关键的。 计费系统可以说是我接触过的最为复杂的一个系统，越是复杂的系统越需要清晰的头脑和良好的设计。云计算产商的博弈已经到了白热化阶段了，大家拼的不光光是每个产品的质量和体验，还有整个云平台的内功。公有云平台本身就是一个庞大、复杂的系统，如何把这个系统建设好，用户体验做好、服务质量提高、稳定性得到保障，这本身就是极为有难度的一件事情。计费系统作为公有云平台一个重要的组成部分，可以说扮演着一个极为关键的角色。做得好可以对整个平台提供助力，而做的差则会拖慢整体的发展进程。我们已经找到了适合自己的一条道路，相信会走上正轨！]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>云计算</tag>
        <tag>计费</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程心智(二)——二八定律对软件开发的影响]]></title>
    <url>%2F2017%2F11%2F03%2F%E7%BC%96%E7%A8%8B%E5%BF%83%E6%99%BA-%E4%BA%8C-%E2%80%94%E2%80%94%E4%BA%8C%E5%85%AB%E5%AE%9A%E5%BE%8B%E5%AF%B9%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E7%9A%84%E5%BD%B1%E5%93%8D%2F</url>
    <content type="text"><![CDATA[相信很多人都听说过二八定律，这是一个适用性非常广泛的定律。我发现二八定律同样适用于软件开发，并对其产生了十分深远的影响。这次我想聊聊二八定律是如何影响我们日常的开发工作的，希望通过这个话题来改变一下大家习以为常的开发思维。 定义二八定律是19世纪末20世纪初意大利经济学家巴莱多发现的。他认为： 在任何一组东西中，最重要的只占其中一小部分，约20%，其余80%尽管是多数，却是次要的，因此又称二八定律。 二八定律有相当广泛的普适性，不论是在生活中，还是在工作上，只要你细心观察，都会发现其身影。 功能需求对软件开发的影响不知道大家有没有发现这样一个事实，随着我们系统要处理的业务功能越来越多，我们添加一个新功能的代价也越来越大。很有意思，我发现业务功能与添加一个新功能要做出的努力呈现出类似于下图所示的关系。 起初，为了使得一个新系统能运行，我们不得不处理一些非业务性的工作，比如搭建框架、技术选型、架构设计、部署结构设计、资源申请等等。而一旦这些基础性的工作完成，那我们就可以快速的完成业务需求。大概花费我们20%的精力就可以满足80%的业务功能，这些业务功能也是系统的主要功能。但是再往后新增功能，所要做出的努力就会成指数增长。这张图与P o EAA中的领域逻辑复杂度与工作量之间的关系类似。当然，这个曲线并不是绝对的，影响这条曲线的关键在于系统的代码架构，好的代码架构能让你在处理复杂的业务需求时更加从容。（题外话，我认为一个优秀的程序员应该具备处理复杂需求的能力。） 既然我们发现了这个规律，是否能指导我们的日常开发工作呢？答案是肯定的。因为80%的功能基本已经满足了大部分人的需求，而为了满足少数人的需求而增加80%的努力是不值得。当然，公司完全有理由要求你这么做，与此同时你也可以把这个利害关系介绍给他们听。 甚至在细分到x轴和y轴，我们可以继续运用二八定律来分解。80%的业务功能其实大概只有20%是核心功能，其余的只是为了优化体验或者简化流程为存在的；而对于20%的努力而言，其中80%的工作主要集中在满足核心的业务需求而存在的，我们应该也必须投入这么多精力来设计并开发这些功能，因为它们是整个系统的核心。 性能优化对软件开发的影响程序员总是对性能优化这个话题充满激情，好像这成了唯一彰显其技术能力的手段。确实，要把应用系统的性能优化到极致，确实要付出大量的努力。但实际上性能优化所付出的努力与取得的效果也符合二八定律。其工作量与索取的效果类似于下图所示。 不消多说，凡是做个性能优化的同学应该都会有这样的感触：只用加个索引或者加上缓存就可以使得系统的性能大幅度提供。使用常规的优化手段（大概耗费20%的精力）就可以取得显著的效果（提升80%的性能）。但是要取得另外20%的性能提升要付出努力将大大增加。掌握这个规律相信大家应该知道如何“使力”了。 项目人数对开发效率的影响还一个比较显著的符合二八定律的场景就是在项目管理上。 同时参与一个项目的人并非越多越好，实际上影响应项目进度只取决于少数人（20%），后面增加更多的人其实收效甚微。我个人也是倾向于不要在一个项目上投入过多的人力，要精不要多。现在微服务这么流行，我觉得也有类似地影响。它在架构层面把一个大系统拆分成一个一个小服务，让每个服务有少数几个人负责，这样整体的开发效率会更高。 小结类似上面的例子还有很多，比如迭代周期对软件质量的影响、服务数量对整体可用性的影响等等，只要你细心观察就会发现二八定律在我们的日常开发工作中无处不在。更为重要的是，我们不仅要发现其存在，更要在那20%的重点上下功夫，避免在80%的事情上瞎费劲。 （文中配图是我用Windows的画图程序生成的，不好看望大家见谅。） 参考资料：二八定律企业架构模式]]></content>
      <categories>
        <category>编程心智</category>
      </categories>
      <tags>
        <tag>编程心得</tag>
        <tag>二八定律</tag>
        <tag>软件开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程心智(一)——代码架构与系统架构]]></title>
    <url>%2F2017%2F09%2F24%2F%E7%BC%96%E7%A8%8B%E5%BF%83%E6%99%BA-%E4%B8%80-%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[写在开头的话想写这个系列文章很久了，但是对于一个重度的拖延症患者来说，决定写一个系列文章还是颇有挑战。最开始，只想写一两片文章分享一下自己对于编程的感悟。但随着时间越拖越久，发现想写的东西越来越多。直到今天，居然发现我的博客的To-Do-List（目前我在使用WunderList，很好用的一个To-Do-List工具)文章数达到了10篇，终于说服自己动笔了。“编程心智”这个词这段时间一直萦绕在我的脑海中，我觉得这个词最能表达我想分享了内容了。我希望通过这个系列文章分享自己对于代码、编程、架构以及软件工程的理解与感悟，另外，还有隐藏在代码后面的程序员心智。所有文章仅代表个人观点，没有是非对错的标准。如果你对文章中的观点不认同，还请给我留言，不同的声音对于进步有着极大的促进。 选择“代码架构与系统架构”作为第一篇文章是因为我发现很多人对“架构”的误解很深，而且国内关于“代码架构”的分享和书籍凤毛麟角，似乎只有流弊的“系统架构”才能成为谈资。我不太能理解这个现象，好像大部分人都完全不用操心“如何写好代码”这回事，似乎只要有一个看上去比较“完美”的系统架构就能解决所有的事情。但根据我的实际经验，现实情况往往不是这样，有时候甚至相反。有些项目的系统架构图画的非常“漂亮”，引入了很多新潮的技术，每个组件都划分的很清楚，系统之间如何通信，模块之间如何引用等等都一目了然。但是当你去看项目的真实代码时，完全是另外一番景象。至于为什么会这样，我想很大一部分原因是“系统架构图”已经沦为了一种满足KPI考核手段，而通常你的老板不会深入地去理解你的代码，更不要说指出其中的问题了。 系统架构相信很多人对系统架构都不陌生，只要是从事软件开发领域的人，或多或少都接触过系统架构。系统架构最直观的表现就是系统架构图，下图就是一张系统架构图，摘自李智慧老师大型网站技术架构:核心原理与案例分析。 系统架构是一个比较大的概念，从技术角度来看，它往往以部署架构图的形式出现（上图就是）；而换到业务视图，它又以另外一种形式出现，如下图。 不论是部署架构图还是业务架构图，它们都反映了系统与系统之间的一种关联关系，从更加宏观的角度反映系统在全局中的作用和定位。如果你是某个系统的开发者或者负责人，那么你的系统会在系统架构图中以一个方框出现。通过系统架构图，你的老板和同事能很直观地了解到你的系统在全局中的位置以及你服务的层次。这样做有好处的，它降低了技术人员之间以及技术和业务人员之间地沟通成本。 实际上，关于系统采用什么样的中间件、何种数据库和缓存、选用哪种服务框架等等，甚至今年非常火的微服务架构，这些统统都属于系统架构的范畴。关于系统架构方面的书籍和文章已经非常多了，而且国内的分享也主要集中于此，我就不再这方面展开了。 代码架构相比于系统架构，代码架构对很多人可能就陌生许多。我刚刚去Google一下，发现甚至没有关于“代码架构”的权威定义。那么什么是代码架构呢？打个比方，如果你的系统在系统架构图中只是一个方框，那么代码架构就是介绍这个方框是如何组成和实现的。代码架构的关注点在一个工程（Project）内部，它描述了你的整个工程代码是如何组织和实现的。简而言之，系统架构是宏观层面的体现，而代码架构是微观层面的体现。 在我的博客中有很多关于DDD的文章，而DDD本身就是一种代码架构。除此之外，还有MVC、CQRS、Event Souring等等。那么，设计模式是否也可以成为代码架构呢？在某种程度上是的，因为它可以指导你如何组织代码的实现，如何在代码层面解耦，但是，光光通过设计模式你无法组织起你的整个工程代码，所以从严格意义上讲，设计模式并不是一种代码架构。代码架构也可以通过图文的形式表现，不过这完全取决于你采用何种代码架构。下图是我目前负责的一个系统的代码架构，这个系统的核心在于策略语言（Policy）。 熟悉DDD的人一眼就可以看出来这是DDD种的经典六边形架构（题外话，至今我不太明白为什么是六边形）。如果你的工程采用MVC或者CQRS架构进行组织，可能会画出完全不一样的架构图。我很庆幸，在我正式的职业编程生涯的早期接触到了DDD这种编程思想，它对我的编程生涯影响很大，让我少走了很多弯路。如果你还没有接触过DDD，我希望你能立马买一本Eric Evans的领域驱动设计:软件核心复杂性应对之道，细细研读此书，字里行间都体现着作者对软件开发的深刻理解。 为什么我说代码架构是如此的重要？是因为其奠定了大型系统的基石。我认为衡量一个优秀的程序员的能力之一就包含其对复杂问题的解决能力。现实的问题往往比理论复杂很多，很多时候需要妥协、折中、权衡和取舍，如何在这些取舍之中不影响到软件的核心，这需要大量的经验。当然，这是有规律可循的，那就是代码架构。 好的代码架构会帮助你理解你的业务，哪些部分是你系统的核心，哪些部分只是技术层面的实现。换句话说，好的代码架构不光能知道你如何去组织你的代码，还能加深你对系统的理解。反过来，随着你对系统理解的不断深入，你又能更好的调整你的代码以适应新的变化。是不是所有的项目都需要代码架构呢？这取决于你的问题域。如果你的项目仅仅是一个Hello World程序，又或者是一个数据采集脚步，那么使用代码架构来组织代码可能没什么作用，反而使得你的代码变得更加复杂和臃肿。那么什么情况下你需要使用代码架构呢？我认为只要满足以下两个条件就行。 你有一个相对固定的业务场景。固定意味着你要处理的问题域是有边界的，比如订单系统、库存系统、用户中心等等，它们所要处理的问题是比较集中和固定的。 你要解决的问题相对比较复杂。这看上去本身就比较矛盾，因为“复杂”本身就是相对的。这里的复杂的意义在于，你要处理的问题领域本身就具有复杂性。也许起初问题本身并不复杂，但随着时间的推移，系统要处理的问题也越来越复杂了，这要求你对问题有一定的前瞻性。 事实上，上面两个条件是很容易满足，之所以还列出来因为在实际的开发过程中，我确实遇到过在以上两点犯错的情况。这主要出现在刚刚开始正式编程生涯的毕业生，他们对业务和要做的事理解程度不够，如果有经验丰富的程序员带的话，可以避免走一些弯路。正是因为上诉条件门槛较低，所以代码架构的应用场景非常广泛。有可能你现在的项目就在使用MVC架构，只是你没有意思到。我建议程序员能有意识地去了解你的代码架构，深入的思考一下目前的代码组织方式是最为合理的吗？ 小结说了这么多，希望自己把代码架构和系统架构的核心点说明白了。两者都非常地重要，但是应用的场景各不相同，两者结合使用才能让你做出一个高质量的系统。相比于系统架构，代码架构往往被人们所遗留，但这并不代表其不重要。依我之见，代码架构的应用场景更为广泛，因为大部分的公司和项目其实并不需要一个复杂和“高大上”的系统架构，而与我们日常交互最多的就是一行一行的代码。深入的了解你的项目代码是如何组织对程序员来说是十分重要的，好的代码架构能起到事半功倍的效果。最后，个人建议将代码架构纳入到KPI的评判之中，最为直观的表现就是“技术债务”。好的代码架构会把项目的技术债务维持在一个比较低的水平；相反，糟糕的代码结构会让项目的“技术债务”越滚越大，最终到了不可收拾的程度。不过，技术债务如何量化，以及是否需要量化，目前这方面有着很多不同的身影，但是，能意识到这个问题的存在，至少，我们在向高水平的软件开发者迈出了一大步。 写在最后的话编程心智这个系列我会持续地更新，但更新时间就不确定了。前面也说了，我是一个重度的拖延症患者，而且，最近项目的事情很多，一个接着一个。我会努力做到一个月一篇的。]]></content>
      <categories>
        <category>编程心智</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
        <tag>代码架构</tag>
        <tag>编程心得</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再谈领域事件]]></title>
    <url>%2F2017%2F08%2F13%2F%E5%86%8D%E8%B0%88%E9%A2%86%E5%9F%9F%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[我以前写过一篇关于领域事件的文章——实现领域事件，随着在项目中深入的使用DDD架构，我对领域事件有了新的认识。尤其是采用领域事件来解耦代码这种方式对项目的发展具有深远的影响。 我在实现领域事件中主要谈到了如何在技术层面去实现发布事件与订阅事件，比较了几种不同的方式以及它们背后的原理。但随着我在自己负责的项目中严格地实施DDD架构时，我发现如何去发布订阅领域事件的意义远没有决定去做这件事情本身重要。换句话说，与其纠结与是使用基于Spring的事件架构还是Guava提供的EventBus，是使用同步发布还是异步发布，还不如想想去做这件事情对你的项目会产生怎样的影响。 为什么要使用事件？我认为这是所有人应该考虑的首要问题。对我来说，使用事件的意义有两个方面，一是在于流程上的解耦，二是在于代码层面的解耦。在代码层面的解耦是显而易见的，我就不再赘述了。那么流程上的解耦是什么意思了？我们先看一下一个普通的业务流程执行的链路。 目前我们绝大部分人的思维习惯是顺序式的，体现在代码上也就是A做完它做的事情然后B继续处理，当然这么做没有任何问题，这也是最为简单直观的一种编程方式。我们再来看一下通过Event来解耦的链路。 通过引入事件，我们将过程A和过程B解耦了。第一种方式和第二种方式都有着其重要的存在意义，决定何时采用第二种方式的关键在于BoundedContext。正好最近我在负责处理一个遗留系统的拆分问题，恰好有一个好的例子来说明这个问题。 这个遗留系统是一个计费系统，因为各种各样的原因，整个项目在代码层面非常混乱，代码之间各种凌乱的引用和交叉，这种感觉就和下图一样。 我认为造成这个问题的根源在于开发人员并没有及时地识别出这个项目中的几个关键领域以及及早的将其进行隔离。更为让人遗憾的是开发这个项目的人员都已离职，后来接手这个项目的开发人员被堆积地需求压得喘不过气来，也就更没有时间来处理以前的技术债务问题。 实际上，这个项目包含多个领域，最为核心的三个领域就是订单、账单和计费。在和老大以及开发沟通过后，我们意识到系统拆分已经刻不容缓。目前我们在做的事情就是在工程内部进行代码级别的拆分，其中最为棘手的问题就是订单系统和计费系统的耦合太深。 仔细分析各个业务流程之后我们发现，很多耦合都是可以避免的。大部分的业务流程都是由订单系统触发，然后计费系统做出相应的变更。最终，我们决定使用领域事件来讲订单系统和计费系统解耦开。（PS:原系统中并没有使用DDD的开发模式，但这并不影响我们使用领域事件。) 上图是我们现在的做法，通过OrderEvent和BillEvent来将两个系统解耦开，然后将Event放到一个公共的Module中来达到Module级别的解耦。令人惊喜的发现在于，这种解耦的方式与我们规划中订单系统与计费系统通过MQ来通信达成了一致。后面我们只需要标准化这些事件，就可以做到无缝迁移到MQ中。 通过上面这个例子，我再总结一下使用领域事件的来解耦业务流程的应用场景： 如果一个业务流程需要贯穿几个不同的受限上下文中，那么可以通过以发布领域事件的方式来避免上游系统耦合下游系统。这种解耦方式收益最大，因为其有利于后期系统间的拆分。 如果在同一个受限上下文中，也可以通过发布领域事件的方式来达到领域间解耦。 至于为什么说以何种方式来发布事件不在那么重要，因为当你在项目采用了领域事件技术来解耦代码，你已经获得这项技术的90%的好处，而具体怎么执行就显得不那么重要了。我在另外一个项目中（这个项目完全采用DDD的模式来开发）就采用了最为朴实的方式来实现，不再基于Spring或者Guava了。 附上我目前的使用方法：https://gist.github.com/mymonkey110/aba58de452928bec2243848bb2c9b84a 如果你对使用领域事件的感触没有那么深，那么请记住这句话：代码间解耦用事件，系统间解耦用MQ！ 参考资料：实现领域驱动设计领域驱动设计:软件核心复杂性应对之道]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>领域事件</tag>
        <tag>event</tag>
        <tag>dddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨Region实践初探]]></title>
    <url>%2F2017%2F08%2F02%2F%E8%B7%A8Region%E5%AE%9E%E8%B7%B5%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[最近网易云上线华北REGION(cn-north-1)地区的服务，在此过程中我们做出了很多调整以适应跨REGION架构。 在此分享一下我在团队内部的分享：http://pan.baidu.com/s/1eSgUYmY 密码：m72t 这次的跨REGION改造仅仅是第一步，我们意识到要支持多REGION，要做的事情很多。后续有机会进一步跟大家分享网易云在这方面的实践心得。]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>架构</tag>
        <tag>高可用</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次坑爹的Debug过程]]></title>
    <url>%2F2017%2F06%2F21%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9D%91%E7%88%B9%E7%9A%84Debug%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[昨天QA跟我反馈说系统有几个接口反应很慢，起初我不以为意，因为这几个接口就是简单的写入和删除，最多就是再更新一下缓存，能有多慢。我让QA看看是不是网络抖动，延迟的问题，再看看我们的access_log里面响应时间是多少。QA说网络比较稳定，access_log里面显示要好几秒，这就让我有些诧异了。其中有一个删除用户XXX数据的接口响应特别慢，我们在测试环境去复现的时候果然复现了这个问题。当前端直接点击删除的时候，接口过了8秒多才返回，这肯定不正常了，而且access_log也印证了这一现象。 access_log如下所示：（后面的代码和日志我都以XXX来代替这次的业务场景）。 1210.180.9.150 - 2017-06-20_15:58:55.960 DELETE /v1/xxx/user/comb/region-1497945389492-vfxil 200 95 (9586 ms)10.180.9.150 - 2017-06-20_16:04:00.239 DELETE /v1/xxx/user/comb/region-1497945389482-yajym 200 95 (4580 ms) 铁证如山，access_log显示了确实是我们接口响应慢了。这让我有些纳闷了，这个接口的业务场景非常简单，就是删除用户的一条XXX记录，并清除跟它相关的表信息，最后发出一个领域事件，由一个listener来清除缓存，代码如下。 1234567891011121314@Override@Transactionalpublic void deleteUserXXX(long uid, String code, String name) throws XXXNotFoundException &#123; Optional&lt;XXX&gt; result = getUserXXX(uid, code, name); XXX xxx = result.orElseThrow(PolicyNotFoundException::new); long xxxId = xxxx.getId(); xxxRepository.clearAllVersion(xxxId); authorizeService.revokeXXXRefFromYYY(primaryAccountId, xxxId); authorizeService.revokeXXXRefFromZZZ(primaryAccountId, xxxId); xxxRepository.delete(xxxId); DomainEventPublisher.publish(XXXEvent.newDeleteEvent(xxx));&#125; 关键是这个接口响应慢也不是每次都出现，响应慢的概率大概有50%，还是比较好复现的。还一个比较重要的信息就是，我们的SQL日志很快就打印完了，基本上我在POSTMAN一发出请求，我们的SQL也就执行完成了。但是POSTMAN此时并没有请求，那么就是说我们还没有返回response给前端。 怎么会这样？！不应该呀？难道是慢查询，索引的问题，我已经建了索引了呀，况且测试环境数据量这么小，不要索引也不至于这么慢啊！为了确定是不是慢查询的问题，我去咋们的APM工具(蜂巢的APM产品很强大，推荐大家使用)里面查询一下有没有捕获到慢查询的日志，结果很遗憾，并没有看到响应的慢查询日志。此时我就更困惑了。如果不是慢查询还能是什么。 走投无路的我只能祭出神器了——JProfiler，一款专业的APM工具。在折腾完一番环境配置部署等问题以后，我的客户端重要可以连上测试环境的jvm进行profiling了。用上了JProfiler感觉档次提高了好多，好像马上就能把问题解决了。下图是JProfiler的显示的调用过程。 调到这里，我只想说WTF！JProfiler显示这个HTTP调用只用了44ms就完成了。 我的内心又奔溃了，明明access_log显示花了8秒多，为啥JProfiler显示才44ms，难道JProfiler出错了？实际上，我更相信我自己的程序有问题，那为什么JProfiler显示我们的程序执行的很快呢？ 看来JProfiler不能用了，我又想了很久。 难道是因为我agent加的太多了，因为测试环境为了统计需要jvm参数里面加了jacoco的agent；还有，apm的agent。这么多agent会不会导致某种性能问题了，虽然我自己都不太相信，但本着大胆尝试地原则我果断去掉了两个agent再重试了几次，现象依旧！ 幸好我内心强大，我还是很珍惜每次调试诡异BUG的机会的，因为能学到很多东西。此时的我已经没有什么手段了，事实摆着那里，接口响应很慢，也没有看到慢查询，JProfiler也没用了。然后我又祭出了我的第二个神器——BTrace。 相信很多人用过BTrace，这是在线调试的神器！虽然我不太想用这玩意，因为它要自己写脚本，内心有点排斥。但是我也没有别的办法了。准备再去看看BTrace的文档的时候发现BTrace的官方文档网站已经关了，WTF! 我突然想到了以前看到过的另外一款神器——Greys。Greys也是一款在线调试神器，是阿里开源的一个工具。以前我没有用过这个工具，这次形式所迫，不得以而学之。看完文档之后发现它非常强大，不比BTrace弱，而且对开发者比较友好，至少不用去写脚本。我用trace跟踪了一下那个deleteUserXXX方法，结果如下： 啥？为啥我发一次请求这个方法会被调用两次？而且还是被同一个线程执行两次？为此我专门在代码入口处加了一条无用的log来看看这个方法到底被执行了几次。log显示这个方法只执行了一次。那为什么trace显示执行了两次，我为此纠结了很久，有知道的小伙伴可以告诉我。 Greys没有提供太多有价值的线索给我，唯一有价值的信息就是那个线程名称。此时，我又灵关一闪，难道是Stop The World ？ 因为我用的同步请求的方式，所以一个request只会被一个thread处理，而又没有满日志打印，说明不是数据库的问题，只能是jvm本身的问题，难道请求的时候触发了GC ？ 又本着大胆尝试的精神我果断开启了jstat观察GC的情况。 观察很久以后发现自己还是太年轻。别说FGC了，连YGC都没几次，根本不是GC的问题。这可如何是好？对了，还有一个工具没试过，jstack，反正这么多工具都用了，也不差这一个了。 在请求过程中我用jstack来查看线程的运行状态，得到了如下的运行堆栈。堆栈显示socket在读取什么东西，到底是什么东西呢？ 1234567891011121314151617181920212223&quot;http-nio-8080-exec-2&quot; #104 daemon prio=5 os_prio=0 tid=0x0000000006b1b000 nid=0x7392 runnable [0x00007f74dece9000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:170) at java.net.SocketInputStream.read(SocketInputStream.java:141) at com.mysql.jdbc.util.ReadAheadInputStream.fill(ReadAheadInputStream.java:101) at com.mysql.jdbc.util.ReadAheadInputStream.readFromUnderlyingStreamIfNecessary(ReadAheadInputStream.java:144) at com.mysql.jdbc.util.ReadAheadInputStream.read(ReadAheadInputStream.java:174) - locked &lt;0x000000076ef859b8&gt; (a com.mysql.jdbc.util.ReadAheadInputStream) at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3008) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3469) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3459) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3900) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2486) - locked &lt;0x000000076ef7b928&gt; (a com.mysql.jdbc.JDBC4Connection) at com.mysql.jdbc.ConnectionImpl.commit(ConnectionImpl.java:1555) - locked &lt;0x000000076ef7b928&gt; (a com.mysql.jdbc.JDBC4Connection) at org.apache.commons.dbcp2.DelegatingConnection.commit(DelegatingConnection.java:364) at org.apache.commons.dbcp2.DelegatingConnection.commit(DelegatingConnection.java:364) at org.springframework.jdbc.datasource.DataSourceTransactionManager.doCommit(DataSourceTransactionManager.java:279) 我拿着堆栈信息一通Google，最终发现下面这两个网页：ReadAheadInputStream hangs on socket readServer query cache vs protocol issue 啊哈，这个人的堆栈跟我们一样，这是MySQL的一个BUG。哈哈，我居然碰到了MySQL的一个BUG。似乎一个程序员在一个问题上调试了很久还没有找到原因时，总是急于把发现的蛛丝马迹套到某个相识的问题上，而且那个人跟我有着一样的运行堆栈！我现在多么希望就是这个原因啊！ 在Bug #74979的说明中表示这个影响的版本是MySQL 5.7.4，但是我的MySQL 版本是5.7.14。为了确认是否是MySQL的问题，我专门找DBA来一起看这个现象。 起初，DBA也很诧异，SQL的执行速度是很快的，索引也没有问题，但是COMMIT很慢！这是为什么呢，我并不是MySQL专家，这么专业的事情还是主要交给DBA来分析。再和DBA复现了几次现象以后，DBA也有些纳闷了，再和其他的DBA沟通以后发现我的库所在的盘的IO很高，是磁盘IO的问题！WTF?! DBA在给我的库换了一块盘以后一切恢复正常了，但是我此时的内心是这样的！ 这个例子告诉我，有时候再多的分析也没有，不要想太多，想把基本的监控参数看清楚很重要！哈哈，当然，我再这个过程中又学到了很多新技能，就算这次坑爹的Debug过程花了我快1天半的时间，但我还是觉得很值得！]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>调试</tag>
        <tag>mysql</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构师应该是一种角色，而不是一个职位]]></title>
    <url>%2F2017%2F06%2F03%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E5%BA%94%E8%AF%A5%E6%98%AF%E4%B8%80%E7%A7%8D%E8%A7%92%E8%89%B2%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E8%81%8C%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[昨天看到一篇关于“架构师”的文章，读后非常有感触。我个人比较认同作者的大部分观点，故决定将原文进行翻译，和国内的开发者一起分享。原文地址：“Architect” Should Be a Role, Not a Position”。 当一个资深的开发者变得更加资深时会发生什么事情？他们经常会被提拔做去“架构师”。有时一个架构师也不一定非要是开发者，如果他们能看到更大的蓝图。最终，总有一个人挂着“架构师”的头衔：他对要开发的系统和正在开发的系统做出架构上决策。在一些更大的公司，还有“架构师议会”，每个团队指定的架构师们聚在一起决定着一些明智的事情。 但我认为专门设立“架构师”的职位是一个糟糕的想法。架构师应该是建筑行业的一个职位，这是说的过去的，因为你不能在项目中期改变和调整架构。但是软件架构是十分灵活的，不应该预先就严格地定义好。而且开发工作和架构设计是如此的紧密关联，所以说某个人决定“什么要做”和“什么不要做”是不科学的。这会带来各种各样的问题，主要是因为架构师经常无法全面的考虑到具体的实现是怎么样。如果一个架构师长时间不写代码，他们更加倾向于忽略“实现细节”，转而仅仅考虑抽象设计。然而，抽象总是伴随着遗漏，只考虑抽象而不考虑特定的实现这样的解决方案很少行得通。 我的第一个论点就是：在不知道详细地编写所有代码地情况下，你无法在成为一个优秀的架构师。大多数情况下都不是“简单地编码”。如果你已经成为架构师多年，同时也多年没有写过代码了，那几乎可以肯定你不是一个优秀的架构师。 当然，你可能是一个优秀的架构师。或许在你所在的那个特别的公司里，有人坐在象牙塔中，指挥着码农去整合这个实现那个，这可能说的过去。但即使是这种情况，也有更好的方法。 架构师应该是一种角色。每个资深的团队成员都可以也应该扮演架构师的角色，不用每个团队指定一个人来当。实际上，最好有多个人来扮演架构师。在会议中讨论架构设计和讨论功能设计类似，如果你是那个要实现所有事情的人，那么你需要带着明确的想法去参会。任何的过度设计（大部分架构师经常会犯这个错误）需要在你面前证明是合理的——“我是否愿意去写这些模板代码，或者是否有一种更简单优雅的实现方式”。 职位可以使“软件工程师”，但角色可以是“敏捷大师”、”架构师”、”持续集成官”，等等。如果公司需要一个“架构师议会”去决定系统间更宏观的整合，开发者可以提名某个人去参与这些会议，这个人有可能是对这些系统最了解的人。 我知道现在架构师在想什么——有一些更加高层次的关注点开发要么不太能理解要么不应该为此被打扰。大错特错！如果你的开发不理解更高层次的架构规划，那么迟早你会遇到问题的。是的，因为他们要让代码适应你正在规划的更大的蓝图，他们需要被打扰。 还有一方面于团队成员的态度和动态的交流。如果某个不是特别优秀或者受人尊敬的开发被提升为“架构师”，那么可能破坏团队的和谐。另一方面，某些人被提升为“架构师”以后可能会过于自信，以至于他们会想当然的去做出设计决定，而不管那些反对他们的好的争论点。 所以，理想的情况（这是我的第二个论点）是取消架构师的职位。确保你团队中资深的成员能够参与架构设计和决策，那样他们可能会更有干劲，他们也会对他们开发的成果有一个更加清晰的规划。最为重要的是，架构决策不能脱离日常的“现实”的开发环境，否则它们会不必要的复杂化。 很久没有翻译了，有很多句子拿捏不准。如果有误翻的地方，还望指正，谢谢！]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
        <tag>软件开发理论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[访问控制：为你的云上业务再加一把锁]]></title>
    <url>%2F2017%2F06%2F01%2F%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%EF%BC%9A%E4%B8%BA%E4%BD%A0%E7%9A%84%E4%BA%91%E4%B8%8A%E4%B8%9A%E5%8A%A1%E5%86%8D%E5%8A%A0%E4%B8%80%E6%8A%8A%E9%94%81%2F</url>
    <content type="text"><![CDATA[企业上云首当其冲的就是要解决安全性的问题，是否满足企业对安全的诉求成了影响其是否上云的一个十分重要的因素之一。安全是一个很大的话题，从底层资源数据的安全到上层应用访问的安全，从访问客体（资源或服务）的安全到访问主体（人或者第三方服务）的安全，这些都属于安全的范畴之内。访问控制正是从资源访问的主客体关系出发，解决企业对资源访问的权限控制的需求。 维基百科对访问控制的定义如下： 访问控制是指允许或禁止某人使用某项资源的能力。 云环境下的访问控制使得这个问题变得复杂，我曾写过一篇对云环境下访问控制系统的思考来阐述这个问题。从2.14号上线访问控制以来，接入访问控制的业务越来越多，截止目前已有六大业务支持访问控制；同时，访问控制还对云服务提供了支持，用户可以授权给易盾和视频云来访问其在NOS（网易对象存储）的数据资源。现在，你可以自定义访问控制策略，通过一套特定DSL语法来定义权限。根据自己的实际使用场景和组织架构来定义对权限的需求，这具有十分重要的意义。 举个例子，如果不允许某某子账号删除avatar桶中file-1.png的图片，而允许其对其他任何文件有所有的控制权限，那么可以定义如下的策略来达到这个目的。 1234567891011121314151617181920212223&#123; &quot;version&quot;: 1, &quot;statement&quot;: [ &#123; &quot;action&quot;: [ &quot;comb:nos:DeleteObject&quot; ], &quot;effect&quot;: &quot;deny&quot;, &quot;resource&quot;: [ &quot;comb:nos:*:*:*:avatar/file-1.png&quot; ] &#125;, &#123; &quot;action&quot;: [ &quot;comb:nos:*&quot; ], &quot;effect&quot;: &quot;allow&quot;, &quot;resource&quot;: [ &quot;comb:nos:*:*:*:*&quot; ] &#125; ]&#125; 通过语言来定义权限，用户将获得十分灵活的权限控制，当然也包含了细粒度的权限控制。使用DSL来定义权限的做法很早之前就存在了，可以追溯到2001年的XACML时代。目前主流的云计算厂商也均采用这种方式来描述权限。我们采用了业界相同的命名方式来降低用户的理解成本。这里对策略语法做一个简单的介绍。 策略语法就是有着一定约束关系的JSON格式数据，由version和statement两个部分组成。version目前只支持1，而statement则是描述策略的具体形式。statement由三个部分组成，action、effect和resource，这三个子句构成了访问控制最为核心的三个部分。 effect表示授权类型，只能是allow（允许）或者deny（拒绝）。 action表示动作，组成结构为product:service-name:action-name。product目前只支持comb，service-name代表基础服务（蜂巢）下的服务，目前已支持的服务如下： 服务代号 | 服务名称— | —nos | 对象存储nlb | 负载均衡rds | 关系型数据库mongodb | MongoDBncr | Redis缓存cdn | CDN action-name表示具体动作的名称，例如nos支持GetBucket、PutObject等动作，cdn支持CreateDomain、DisableDomain等等，具体的动作请参考对应服务的文档。 resource表示资源，组成结构为product:service-name:region:az:account-id:resource-descriptor。product和service-name和action中的意义相同，region表示地域，az表示可用域，目前只支持*，account-id是用户的主账号id，目前也只能填入*，resource-descriptor是具体资源的描述符。resource-descriptor根据具体的服务会有变化，整体上是树形结构的。例如：bucket-1/file-1.png可以表示nos中bucket-1的桶中的file-1.png文件，而instance/nlb-1可以表示nlb中实例名称为nlb-1的实例。具体的规则请参考对应服务的文档。 statement语句本身是一个Array，你可以在其中最多定义5条子句。这样就允许你将多条策略组合在一个策略里面，也可以根据需要将策略拆改，选择权在你手上。 通过上面的策略语言，企业完全可以根据自身的实际需要来定义权限，具有非常大的灵活性和自由度。如果你以前使用过其他云的访问控制产品，那么上手会很快。如果是第一次接触此类产品，也不用担心，我们提供了一个强大了“编译器”来检查你的策略语法是否合法，并提供简单直观的错误展示来帮你迅速定位问题，如下图所示。 另外，访问控制还提供了了子账号、组和角色来满足企业对访问主体描述性的需求，企业可以根据自身的组织架构和研发模式来组合使用这些身份。 掌握了授权策略后，理解鉴权的执行流程也是很重要的。鉴权流程按照Deny优先原则执行，如果有显式的Deny，那么直接拒绝；如果有显式的allow，那么则允许，否则也拒绝。具体流程如下。 在授权时请遵循最小权限原则，即根据用户的需要，将刚好能满足其需求的权限赋予给他，这样有助于规避一些越权执行的问题。除此之外，最佳实践还包含及时收回用户不再需要的权限，尽量通过组和角色来授权等等。详细的文档可以参考访问控制的官方文档。 通过以上的介绍，不知道你是否对访问控制有一个大致的了解。如果还是有些云里雾里，那不如自己去动手定义一个属于自己的访问策略吧！]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>访问控制</tag>
        <tag>DSL</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[评论从多说迁移到Disqus]]></title>
    <url>%2F2017%2F05%2F21%2F%E8%AF%84%E8%AE%BA%E4%BB%8E%E5%A4%9A%E8%AF%B4%E8%BF%81%E7%A7%BB%E5%88%B0Disqus%2F</url>
    <content type="text"><![CDATA[建站以来一直使用多说作为评论系统，我还是非常喜欢国人做的评论系统，简单实用接地气。但是不盈利的商业软件最终只能关闭，这方面国内对盈利模式得探索要不国外落后太多了。 虽然切换到Disqus以后免不了被墙，但目前我确实还没有找到称心如意的评论软件。如果网友们有好的评论系统，不放留言给我推荐，叩谢！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对云环境下访问控制系统的思考]]></title>
    <url>%2F2017%2F03%2F07%2F%E5%AF%B9%E4%BA%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[背景现在，云计算市场已是一片红海，不论是国内还是国外的云计算市场竞争都相当激烈。主流的云计算厂商在争夺企业客户方面都不留余地，因为企业用户对云计算的发展有着极为重要的意义，尤其是大企业客户。可以毫不夸张的说，没有企业用户，云计算的发展绝不会发展的如此迅速。 企业上云首当其冲的问题就是安全性，安全性已经成为企业上云最大的障碍。这里的安全性不光是基础设施的安全和稳定，比如虚拟机的高可用、RDS的高可靠等等，也包括应用层面的安全性，如WAF、证书服务、加密服务等等，还包括因为企业本身的IT架构/研发架构的复杂性带来的资源管控方面的安全性需求。毫不夸张地说，谁解决好了企业的安全性诉求，那么他就能在这片红海中立于不败之地。 安全是一个很大的话题，我不敢妄谈。最近我在做访问控制方面的工作，故此分享一下我对这个领域的一点思考。访问控制是安全中一块，也是十分重要的一块。有些云计算提供商甚至都没有将其划归到安全的范围，可能是没有意识到访问控制的重要性。AWS中访问控制的产品是IAM，可以说是云计算厂商中做的最早也最为完善的一个。IAM在其的产品分类中有一个词我觉得形容该产品最为合适——“合规性“。其实访问控制就是满足企业用户对于合规性的需求，说白了就是规范企业用户对云计算资源的访问。 既然这是一篇关于访问控制的文章，那么我们先来看看关于访问控制的定义。 维基百科关于访问控制的定义是：访问控制是指允许或者禁止某人使用某项资源的能力。这个定义中有几个关键点需要留意： 人 某项资源 允许/禁止 能力 虽说维基百科关于访问控制的定义略显简陋，但是这个定义我觉得已经勾勒出了访问控制系统的大致形态。首先是人，访问控制的主体是人，所以其最为重要的使用群体是用户，那就是说这个系统是一个面向用户的系统。其次是某项资源，资源是访问控制的客体，某项的限定词则表明资源的具体形式是未知的。再次是允许/禁止，这是访问控制对外提供服务的最为直观的表现形式，用一个更为专业的名称来形容的话就是“鉴权”。最后是能力，为什么我把能力专门拿出来作为一个关键点来说，因为这是理论和实践的一个关键区分点之一。访问控制的理论为我们设计对应的系统和产品指明了方向，但是在生产环境中使用的还是遇到各种各样的现实问题。有一点需要特别注意的是，访问控制系统作为一个通用的公共服务，它需要提供的是一种能力，而不是针对特定环境和产品，否则只为沦为某个特定的专家系统。 维基百科关于【访问控制】的定义在理论层面已经颇为全面，然而从系统的设计到角度来看还缺少一个关键点，那就是——动作。这里的动作（可以也称之为操作）可以理解为具体系统所开放的能力，或者用户可以对系统执行的操作。例如，RDS产品需要开放createDataBase\listDataBase\deleteDatabase等等动作，又如NOS（网易对象存储）需要开放listBucket\createBucket\listObject\putObject等等动作。就算脱离云计算的环境，动作也是访问控制中不可缺少的要素之一，因为任何给人使用的产品都会伴随与人的交互，而这些交互的细粒度表现就是这些动作。 既然现在我们已经了解了访问控制的基本理论，那是否可以开始设计系统开始编码了呢？千万不要这么做，想清楚再做远比边做边想要节约时间。这听上去有点和现在的“敏捷开发“不太符合，实际上恰恰相反，”敏捷开发”虽然强调持续集成、快速迭代，但是这却是建立在前期良好的架构设计的基础之上的。言归正传，这是一篇关于访问控制实践探究的文章，在我们设计系统之前，先看看以前的访问控制系统一般是怎么做的。 传统的访问控制模型在访问控制系统的设计中，有两种设计模式是十分重要，也是得到广泛应用的，那就是访问控制列表（ACL）和基于角色的访问控制（RBAC）。 1.访问控制列表（ACL）访问控制列表是早期的一种访问控制技术，其原理十分简单，就是记录哪些用户对这个资源能进行哪些操作，有类似如下的二维表维护在文件中： User Create Update Query Delete 张三 √ √ √ × 李四 √ √ √ √ 王五 × × √ × 这种访问控制的方式好处显而易见，就是简单直观，易维护。这种设计在操作系统、路由器、交换机和工业控制系统中都得到了广泛的使用。不过，ACL的缺点也是显而易见的，那就是当用户、资源和操作组建增长时，维护这张表的代价会异常庞大，另外，这种设计模式将用户对资源的控制权限直接绑定，十分死板，灵活性不够，无法满足云环境下动态资源授权的需求。 2.基于角色的访问控制（RBAC）基于角色的访问控制将用户按其属性进行分类构建出一个个具体的角色，而将权限授权角色，用户通过扮演角色来间接地获取对应的权限。RBAC非常适合现实环境，尤其是企业，因为使用资源的使用者一般并不是资源的拥有者，资源的所有者属于企业。在云环境中更是如此，可能使用RDS的人是公司的开发或者PE，而RDS的归属者是对应的企业。RBAC从访问控制的主体的角度出发，很好使适应了企业的组织结构，同时也将用户和权限分离开了，用户只需要通过扮演不通的角色就能获得对应的权限，这种方式解决了云环境下动态授权的权限需求。 那是否RBAC能解决我们所有的问题了？显然不是。现实的问题往往是复杂的，不会像非黑即白这样简单。RBAC将人和权限分离的方法确实解决了一部分灵活性的问题，但是也增加了使用成本，同时它对细粒度的权限控制没有很好的应对之法。 云环境下面临的挑战现在我们也知道了主流的访问控制模型一般是怎么做的了，那么如何应用在云环境中呢？我觉得在云环境下的访问控制系统主要面临以下几个挑战： 1.资源标识的灵活性访问控制的系统的立项一般都晚于云计算中的其他产品，因为它本身属于支撑产品。但随着其他产品形态组建完善，如何很好地描述各个产品的资源就成了一件非常令人头疼地问题。在一些IaaS的产品形态中，很大一部分是以实例(instance)的方式来提供服务的；而在某些PaaS的产品形态中，有些是实例的方式来提供服务，而又有一些有着很强的特殊性，比如上文提到的NOS，它们的资源描述是需要以树形方式来表达的。SaaS产品用统一的访问控制系统来管理一般不太可能，因为每个Software的产品形态和使用方式千差万别，你很难去做到统一。在对访问控制系统的设计过程中我发现了一个很有趣的现象，当你考虑的产品越接近应用层面（上层服务），访问控制系统就越接近专家系统。这样很好理解，越上层的服务它的特殊性越强，所以通用性越差，只能做成专家系统。 2.细粒度的权限控制访问控制系统的有一个比较困难的点，那就是细粒度的权限控制。这一点在访问控制模型中你找不到答案，它们只是在比较宏观的层面讨论了人和权限的关系。细粒度的权限控制是现实中存在的一个需求，比如一个企业有若干台虚拟机，有一些虚拟机用作webserver，而有一些虚拟机用作数据库，还有一些作为中间件服务器，比如Zookeeper等等。而使用这些虚拟机的人各不相同，他们能看到并操作的虚拟机也应该得到严格地监管，否则可能会引起安全事故。细粒度地权限控制关键点在于“多细”，越细致地控制会导致你的系统复杂度成倍增加，不利于的系统地可维护性。我的建议是只做到实例级别，但有一个例外，那就是对象存储。能做到多细的程度很大一部分取决于第一点中你地资源标识地方式，如果你的资源描述方式得当，那么更加细粒度地访问控制并不会增加你系统地复杂度。这个我会在下文中提到。 3.身份的多样性如果一个云计算厂商想吃下一个大客户，满足其业务架构只是其一，还有一个十分重要的条件就是满足其组织架构。大企业绝对有实力也有能力解决其本身的业务架构，其实上不上云更多地是战略性的考虑，他们更加看重云服务的稳定性、安全性和可维护性。同时，其本身的组织架构也十分复杂，要想让其没有阻力地上云，解决其员工的身份问题首当其冲。所以现在主流的云厂商都会提供多种身份的表示方式，例如：子账号、组和角色。 4.权限的描述方式权限的描述方式也是十分重要的一个点，可以说这个点设计得好坏决定了你后期能否悠然地应对业务方的接入还是每天火急火燎地和各个业务方定协议定接口。我们知道所有需要访问控制的云产品必然有其支持的动作（Action），每个产品资源(Resource)的描述方式也各不相同，同时允许（Allow）还是禁止(Deny)针对某个资源的操作也是需要明确给出来的。这三个点构成了权限描述的三个要素。如果在前期的设计中没有充分思考这个问题，那么恭喜你，你很有可能给自己埋了一个深坑。你很有可能设计几张大表，来表示各个业务方支持的动作，资源以及用户和他们的关系。出现这样的设计是因为没有真正理解访问控制系统的业务领域。当你在设计这几张表的时候其实意味着访问控制系统在“理解”各个产品的功能，这对一个通用的访问控制系统是致命的。访问控制系统作为一个底层/共享的通用系统，对外输出地只能是能力，而不是去理解各个产品它们自己地业务领域。说到这里，我还是推荐所有的技术人员都有必要学习一下DDD的理论，就算不用自己写代码，系统性地学习其战略模式也会让你收益颇多。 5.动态的授权体系这一点相比以上4点来说要简单，这是因为如果你的访问控制系统已经很好地解决上面的挑战，那么你也就自然而然得获得了动态的授权体系。之说以是动态的，是因为云环境下用户和权限的关系往往不是一成不变的。用户在某个时刻希望获得A授权，而在另外一个时刻又希望获得B授权，而且有时授权还带有时效性，当过了截至时间授权也就自动失效了。这种动态性的需求是真实存在的，但我认为满足这个需求依赖于针对前4点的设计，如果把前面的设计做好了，那么系统也就自然而然地满足了动态性的需求，这是一个水到渠成的过程。 业界是如何处理这个问题说实话，当我去设计蜂巢的访问控制系统的时候并没有像现在考虑的这么全面。我意识到了一些问题的棘手性，也调研了现在业界做访问控制的方法，可以说做的最好的还是IAM。IAM将用户身份划归为子用户、组和角色，基本上这三种身份标识可以满足身份多样性的要求了。我觉得IAM关于权限描述的方式令我耳目一新，它使用了领域专用（DSL）语言来描述权限，具体的形式如下： 12345678&#123; &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: &#123; &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListBucket&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::example_bucket&quot; &#125;&#125; 这是我第一次接触DSL的概念，当时对这种设计模式是完全懵逼的，也不太理解其设计思想。随着考虑的问题越来越多，我发现了DSL的强大之处。因为云环境下的访问控制系统最令人头疼的问题就是资源和权限的描述方式，这种极致的灵活性很难通过设计表格来获得。因为任何的以表为中心的设计方式都会映射到某个具体的领域模型上，又因为各个业务的权限控制各不相同，难道说我要根据各个业务来建立模型？前面也说过了，这是万万不可取的，这样设计只会让你深陷无尽的加班和调试之中。用DSL来将访问控制和具体的权限理解分隔开了是最为合适的方式。 通过一套约定的DSL语法来描述权限，访问控制系统可以获得极大的灵活性，同时也不需要理解具体的权限。对权限的理解还是由各个业务方自己控制，这样系统就获得了最大程度的解耦。访问控制系统只用维护这套DSL语法就可以无限的扩展性，多么完美的方案啊！有时间我会专门写一篇关于DSL的文章来对其应用场景进行分析。 实际上，用DSL语法来描述权限也不是IAM首创，早在2001年就出现了响应的规范——XACML（可扩展的访问控制高标识语言），该规范现在已经发展到3.0了。其大致的鉴权流程如下图所示，如果对其原理由兴趣的同学可以查看对应的资料。 以上就是我对云环境下访问控制系统的一点理解，如有不严谨的地方，还望指正。总而言之，云环境下的访问控制系统面临的挑战很多，充分理解访问控制的原理有助于理解代码背后的意义，让我们的系统设计不至于走偏。基于DSL的访问控制模型已经成为业界的主流，但各个云计算厂商自身的业务场景和面向目标人群又各有不通，如何制定适应自身环境的DSL成为了一个关键。后续有机会我会分享网易蜂巢在访问控制系统方面的实践。 参考资料：访问控制访问控制模型ACL和RBACDSL]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>访问控制</tag>
        <tag>架构设计</tag>
        <tag>DSL</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot反序列对象失败]]></title>
    <url>%2F2016%2F12%2F21%2FSpring-Boot%E5%8F%8D%E5%BA%8F%E5%88%97%E5%AF%B9%E8%B1%A1%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[现在Spring Boot这个项目很火，尤其是微服务的流行，Spring Boot作为Java语言最热门的微服务框架之一，它极大地简化了Spring的配置过程。只需要一个注解就可以把整个工程拉起来，大大地降低了Spring的学习成本。我记得Spring Boot的某个开发人员说过，Spring Boot最令开发者激动的功能是可以自定义banner，哈哈，我也非常喜欢这个功能。 言归正传，开始介绍今天我遇到的一个诡异的问题。我使用Redis来缓存一些数据，但是这些数据在反序列的时候报错了。由于原工程涉及一些敏感信息，我新建了一个demo工程来说明这个问题。报错信息如下： java.lang.ClassCastException: com.netease.boot.dal.Product cannot be cast to com.netease.boot.dal.Product 看到这个报错我就懵逼了，以致于我对了好几遍来确认眼睛没有看花。经过若干次重试，还是一样的错误。有人可能会对Product的实现产生怀疑，是不是没有加serialVersionUID，作为一个专业老司机，这点错误我还是不会犯得。我贴一下相关的代码： Product类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Product implements Serializable &#123; private static final long serialVersionUID = -5837342740172526607L; @Size(min = 1, max = 32) private String code; @Size(min = 1, max = 16) private String name; @Size(max = 255) private String description; @NotNull private EMailAddress principalEmail; public Product(String code, String name, String description, EMailAddress principalEmail) &#123; this.code = code; this.name = name; this.description = description; this.principalEmail = principalEmail; &#125; public void changeName(String newName) &#123; this.name = newName; &#125; public void changeDescription(String newDescription) &#123; this.description = newDescription; &#125; public void changePrincipalEMail(EMailAddress newPrincipalEMail) &#123; this.principalEmail = newPrincipalEMail; &#125; public String getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125; public String getDescription() &#123; return description; &#125; public EMailAddress getPrincipalEmail() &#123; return principalEmail; &#125; @Override public String toString() &#123; return &quot;Product&#123;&quot; + &quot;bizCode=&apos;&quot; + code + &apos;\&apos;&apos; + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, description=&apos;&quot; + description + &apos;\&apos;&apos; + &quot;, principalEmail=&quot; + principalEmail + &apos;&#125;&apos;; &#125;&#125; redis service相关的代码如下： 123456789101112131415161718192021222324252627282930313233343536 @Overridepublic void put(String key, Serializable content) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] contentBytes = SerializationUtils.serialize(content); jedis.set(key.getBytes(ENCODING), contentBytes); &#125; catch (Exception e) &#123; LOG.error(&quot;Put error:&#123;&#125;.&quot;, e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125;&#125; @Overridepublic &lt;T&gt; T get(String key) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] valueBytes = jedis.get(key.getBytes(ENCODING)); if (valueBytes == null || valueBytes.length == 0) &#123; return null; &#125; return SerializationUtils.deserialize(valueBytes); &#125; catch (Exception e) &#123; LOG.error(&quot;Get error:&#123;&#125;.&quot;, e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125;&#125; 实在没办法，这尼玛是什么问题。因为我以前这么使用过，而且工作的非常好，为毛这次就不行了。没办法了，加debug代码，我让get方法返回Object，再外面强转，（冥冥中有一种感觉，像是泛型的问题）。修改后的代码如下： 1234567891011121314151617181920@Override public Object get(String key) throws RedisException &#123; Jedis jedis = null; try &#123; jedis = redisPoolConfig.getJedis(); byte[] valueBytes = jedis.get(key.getBytes(ENCODING)); if (valueBytes == null || valueBytes.length == 0) &#123; return null; &#125; Object o = SerializationUtils.deserialize(valueBytes); return o; &#125; catch (Exception e) &#123; LOG.error(&quot;Get error:&#123;&#125;.&quot;, e.getMessage(), e); throw new RedisException(e); &#125; finally &#123; if (jedis != null) &#123; redisPoolConfig.releaseJedis(jedis); &#125; &#125; &#125; 在反序列化之后加断电debug，观察变量o，得到如下所示的图： WTF! IDE都识别出来了变量o是Product类型，但是后续的强转还是失败。经过我的测试发现所有的通过redis反序列化出来的类都有这个问题。万般无奈之下，我陷入了深深地沉思之中…之中…中… 我开始怀疑是序列化的姿势不对，但是为毛以前可以啊。不管了，先加一段测试代码： 123456789101112131415161718Product product = new Product("comb","蜂巢","云计算基础设施产品",new EMailAddress("hzxx@corp.netease.com")); /*FileOutputStream fileOutputStream = new FileOutputStream("/home/mj/work/product.data"); fileOutputStream.write(SerializationUtils.serialize(policyContext)); fileOutputStream.flush(); fileOutputStream.close();*/ ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("/home/mj/work/product.data")); oos.writeObject(product); oos.flush(); oos.close(); /*FileInputStream fileInputStream=new FileInputStream("/home/mj/work/product.data"); byte[] rawPolicyContext=new byte[fileInputStream.available()]; fileInputStream.read(rawPolicyContext); PolicyContext pc = SerializationUtils.deserialize(rawPolicyContext); System.out.println(pc);*/ ObjectInputStream ois = new ObjectInputStream(new FileInputStream("/home/mj/work/product.data")); Product pc = (Product) ois.readObject(); System.out.println(pc); 在倒数第二行打点，截图如下： 没截图没毛病啊，很正常啊。我还专门测试了SerializationUtils版的序列化方式(把上面的注释去掉)，发现结果也很正常，这尼玛到底是怎么回事。实际上，SerializationUtils也就是jdk自带的ObjectOutputStream和ObjectInputStream的简单封装。 在我走投无路之际，正准备研究instanceof的工作原理的时候，脑中闪过一道灵感——难道是classloader的问题？说干就干，debug得到如下情况： 终于发现问题所在了，原来两个classloader不一样，而instanceof是对同一个classloader而言的。再确定原因后，借助强大的google发现了这是Spring Boot DevTools的一个限制，相关的文档链接: http://docs.spring.io/spring-boot/docs/1.4.2.RELEASE/reference/htmlsingle/#using-boot-devtools-known-restart-limitations 原话是这样的： Restart functionality does not work well with objects that are deserialized using a standard ObjectInputStream. If you need to deserialize data, you may need to use Spring’s ConfigurableObjectInputStream in combination with Thread.currentThread().getContextClassLoader().Unfortunately, several third-party libraries deserialize without considering the context classloader. If you find such a problem, you will need to request a fix with the original authors. DevTools是Spring Boot中一个很有用的工具，可以自动帮你重启应用，而不用你每次重启应用来debug，提高了生产效率。具体的用法可以参考相关的文档。这里的限制条件说的很清楚了，重启功能不能和使用标准的ObjectInputStream来反序列对象一起使用，如果你非要使用，那么请从线程的上下文中来获取classloader。 看到这里我瞬间明白了。因为devtools使用两个classloader，你工程中使用的第三方jar包被一个叫”base”的classloader所加载，而你正在开发的代码被一个叫”restart”的classloader所加载。如果检测到你的classpath路径下文件有变化，restart就会重新加载你工程的类。这样做以后能提高你的类加载速度，这在开发阶段是很有用的一个功能。 既然知道了原因，就很好解决了。因为我目前的工程比较小，而且只是一个restful后端应用，所有devtools对我的应用帮组不大。注释掉devtools依赖后就解决了上面的问题。如果你想使用这个工具，同时又有反序列化的需求，有两种方式解决： 自定义一个ObjectInputStream，重写resolveClass方法，也可以使用Spring提供的ConfigurableObjectInputStream类。然后从Thread.currentThread().getContextClassLoader()获取classloader就可以解决该问题。 配置spring-devtools.properties文件，把你使用的第三方序列化工具也加入restart classloader的控制范围内就行了。 这两种方法均可以在Spring Boot的官方文档中有详细描述：http://docs.spring.io/spring-boot/docs/1.4.2.RELEASE/reference/htmlsingle/#using-boot-devtools。 总结，从发现问题到定位原因耗时两个多小时，还是要加强对基础概念的深入理解才能快速定位原因啊！ 文本的示例demo我已上传到github，有兴趣的同学可以下载自己debug一下：https://github.com/mymonkey110/boot-demo.git 参考资料: Spring Boot官方手册spring-boot issueredis serializationclasscastexception]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>springboot</tag>
        <tag>deserialized</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构为什么会腐化]]></title>
    <url>%2F2016%2F12%2F15%2F%E6%9E%B6%E6%9E%84%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E8%85%90%E5%8C%96%2F</url>
    <content type="text"><![CDATA[架构腐化一词我已经忘了从哪本书上看到的了，但是这个词给我留下了非常深刻的印象。关键在于“腐”一词，充分而又形象的描述了架构是怎样一步一步从简单清爽走向复杂污秽的。请允许我用“污秽”一词来描述一个糟糕的架构，因为糟糕的架构就像是一潭散发着臭味的淤泥，让你不想靠近，一旦涉入其中就会难以自拔，苦不堪言。 我相信所有的开发者都不希望自己的参与项目是一潭淤泥，但是为什么会出现这么多糟糕的架构呢？难道是项目最初的设计者经验不够，又或者项目开发周期太赶？我认识事实并非如此。现在，软件开发者的水平都普遍提高了，因为我们有前人那么多经验可以借鉴，连刚毕业的大学生也知道用MVC模式来搭建框架。难道是MVC模式太挫了，不够用，实际上80%的项目用MVC模式足以应对。那到底是什么原因导致了项目腐化呢？我认为有以下三个原因： 1. 不理解项目的业务价值实际上，几乎所有的软件（尤其是商业软件）都有其所属的业务价值，理解你所开发的软件的业务价值对项目的成功来说至关重要。我发现很多程序员对业务需求不屑一顾，而对那些所谓的非功能性需求盲目的崇拜和追捧，其实这是一种本末倒置的行为。 现实世界是一个商业的世界，而商业世界则会充斥着各种各样的业务逻辑。理解这些业务逻辑会极大地增加你的见识、拓宽你的视野。如果你是一个在金融行业工作的程序员，那么长时间在金融领域工作的精力将极大地提高你的市场竞争力。但是如果你不愿意花时间去学习金融领域的知识，而是去盲目的追求最新的技术，那么其实你是丢芝麻捡西瓜，浪费了这个行业带个你的附加价值。我不是不鼓励程序员瞎折腾，实际上我自己有时候也喜欢瞎折腾，倒腾一些新玩意，这视乎是程序员的一种天性。我的意思是说不要放弃了解自己所在行业/领域的知识视为不见，而盲目的追求其他的“高大上”的技术。 为什么说理解项目的业务价值至关重要呢，那是因为只有理解了其业务价值你才能识别出来这个项目的核心领域所在，这样这个项目才不会走偏。传统的软件开放流程中有一个非常重要的角色存在，叫做“业务分析员”，他的工作在项目的概要设计和详细设计解决十分重要。虽然我也没见过有专职的人员干这个，但是这却是非常重要的一个角色。他会帮你分析你的业务，和产品经理沟通，理解产品的真正意图。在这个沟通过程中，你的领域模型也就逐渐的清晰起来了，哪些是核心哪些是支撑部分也就清楚了。 有些程序员在接到产品需求后立马就开始工作了，吭哧吭哧地撸袖子上阵，我认为这是十分要不得的。接到产品需求的第一反应不是要想着我要建哪些表哪些字段，而是要多问问自己这个需求是干啥的，产品经理真正的意图是啥，为什么要我来做，跟我的系统有啥关系。千万不要盲从产品经理的话，实际上有些时候他们自己也不知道自己要干啥，为啥要这么干。这个时候必要的交流是不可少的，随着对话的深入，你和产品对真是的需求都会有着更深地认识。新人和实习生在这方面经验往往不足，此时最好找一个比较资深的程序员帮你梳理一下业务流程。 相反，如果你不知道你的系统的业务价值或者核心所在，什么需求你都来着不拒，那么恭喜你，你的系统正在腐化。当你在抱怨说“为什么这个业务要放在我这里”，“这个我有什么关系”之类的话的时候就可以闻到一丝“腐化”的闻到。你可能会说项目工期紧、人手太少、需求太多之内的外部原因，所以临时地先加到系统中搞一下。Ok，这没有任何问题。但是我还是要说，你知道你的系统的核心价值所在吗？如果你的回答是Yes，那么恭喜你，你是一名合格的程序员了。否则，你可能需要学习一下技术之外的东西的了－那就是沟通。 2. 过度设计软件开发的头号敌人就是复杂度。现在软件开发是如此的困难，动不动就有十几万行代码出现，但是现实世界就是如此的复杂，不会因为你采用某种架构或者奇淫巧技就能把代码行数降下来。好的架构设计会将系统的复杂度控制在一个合理的范围之内，因为人所能驾驭的代码行数最多也就几十万行，如果一个系统的代码行数达到百万行，那么这个系统就很危险了。现在微服务架构如此火爆，不得不说有这方面的原因。 如果你在设计一个新系统，那么我需要提醒你一定要控制好复杂度。一个好的系统的核心域往往是简单的、直观的，其他人很快就能理解其核心的工作原理。如果一开始系统设计的十分复杂，那么这个系统的扩展性就会很差，后续的维护将不可想象。但是是不是在设计之初就完全不考虑后续的变化了呢？我的建议是你只需要把你的核心领域模型建好，多问问自己系统最核心的价值是提供什么服务的，照着这个方向去设计，那么你的系统就不会走偏。灵活性和可扩展型往往只是领域模型的延伸，这是一个水到渠成的过程。 非要给个度的话，我认为5%刚刚好。不要出现超过5%的跟你本次需求无关的概念和行为，而且这5%还是你能确定在不久的将来就会使用的扩展。 还是那句话，好的设计往往是简单的，复杂是万恶之源。 3. 懒于重构过度设计不好，完全不设计也不行，尤其是随着敏捷开发的流行，持续交付优于提前设计的思想逐步流行。现在软件交付速度是如此之快，很有可能刚刚设计好的系统，下个月就全变样了。应对这种变化的唯一方法就是持续重构。 没有任何设计能预料到未来的变化，代码可能会发生变化。新的功能会持续的添加进来，老的功能也在持续的改变。而且每次迭代或者交付，都可能会对核心领域产生影响。千万不要对这种影响视而不见，因为它在改变着你的领域模型。正确地方式是经常调整领域模型以适应新功能所带来的变化，虽然每次调整的幅度可能很小，但是这却能让你的领域模型处于健康的工作状态。没有领域模型或者系统在一开始就是完美的，之所以它们能在后续的迭代过程中良好的工作离不开不断地重构。 重构不是等到你的系统无药可救的时候才想到的事，而是应该在其不断开发过程中一直进行的工作。如果说持续交付提高了你系统的竞争力，那么持续重构则是这种竞争力的有力保障！ 以上三点是我认为架构腐化最致命的原因，很多思想来源于DDD、重构和敏捷开发。linus torvalds曾经说过： Talk is cheap. Show me the code. 我认为Talk is not cheap, 好的思想和开发方式价值连城，想好了再做会提高你的工作效率，从而提升你的生活品质。 这篇文章从下笔到完成，拖了半个多月了，期间琐事太多。对这个话题有兴趣的朋友我们可以留言讨论。]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[值对象的威力]]></title>
    <url>%2F2016%2F10%2F18%2F%E5%80%BC%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%A8%81%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[值对象是DDD中非常重要的一种技术，掌握这种技术让你写代码事半功倍，体会到OO的精妙。如果你是一名Java程序员，我相信你或多或少地见过值对象了，只是你没有意识到而已。 引用维基百科的解释： In computer science, a value object is a small object that represents a simple entity whose equality is not based on identity. 字面意思就是，值对象是一个小对象，它代表着一个简单的实体，而实体的相等性不取决于它的ID。 刚刚接触OO编程的新手看完上面的解释相信直接是懵逼的，跟我接触这一概念时一样。如何理解值对象了，我还是举一个栗子。比如我们在做一个短信推送的服务，需要根据目标用户的手机号推送到相应的短信网关。我们定义了一个根据手机号推送短信的interface，很有可能我们是这么设计： 1234567891011121314void sendMessage(String phone, String message) &#123; if(StringUtils.isBlank(phone) &amp;&amp; phone.length()!=13) &#123; throw new IllegalArgumentException(&quot;phone format error:&quot;+phone); &#125; if(phone.starts(&quot;134&quot;)) &#123; sendMessageToChinaMobileGateway(phone,message); &#125;else if(phone.starts(&quot;130&quot;)&#123; sendMessageToChinaUnionGateway(phone,message); &#125;else if(phone.starts(&quot;189&quot;) &#123; sendMessageToChinaTelecomGateway(phone,message); &#125;else &#123; throw new RuntimeException(&quot;unknown phone range&quot;); &#125;&#125; 上面的过程我们只考虑3个号码段，134(移动)\130(联通)\189(电信)，其他的号码短我们暂不处理。上面的处理方式有什么问题？ 如果我们的工程里面只有一个地方用的phone的概念，也只有一个地方对phone所属的号码短进行判断，那么没问题。上面的写法没有任何问题，因为它是一个简单问题。但是如果你在做一个短信推送的应用，在你的工程里面会只有一个地方会使用phone这个概念吗，也之有一个地方需要判断号码短吗？ 显然不可能。 有人可能会争论说，不就是判断号码归属吗？我可以搞一个类似PhoneQueryService之类的查询类，再提供一个Operator queryBelong(String phone)的interface不就搞定了吗？ 当然，这么做也没有问题。但是当你的问题域逐渐变得复杂的时候，你就会开始有些不舒服了。因为每一个出现phone的地方，你发现基本上都会需要PhoneQueryService，但是他们在代码上又是两个东西。这种做饭的滥用最终会导致Fat Service的出现，代码的复用性会急剧降低。 究其原因，是因为我们把phone这个概念和phone的行为给拆开了。你可以用String代表任何字符类型，可以是phone，也可以是name，基本上这种类型可以代表任何东西。使用你API的人无法从中得到任何信息，除了你把变量名称叫做phone以外。同时，判断手机号网段这个动作是和phone本身强相关的，为什么不把这个动作加到phone里面了？！ 现在，我们重构一下代码，得到类似下面的代码结构： 123456789101112131415161718192021222324252627282930313233class Phone &#123; private String phoneNumber; public Phone(String phoneNumber) &#123; if(!validate(phoneNumber)) &#123; throw new IllegalArgumentException(&quot;phone format error:&quot;+phone); &#125; this.phoneNumber = phoneNumber; &#125; public static boolean validate(String phoneNmber) &#123; //验证逻辑 &#125; public boolean isMobile() &#123; return phoneNumber.starts(&quot;134&quot;); &#125; public boolean isUnion() &#123; return phoneNumber.starts(&quot;130&quot;); &#125; public boolean isTelecom() &#123; return phone.starts(&quot;189&quot;); &#125; public String getRawPhone() &#123; return this.phoneNumber; &#125; public boolean isSameWith(Phone other) &#123; return other!=null&amp;&amp;this.phoneNumber.equals(other.getRawPhone()); &#125;&#125; 我们新增了一个叫Phone的类，并加入了判断网段归属的逻辑。引入这个类以后sendMessage()发生了什么变化呢？ 1234567891011void sendMessage(Phone phone, String message) &#123; checkNotNull(phone); if(phone.isMobile()) &#123; sendMessageToChinaMobileGateway(phone,message); &#125;else if(phone.isUnion())&#123; sendMessageToChinaUnionGateway(phone,message); &#125;else if(phone.isChinaTelecom()) &#123; sendMessageToChinaTelecomGateway(phone,message); &#125;&#125; 咋一看，代码好像没有怎么减少啊。对于这个interface来说代码确实没有减少，反而我们还新加一个类。但是现在看看我们获得了什么： 首先，方法签名变了。不在用String了，取而代之的是Phone类型。这对使用者的约束更强了，我们也再也不用判断phone是否合法了。 其次，判断网段归属和phone合在一起了，这样我需要判断归属运营商的时候直接调用phone的方法就行了。 现在，我们已经得到了一个值对象了，那就是Phone。它是一个小对象，代表了手机号这个概念，它的相等性是基于其业务属性的，而不是ID，而且值对象根本就没有ID这个概念。 值对象最大的好处在于增加了代码复用，同时它也是类型安全的（这一点和我之前提到了enum类似）。如果你只在一个地方使用值对象，那么你是不会体会到值对象带来的好处的。但是，每当你的代码应用一次值对象，你就会收获值对象带来的好处。用的越多，收益越大，这一点和单元测试比较类似。使用值对象的另外一个好处就是前置的安全校验，尤其是你在编写SDK或者开放接口的时候。因为你无法知道使用者会如何使用你的API，那么通过值对象来获得一个前置的安全校验有着非常大的好处。 值对象用在什么地方呢？ 我个人的经验就是，如果在你的工程中反复出现一个具体的概念（往往跟现实生活有关），而且这个概念中涉及的行为是某种确定性的（比如你知道了手机号，就知道对应的运营商一样），那么你可以考虑一下值对象。引用《实现领域驱动设计》中关于值对象特征的定义: 描述了领域中的一件东西 不可变的 将不同的相关属性组合成了一个概念整体 当度量和描述改变时，可以用另外一个值对象予以替换 可以和其他值对象进行相等性比较 不会对协作对象造成副作用 最为重要的就是它描述了领域中的某件东西，并且它是不可变的。值对象一旦创建就不会发生变化，如果你需要表示另外一个东西，用另外一个值对象来代替它。 值对象是DDD中非常重要的部分，我们应该尽可能对使用值对象来建模，因为它是易于使用和替换的。但是值对象的实例化确实一个令人头疼的问题，尤其是聚合中存在1对多的关系时。由于这些内容涉及到DDD的多方面的知识，我不在这里展开讨论了。后续会专门讲值对象的持久化问题。之所以在讲DDD之前首先讲值对象，因为它还是少数几个可以完全脱离DDD并不失其威力的利器。就算你完全不了解DDD，也可以非常顺手的使用值对象。 说了这么多，我相信你也对值对象有个具象的认识了。纸上得来终觉浅，不如看看你现有的代码中哪些可以用值对象来代替吧！ 参考文献： Wikipedia值对象的定义Martin Fowler值对象的解释实现领域驱动设计Power Use of Value Objects in DDD: 强烈推荐]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>Value Object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论Enum的重要性——编程心法（零）]]></title>
    <url>%2F2016%2F09%2F20%2F%E8%AE%BAEnum%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[我们都知道Java中有一种数据类型是枚举类，实际上很多强类型的语言都有枚举。但是很多人对枚举类不那么重视，或者不能正确地应用枚举，也就不能发挥其威力了。这里分享一下我对枚举的理解，及其常见的用法。 既然Java专门为枚举建立了类型，那么我们应该在什么时候去使用enum呢，我认为在以下两个场景中可以尝试使用。 1. 封装有限的的变化相信很多人都遇到这样一个场景，我们有一个父类，父类下面有几个子类，而这几个子类是可以确定的。我们并不想父类被不相干的类所继承，那么我们可以通过enum来限制子类。实际上你想把代码控制在预期的范围之类时，都可以通过enum来达到效果。 2. 状态代码我们经常会遇到使用状态码的情况，例如在任务处理过程中。我发现很多人喜欢使用int或者long来表示状态码，然后通过定义对应的变量来表示其意义。不是说这种方式不好，但我从中嗅出了一丝坏味道。如果通过int或者long来表示状态码，如果出现了不在业务范围内的值该怎么办？为什么状态码不能直接表示其意义，还需要通过文档来说明呢？我一直比较推崇Self-Explained的编程习惯，代码和文档合二为一。 那么使用Enum有什么好处了，我们为什么要用Enum呢？相比于int或者string，enum最大的优势就是有它是类型安全的。如何理解类型安全呢，我举一个例子：很多APP都有第三方登陆的功能，服务器要根据客户端传过来的登陆类型(type)来调用对应平台的接口来获取用户信息。我的代码是这样写的： 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class TPAccountRouterImpl implements TPAccountRouter &#123; @Resource @Qualifier(&quot;wbAccountResolver&quot;) private TPAccountResolver wbTPAccountResolver; @Resource @Qualifier(&quot;wxAccountResolver&quot;) private TPAccountResolver wxTPAccountResolver; @Resource @Qualifier(&quot;qqAccountResolver&quot;) private TPAccountResolver qqTPAccountResolver; @Override public TPAccount getAccountInfo(final String tuid, String accessToken, AccountType accountType) throws TPException &#123; TPAccountResolver tpAccountResolver; switch (accountType) &#123; case WB: tpAccountResolver = wbTPAccountResolver; break; case WX: tpAccountResolver = wxTPAccountResolver; break; case QQ: tpAccountResolver = qqTPAccountResolver; break; default: throw new TPException(&quot;unknown account type&quot;); &#125; return tpAccountResolver.getAccountInfo(tuid, accessToken); &#125;&#125; TPAccountRouter是一个账号解析的路由器，根据AccountType来调用对应平台的解析器来解析。配合switch-case语法，利用策略模式我们就可以写出一个还算优美的代码。如果把accountType换成int会怎样？那么我们不得不加上一句及其烦人的123if(accountType&lt;0 || accountType&gt;3) &#123; throw new IllegalArgumentException(&quot;type illegal&quot;);&#125; 保护性代码，同时将case子句换成一个一个静态常量，最后还在API文档上配上说明，1,2,3各代表什么意义。我相信大家一定能感受出来两种代码写法带来的区别。 另外一个有点，我认为就是enum的self-explain特性，上面的例子中也直观的反应了这一点。Enum结合了int和String的优点，并将其发扬光大。 关于Enum怎么用，网上有很多的介绍，可以参考这篇文章：http://www.cnblogs.com/happyPawpaw/archive/2013/04/09/3009553.html，还是比较全面的。最常用的就是直接申明各个枚举值，基本上能满足大部分业务场景了。也有很多场景下，我们会在enum中加入成员变量，这是因为业务中存在和Enum相对应的文档和动作。再举一个我写过的代码例子：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class AbstractCheckedException extends Exception &#123; private static final long serialVersionUID = -3143228702981231790L; public AbstractCheckedException() &#123; &#125; protected abstract ErrorCode errorCode(); public int code() &#123; return errorCode().code(); &#125; public String msg() &#123; return errorCode().msg(); &#125; public static int successCode() &#123; return ErrorCode.SUCCESS.code(); &#125; public enum ErrorCode &#123; SUCCESS(1000, &quot;success&quot;), PARAM_ERROR(1001, &quot;parameter error&quot;), ILLEGAL_REQUEST(1002, &quot;illegal request&quot;), SYS_ERROR(1003, &quot;system error&quot;), NAMESPACE_NOT_FOUND(2001, &quot;namespace not found&quot;), NAMESPACE_ALREADY_EXIST(2002, &quot;namespace already exist&quot;), APP_NOT_FOUND(2003, &quot;app not found&quot;), APP_ALREADY_EXIST(2004, &quot;app already exist&quot;), TASK_NOT_FOUND(2005, &quot;task not found&quot;), TASK_ALREADY_EXIST(2006, &quot;task already exist&quot;), CRON_EXPRESSION_ERROR(2007, &quot;cron expression error&quot;), ZOOKEEPER_ERROR(3001, &quot;zookeeper error&quot;), NODE_NOT_EXIST(3002, &quot;node not exist&quot;), NODE_ALREADY_EXIST(3003, &quot;node already exist&quot;), UNKNOWN_ERROR(9999, &quot;unknown error&quot;); private int code; private String msg; ErrorCode(int code, String msg) &#123; this.code = code; this.msg = msg; &#125; public int code() &#123; return code; &#125; public String msg() &#123; return msg; &#125; public static ErrorCode getErrorCode(int code) &#123; for (ErrorCode it : ErrorCode.values()) &#123; if (it.code() == code) &#123; return it; &#125; &#125; return UNKNOWN_ERROR; &#125; &#125;&#125; 我在jscheduler中封装了高层了受检异常，这点收到了Zookeeper中KeeperException的启发。我在ErrorCode中加入了code和message，因为code和message是和这个枚举绑定的，放到枚举中再合适不过呢，我将之称为文档的绑定。还有情况是因为业务动作和枚举相关，比如第三方登陆的例子，我们完全可以第三方登陆接口的URL放到AccountType中，然后后续的解析方法直接从中取的URL进行调用就行，因为这个解析方法是和Enum一一对应的。这样的例子实在太多了，不胜枚举。 总之，如果你有一类相识的业务场景，并且这些业务场景只有有限的变化，是可以预期的，那么建议你考虑一下使用Enum。相信我，它值得尝试！]]></content>
      <categories>
        <category>编程心法</category>
      </categories>
      <tags>
        <tag>编程技巧</tag>
        <tag>代码技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDD-复杂问题解决之道]]></title>
    <url>%2F2016%2F09%2F18%2FDDD-%E5%A4%8D%E6%9D%82%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93%2F</url>
    <content type="text"><![CDATA[上个星期在团队内部进行了关于DDD的分享，分享链接：http://slides.com/michael-j/ddd-tackling-complex-problem#/。 分享的过程中发现还是有很多小伙伴对DDD不太了解，或者一知半解。DDD其实不是一个新的技术，实际上距离Eric Evans出版《Domain Driven Design》已经12年了。与其说DDD是一门编程技术，我更愿意将它称之为软件开发方法。我发现国内的技术分享两级分化比较严重，要么太过高大上——关于架构、新技术之类，要么太底层——关于数据库优化、底层性能优化之类，但很少有人来讲中间的那一层——软件编程方法。 在我看来，一个新人要成长为技术大牛，都要经历下面三个阶段： 1. Make It Work （1~2 年）刚刚踏入职场的新手程序员往往处于这个阶段，他们首要的工作是要让系统能正常工作。出于工作的需要，他们开始了解语言、框架、数据库、缓存。如果在大公司的话，可能会更早的接触服务框架、中间件等。但是他们的主要工作还是实现业务需求，对代码的质量没有过多的要求。有时候可能感觉到现在的写法可能不太好，但是又不知道怎么去组织代码才能让它们看上去更舒服，经常会刚到迷茫，好像刚工作一年就看到了未来十年的影子，这是十分令人沮丧的。这个阶段一般会持续1~2年。 2. Write better code (3~5 年)这个阶段是新手程序员向老司机转变的一个时机。他们已经能独立完成常见的业务需求，并给出自己的意见。写出的代码不仅是为了完成功能，更多地是在寻找一种平衡的美。这种美很难言明，它是介于现实逻辑和代码组织的一种完美结合。正好我也处于这个阶段，我会有时因为一次完美的解耦而欣喜，也会因为业务的妥协而忧伤。在这个时期，我在寻找一种“术”，一种能随心所欲驾驭代码的术。我开始了解到OO技术的精妙，开始理解设计模式的妙用，学着掌控整个项目的发展，只为达到软件的最高境界——“可复用”。这个阶段肯能持续时间很长，因为我们要细细去品味优秀代码的味道并为己所用，这需要时间的沉淀。 3. Create suitable architect (5年 ~ )当你能随心所欲的操纵代码时，你就会去寻找你还未涉及的阶段。这个阶段可能会产生多种分化，你可能会对项目的整体架构产生兴趣而走上架构师的道路，也可能对某些专有技术情有独钟而成为某一方面的技术专家。不论后面的发展方向如何，此时代码对你已经不是问题了，而成为了你的“工具”。国内的技术分享往往也集中在这个层面。好的架构往往有着相似的部分，但是每个架构又有它独有的业务背景，你需要剥离其中的业务部分，找出能为自己的项目有用的设计。没有完美的架构，只有最合适的架构，任何现实的架构都充满着妥协和折中。这个阶段持续时间可能更长，你也需要机缘能参与几个重大项目的架构设计。 说白了，软件开发还是一门需要经验的行业。我并不太相信天才的存在，因为没有长时间浸泡在代码之中项目之中，你是很难理解代码和业务的关系的，这需要大量的时间。现在“新技术”层出不穷，我的建议是，在没有成为真正的架构师之前，不要盲目的追逐这些“新技术”，这只会耗费你大量的精力。 言归正传，我认为DDD是一门教你Write better code的软件开发方法。就算你是底层的研发人员，我相信你也会从中收益。如果你是一名业务程序员（80%的都是），为什么不多花一些时间去真正理解你的业务呢？不要再去追逐那些“新技术”，多去思考一下我的代码该如何解耦、业务如何切分、代码怎么写才能更好的复用。如果你坚持这么做，我相信不出两年你对技术和业务的理解会发生质变。 学习DDD其实还是有一定的曲线的，如果你的团队中已经有人尝试过DDD了不妨向他取经，因为DDD的精髓更多的在于编程的思想，而不在于具体的代码。后期我会分享一些关于DDD、OO、Microservice方面的心得，如果你有这方面的心得和困惑也可以与我交流，分享是技术人成长的很重要的途径。 近期，我换了工作，加入了网易蜂巢团队。以前上研究生的时候就搞云计算，想不到时隔两年之后，又加入了云计算的浪潮之中，也算是殊途同归。]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>DDD</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper:distributed process coordination中文版]]></title>
    <url>%2F2016%2F08%2F02%2FZookeeper-distributed-process-coordination%2F</url>
    <content type="text"><![CDATA[最近使用zookeeper比较多，但是国内关于zookeeper方面的数据太少。能介绍其使用同时也讲解原理的书太少了。Zookeeper:distributed process coordination是一本关于zookeeper不可多得的好书。读完以后我对zookeeper有能一个非常直观的了解。 现在分布式应用开发越来越常见，基本上大部分的分布式应用都需要与其它应用进行协同。Zookeeper非常擅长于处理分布式协同。所以我决定利用工作之余的时间翻译这本书籍，完全出于个人兴趣。 GitBook阅读地址 GitHub阅读地址 由于本人第一次翻译技术书籍，肯定会有很多翻译不当的地方，欢迎大家能及时指正。如果有对本书翻译有兴趣的小伙伴，可以通过以下方式参与贡献： 参与讨论：邮件列表：&#x7a;&#107;&#x5f;&#x74;&#x72;&#x61;&#x6e;&#x73;&#x6c;&#x61;&#x74;&#x6f;&#114;&#x40;&#x67;&#114;&#x6f;&#x75;&#112;&#x73;&#x2e;&#x31;&#54;&#51;&#x2e;&#x63;&#111;&#x6d;，申请加入地址：http://163.fm/UJNWGHS 部分贡献：通过issue进行讨论，如果通过，我会进行修改。这种方式我无法统计贡献者的名字，建议使用下面的方式参与翻译。 在 GitHub 上 fork 到自己的仓库，如 user/zookeeper-book，然后 clone 到本地，并设置用户信息。 1234$ git clone git@github.com:user/zookeeper-book.git$ cd zookeeper-book$ git config user.name &quot;yourname&quot;$ git config user.email &quot;your email&quot; 修改代码后提交，并推送到自己的仓库。 123$ #do some change on the content$ git commit -am &quot;Fix issue #1: change helo to hello&quot;$ git push 在 GitHub 网站上提交 pull request。定期使用项目仓库内容更新自己仓库内容。 12345$ git remote add upstream https://github.com/mymonkey110/zookeeper-book.git$ git fetch upstream$ git checkout master$ git rebase upstream/master$ git push -f origin master PS: 2016/8/15 Update: 很遗憾，因为授权的问题，不得不停止翻译的工作。本书已经有中文版的译本了，我后来才得知，所以我也不会取得中文版的翻译授权了。因为本人第一次翻译，事先没有搞清这些事情，才导致了现在的情况。不得不说，十分遗憾，感谢关注本书翻译的伙伴。我相信已有的中文译本应该还不错，如果需要的伙伴可以去购买。So, that’s it, it’s over, thanks for your attention.]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让百度索引你的github的博客]]></title>
    <url>%2F2016%2F06%2F23%2F%E8%AE%A9%E7%99%BE%E5%BA%A6%E7%B4%A2%E5%BC%95%E4%BD%A0%E7%9A%84github%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[不知不觉中，写博客是一件很潮的事情，尤其是程序员。自然，我也是其中的一员。博客无非两种类型，一种是动态类型的，以Wordpress为代表；另外一种则是存静态的，以Hexo, Jekyll为代表。现在，程序员都喜欢把博客托管在github上。一来省去了买虚拟主机的费用，二来可以通过git工具来管理博客，用起来十分方便。我的博客就是用hexo搭建的。 首先，github是不支持动态博客的，它只能托管存静态的网页，也就是说你只能放置一些html,js,css,jpg,png…之类的静态文件。其次，github屏蔽了百度的爬虫，也就是说百度不能索引你的博客内容。虽说程序员基本上都用google，但是你肯定还是想能被百度搜索到的。想知道自己的博客是否被索引可以这样查询，在搜索引擎中输入：site: 你的博客域名。 解决github屏蔽百度爬虫的思路就是“迁出”我们的博客，让百度爬虫不直接访问github就行了。 方案一：利用CDN制作镜像网站我们知道cdn能缓存静态资源，如果我们利用cdn制作我们的镜像网站，再将百度索引的解析cdn上，那么爬虫就不会访问github服务器了，而是访问cdn缓存服务器。国内最火的cdn服务商就是七牛和又拍云了。我发现七牛不支持自动回源功能，而又拍云在这方面做得比较好，我们可以使用又拍云来做为我们博客的镜像网站。 我以本站为例，讲一下配置的流程： 1. 创建服务 2. 配置回源 3. 绑定域名完成上面的操作后，又拍云会自动分配一个域名给我。此时，我们就需要绑定自己的域名。添加需要绑定的域名： 如果你希望博客能以www的方式来访问，那你还需要添加www的二级域名 4. 配置解析添加完域名绑定后，此时我们就只需要配置dns解析到又拍云了。我使用的是阿里云的域名系统，下图就是我设置的域名解析配置。 因为github在国外访问速度还是很快的，所以对于海外的用户直接访问github就可以了，不用再访问又拍云了。添加解析后一般需要几分钟才生效，看自己添加的域名dns解析生效了没有可以使用nslookup命令： 123456789~/blog ᐅ nslookup michael-j.netServer: 192.168.199.2Address: 192.168.199.2#53Non-authoritative answer:michael-j.net canonical name = mj-blog.b0.aicdn.com.mj-blog.b0.aicdn.com canonical name = ctn.b9.aicdn.com.Name: ctn.b9.aicdn.comAddress: 183.134.101.194 此时，我发现michael-j.net的域名已经成功解析到了又拍云。 完成 完成以上步骤后，你会收到又拍云发给你关于域名绑定通过的邮件。此时你就可以在浏览器中访问你的博客啦！ 最关键的问题是，我们要验证百度是否能正常的抓取我们的博客？ 我们使用百度站长的测试工具来测试一下： 哈哈，现在百度终于可以正常爬去我们的网站啦，接下来就是耐心的等待了，一般最多七天百度就会收录了。 方案二：自己托管博客与利用cdn来制作镜像网站的思路一样，我们完全可以把博客托管在自己的服务器上，当然你得掏银子啦！💰 我个人觉得自己买一台属于自己的虚拟主机还是值得投入了，除了博客外你可以利用这台机器做很多事情，最低配的ecs也花不了多少钱，可以几个人合用一台。 Nginx是世界有名的反向代理服务器，同时它对静态文件的支持非常好，性能很高。我们完全可以利用Nginx来作我们博客的服务器。 1. 安装NginxUbuntu\Debian：apt-get install nginx Centos\Redhat: yum install nginx 其他系统自行google 2. 配置Nginx在/etc/nginx/conf.d新作配置，一定要以.conf结尾。我新建名为michael-j.net.conf的配置文件： 1234567891011server &#123; listen 80; server_name michael-j.net; location / &#123; root /home/michael/mymonkey110.github.io; index index.html; &#125; access_log /var/log/nginx/michael-j.access.log;&#125; 注意root是我们博客的目录，后面会提到。 3. 重启nginx执行nginx -s reload生效 4. 自动下载博客内容我希望每次博客仓库有更新的时候能自动重建本地仓库，为此我专门写了一个工具git-watcher: https://github.com/mymonkey110/git-watcher。当有新的内容push到你的仓库是，它会自动拉去并重建本地仓库。基本原理就是利用github的webhook功能，当有新的push事件发生时，github会发布相应的事件到指定的接口。git-watcher监听push事件，当接受到push事件去pull仓库。如果你觉得这个工具有点儿意思，Please star it. 4.1 安装git-watcher &amp; gitpip install git-watcher apt-get install git 4.2 启动git-watchergit-watcher -u https://github.com/mymonkey110/mymonkey110.github.io.git -s 654321 -u参数配置我们的博客仓库地址 -s参数是我们webhook的secret key git-watcher还支持其他一些参数配置，-h见说明 4.3 配置dns解析将默认的dns解析到我们自己的主机上 4.4 配置webhook进入仓库的settings －&gt; Webhooks &amp; services 设置：Payload URL，这里输入我们主机的地址，这里只能用ip地址。同时，还要设置Secret，这个是用来签名body内容用的，一定要与git-watcher中配置一致 注意，我们只选择发送push事件就可以了。 4.5 测试我们进行一些修改，然后push到博客的仓库，检测一下网站内容是否更新。如果正常更新，那说明已经大功告成了。这是可以再用百度的抓取工具进行诊断。 总结解决百度抓取github内容的问题基本思路都是让百度不直接访问Github，而是通过一个中间服务器来缓存内容。两种方式都需要付费，相对来说使用又拍云搭建镜像服务器在流量较小的情况下比较有优势，速度快，费用少；而自己租用主机在博客流量较大的时候比较经济，你可以选择按带宽计费的方式，同时你还获得了一台完全由你控制的主机，何乐而不为呢？！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客域名更新：michael-j.net]]></title>
    <url>%2F2016%2F06%2F17%2F%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[由于备案原因😢，弃用老的域名michael-j.xyz,正式修改为： http://michael-j.net 本博客主要纪录本人对技术、管理、生活的一些感悟。技术人一定要有沉淀，写博客是一个非常好的方式，我也经常鼓励团队中其他人写博客，记录自己的成长。 喜欢本站内容的同学可以加入收藏哦，也支持rss订阅！😊]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常的选择：Checked Exception还是Unchecked Exception ?]]></title>
    <url>%2F2016%2F06%2F07%2FJava%E5%BC%82%E5%B8%B8%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[曾经听到过关于老司机和新手程序员的区别，其中最大的一个区别就在于异常的处理。新手程序员总是天真得把世界想得太美好，基本上没想过会出现异常的情况，而一个经验丰富的老司机会把最坏的打算考虑进去，给出相应的解决办法，使得发生异常时对系统的影响降低到最小。对此，我深表认同。现实的情况总是复杂的，而且还有很多不怀好意的人时刻准备攻击你的系统。使用你系统的用户越多，这种潜在的风险也就越大。 异常处理是应对这些风险的最强有力的武器。在Java的世界里，异常有两种：受检异常(checked exception)和非受检异常（unchecked exception）。想必所有的Javaer都使用过这两种异常，但是何时使用哪个异常缺失经常困扰程序员的头疼问题。在此，我分享一下自己的看法，如果你有不同的意见，请留意探讨。 1.如果正常情况下会出现，那么使用Checked Exception；反之，则使用Unchecked Exception这条准则是我在决定使用Checked Exception还是Unchecked Exception的第一原则。如果API的使用者在正常使用的过程中都会出现异常，那么这种异常就属于Checked Exception。因为这种异常时属于程序执行流程众多分支之一，API的使用者必须意识到这种情况，并做出相应的处理。 举个栗子： 我希望向zookeeper中创建一个节点，那么这种情况就隐含了两个前提条件： 父节点已经被创建（如果有的话） 本节点还未被创建 那么，这个API的签名大致应该是这样： 1void createNode(String path,byte[] data) throws FatherNodeNotExist, NodeExist; API的使用者看到这个签名的定义时就会得到一个强烈的心理暗示，我需要考虑父节点不存在和本节点已存在的情况，那么他就不得不显示的去处理这两种异常。 有的朋友可能会争论说，我正常的情况下不会出现这种情况，因为使用这个API的前提就是先创建好父节点，而后创建本节点，那我就不用抛出两种异常了，使用者也轻松了许多。但事实真的如此吗？我们想当然的认为了使用者是自己人，他们会乖乖的按照我们的想法去先创建父节点，再创建本节点，如果是在一个很局限的使用场景下，每个人都说经过严格培训的，那么你可以去做这样的假设，但是我还是不推荐你这么做，因为这样设计使得系统是脆弱的，不稳定的。如果能通过系统能自己避免这些错误，为什么不呢？况且，如果你把这个API开放给第三方的使用者，那么情况会更糟糕，你根本不知道他们会怎样去使用API，这非常恐怖！ 有时候情况会变得很复杂，正常情况的鉴定变得很困难，你肯定会遇到这种时候，此时就需要结合你的业务场景去权衡其中的利弊。这依赖与你的经验和对业务场景的理解，我无法给你一个绝对的建议，那样是不负责任的。 我再举个常见的栗子：用户修改他拥有的资源信息。在菜谱APP中给出一个接口，让用户修改他菜谱的信息。那么这里一个隐含的条件就是用户修改他自己的菜谱信息，他是无权限修改别人的菜谱信息的。那么这个API的签名可能是这样的： 1void updateMenu(long menuId,long uid,String title,String description...); 如果用户尝试去修改不属于他的菜谱呢？我们是否需要throws UserPermissionException之类受检异常？我认为是不需要的。判断是这属于正常情况吗？我认为这不算是正常情况。正常情况下，客户端调用修改信息的接口，那么menuId一定是属于这个用户的。如果出现这种情况，要么是你系统设计的就有问题，要么就是不怀好意的人在破坏你的系统。前者需要重新设计我们的系统，而后者我们更不用关系，直接抛出一个RuntimeException就可以，因为他不算正常用户。 2. 调用者中能从异常中恢复的，推荐使用受检异常；反之，则使用非受检异常注意这里的一个关键词是推荐，决定使用哪种异常最为根本的还是第一条原则。如果第一条原则难以判断时，才考虑调用者。这条原则和Effective Java中的第58条很像，如果有这本书的朋友可以再拿出来读读。 我和Effective Java#58不同的观点在于，这条原则只能是推荐，另外，对于所有不能恢复的情况我都建议使用非受检异常。我对可恢复的理解是，如果API的调用者能够处理你抛出的异常，并给出积极的响应和反馈，并指导它的使用者做出调整，那么这就是可恢复的。不可恢复就是API的调用者无法处理你抛出的异常，或者仅仅只是打个LOG记录一下，不能对它的使用者做出提示，那么都可认为是不可恢复的。 还是最开始的栗子，如果调用createNode的调用者能响应FatherNodeNotExist，并把这种情况反应到终端上，那么使用受检异常是有积极意义的。对于不可恢复的情况，包括编程错误，我建议都是用非受检异常，这样系统能fail fast，把异常对系统的影响降到最低，同时你还能获得一个完整的异常堆栈信息，何乐而不为呢？！ 基本上，这两条原则就能帮你决定到底是使用受检异常还是非受检异常了。当然，现实的情况很复杂，需要根据你所处的具体业务场景来判断，经验也是不可或缺的。在设计API的时候多问下自己这是正常情况下出现的吗，调用者可以处理这个异常吗，这会很有帮助的！ 异常处理是一个非常大的话题，除了选择checked exception还是unchecked exception以外，还有一些一般的通用原装，例如： 只抛出与自己有关的异常 封装底层异常 尽量在抛出异常的同时多携带上下文信息 这些在Effective Java中都有详细的介绍，朋友可以认真读一下这本书，写的非常好！ 对异常处理有不同理解的朋友可以给我留言，一起讨论，共同进步！ 参考文献： Effective Java, 2nd Edition.pdf)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防范xss的正确姿势]]></title>
    <url>%2F2016%2F04%2F12%2F%E9%98%B2%E8%8C%83xss%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[xss攻击是web攻击中非常常见的一种攻击手段。如果你还没有听说过xss攻击，可以先了解xss的相关知识和原理，例如:https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)。 防范xss攻击的方式也十分简单：转义！ 但是转义的时机？是在持久化之前转义呢，还是读数据之后escape呢？ 我开始想也没想就选择了第一种方式，因为这种方法看上去一劳永逸，但是我现在越来越倾向于第二种方式。 实际上选择第一种还是第二种需要根据你的实际情况来定。我们知道xss攻击是一种web攻击手段，它的运行环境是在用户的浏览器中，也就是说用户的运行环境是不可控的。那么在持久化之前进行转义看上去似乎不错，因为我们可以利用filter或者interceptor拦截所有的写入请求，统一进行转义。这样一来，我们的业务逻辑就完全不需要care转义的问题了，因为我们取到的数据已经都是转义的过的了。 如果用户的终端是可控的，比如：Native App，那么入库之前进行转义就显得多此一举，因为所有的输出方式都是在我们的App中展现的，自然也就不会出现了xss攻击的问题了。例如用户在评论中输入了&lt;哈哈&gt;，你觉得用户希望输出&amp;lt;哈哈&amp;gt;，还是&lt;哈哈&gt;呢？ 结果是显而易见的。 现实的情况往往是复杂的，不会只有黑和白、0与1、native和web，更多的是它们交织在一起，互相入侵对方的领域。基本上现在大部分的App都有分享功能，那么恶意的用户完全可以在评论中插入注入代码，再将该评论分享出去，那么其它被分享的用户就有被攻击的风险。解决的方法就是针对分享的数据进行全局转义，事实上已经很多模版系统已经帮我们考虑了这部分问题，例如Django和Jinja2的模版就是默认开启自动转义的。如果是前后端分离的场景，也可以有前端来进行escape。 我推荐使用“入库不转义读转义”还有一个原因，那就是前期转义格式的不确定性和后期输出的多样性。如果你正在正在开发一个rest服务器，你与App使用json格式通信。为了简单，在开始业务代码前，你对所有输入数据按照html格式进行转义。那么你可以十分放心分享出去的数据是安全的，因为所有的数据在持久化之前就已经转义了，同时你会痛苦unescape给App的数据。如果那天老板要求你以xml的格式输出这些数据（可能是其它系统的输入要求，也可能是打印报表），那么你会更加痛苦。因为xml和html的转义字符还是有些不同的，你不得不先unescape回原始数据然后再按照xml的格式escape一次。如果这样你觉得都还ok，那么我开始有点佩服你了。如果老板还要求你有更多的输出格式，那么你会更加痛苦，这还是在没有考虑输入格式变化的情况下。因为一个转义的问题导致逻辑变得复杂，影响系统的稳定性是得不偿失的。 最后，我总结一下这两种方式的优缺点： 转义方式 优点 缺点 入库前转义 一劳永逸 需要针对多端进行不同的输出，灵活性不足，无法应对后期数据格式的变化 读取前转义 简单，灵活，能应对各种数据格式的场景 需要对每个输出数据转义，人工处理容易遗漏 本人推荐第二种方式来防范xss攻击。虽然需要对每个输出数据都进行转义，但是如果你使用带自动转义的模版或者框架来处理的话，那么就可以极大的提高效率，又可以规避安全的问题。最后还是要提醒大家，安全无小事，即使你觉得没有人会攻击的系统，还是要规避这些风险，安全是系统的基石。 参考文献： Why escape-on-input is a bad idea When do you escape your data?]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下拳皇97黑屏问题的解决方法]]></title>
    <url>%2F2016%2F03%2F18%2FMac%E4%B8%8B%E6%8B%B3%E7%9A%8797%E9%BB%91%E5%B1%8F%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用Mac系统很久了，渐渐的已经依赖上了这个系统。虽然Mac OS能让我们更加关注于工作，但是偶尔我们还是希望能小小的娱乐一把。我就比较喜欢玩一些小游戏，比如拳皇97。 拳皇街机系列满载的我们80后慢慢的回忆啊！想玩97的朋友可以去：http://www.pc6.com/mac/112306.html下载。 按照提示方法，我发现运行一直是黑屏状态，十分蛋疼。Google了一番后最终找到了解决方法： 打开MAME的Preference -&gt; 切换到Video -&gt; Rendering Option中的Render frames using切换到 OpenGL模式 重新载入游戏就大功告成啦！！！ 祝大家游戏愉快～ 还搞不定可以参考下面这篇帖子👇： https://www.reddit.com/r/mac/comments/3nr2gr/mame_135_on_el_capitan_loads_black_screen_when/]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现领域事件]]></title>
    <url>%2F2016%2F01%2F19%2F%E5%AE%9E%E7%8E%B0%E9%A2%86%E5%9F%9F%E4%BA%8B%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[当你的系统或者业务变得日益复杂时，DDD的模式是一种非常值得尝试的架构模式。DDD让你更加关注于你的业务领域，思考你的业务模型，帮组你理清繁杂的业务关系。我推荐所有还没有了解过或者接触过DDD的后端工程师都去学习一下该架构模式。本文主要关注DDD中的领域事件，以及一种可能的实践方式。 我们知道领域模型的变化会产生领域事件。例如，用户在完成注册后，系统会发出一封带有确认信息的邮件到用户的邮箱；用户关注的好友发送动态后他会收到相应的通知等等。在业务比较简单或者不用考虑性能的情况下，我们可以直接把对领域事件的处理嵌入到领域服务中。考虑这样一个场景：用户回复了某条评论，那么被回复的那个用户（也就是那条评论的所有者）需要收到一个PUSH消息。这个场景比较简单，我们可能直接写出类似下面的代码： 1234 void reply(long fromUserId,long toUserId,String content) &#123; saveReply(fromUserId,toUserId,content); sendPush(toUserId,content); &#125; 这样一来，我们就直接把发送PUSH的动作嵌入到了回复的逻辑中。这样做有以下两个问题： 回复动作处理了它不关心的逻辑。发送PUSH不是回复的强关联逻辑，也就是说即使push发送不成功也应该让回复动作成功。上面的代码将回复和发送PUSH耦合在了一起。 如果出现了多个对回复动作感兴趣的业务方，那么上面的代码将不可维护。比如，我们有一个回复的计数器，它要统计回复的总量。如果把增加计数器的动作写在回复中，那么将不可维护，因为每次出现新的业务方都要修改回复逻辑。这显然返回了开闭原则。 解决上诉问题的方法很简单，就是使用领域事件。领域事件很好理解，说白了就是与领域相关的事件。事件的产生往往伴随着相应的动作，例如上面所提到的回复动作。有了领域事件，每个领域本身就只需要关系其自己的业务逻辑，并在处理完自身逻辑的同时抛出相应的领域事件。对这些领域事件感兴趣的业务方可以订阅该事件，然后进行后续的处理。这与观察者模式和发布订阅模式是十分相像的。我更倾向于发布订阅这个词，它更好的表达了发布者和订阅者的一种解耦。 发布订阅模式有很多种的实现，有很多开源框架和类库也实现了这种模式。例如Spring中的事件，Guava中的EventBus都是很好的实践。直接采用这些工具会有两个问题： 无法灵活的处理同步事件和异步事件。Spring框架自带的事件机制是同步的，那么领域事件的发布者的执行流程就和订阅者的处理流程在一个调用堆栈中了，在某些情况下这事不可接收的。EventBus是支持同步和异步两种模式的，但是它要求在初始化时就指定好事件是同步的还是异步的，这对于使用方不够灵活。 订阅方无法控制事件的订阅与取消。出于解耦和灵活性的考虑，我们往往把事件注册的动作放倒订阅方。Spring框架让这种订阅关系变得模糊，因为事件的注册是通过事件ApplicationListener接口完成的，那么订阅方就无法获得事件发布者的引用，进而无法取消事件的订阅。当然，取消事件订阅的情景并不常见，所以这种情况在大部分场景下也是可以接受的。 无论是出于对事件发送同步异步的控制，还是处于订阅方更高的灵活性要求，自己在这些框架和工具上再进行封装都还是要必要的。下面我给出我的一种实践方案。 我推荐在guava的EventBus上面进行封装，因为它已经实现了同步和异步的模式，并且使用注解的订阅方式对程序员也十分友好。 首先，我们需要定义一个领域事件的抽象基类(DomainEvent)。 1234567891011121314151617/** * 领域事件基类 * Created by Michael Jiang on 16/1/12. */public abstract class DomainEvent &#123; private Date occurredTime; protected abstract String identify(); public DomainEvent() &#123; occurredTime =new Date(); &#125; public Date getOccurredTime() &#123; return occurredTime; &#125;&#125; 这个抽血基类中定义了发生时间和identify的一个抽象方法，该方法用来标示事件。下面我们就可以定义领域事件的发布器了(EventPublisher)，如下图所示。 12345678910111213/** * 领域事件发射器 * Created by Michael Jiang on 16/1/12. */public interface DomainEventPublisher&lt;T extends DomainEvent&gt; &#123; String identify(); void register(Object listener); void publish(T event); void asyncPublish(T event);&#125; 我先定义了领域发布器的一个通用接口，主要包括四个方法： identify() 发布器标示，用来区分不同的发布器。 register(Object) 注册接口，订阅方调用该接口来订阅事件。 publish(T event) 同步发布事件接口 asyncPublish(T event) 异步发布事件接口 同时，我给出了一个基于Guava的实现，如下： 12345678910111213141516171819202122232425/** * Guava事件发布器实现 * Created by Michael Jiang on 16/1/12. */public abstract class GuavaDomainEventPublisher implements DomainEventPublisher &#123; private EventBus syncBus = new EventBus(identify()); private EventBus asyncBus = new AsyncEventBus(identify(), Executors.newFixedThreadPool(1)); @Override public void register(Object listener) &#123; syncBus.register(listener); asyncBus.register(listener); &#125; @Override public void publish(DomainEvent event) &#123; syncBus.post(event); &#125; @Override public void asyncPublish(DomainEvent event) &#123; asyncBus.post(event); &#125;&#125; 我在实现中初始化了两个eventBus，一个是同步的syncBus，用于发布同步事件；另外一个是异步的asyncBus，用于发布异步事件。其中我将异步线程池硬编码为1个线程，基本满足大部分情况，也可酌情修改或者开放这个参数，有各个领域事件的发布器来实现。 具体的领域事件发布器直接继承GuavaDomainEventPublisher，并覆盖identify()方法后就可以使用了。 这里我并没有专门去设计订阅方，因为Guava提供的注解方式已经十分方便了。我设计了一个简单的demo放倒了github上面，有兴趣的朋友可以直接查看源代码。如果你有更好的设计方法或者思路，可以直接留言进行讨论。 Demo地址：https://github.com/mymonkey110/event-light]]></content>
      <categories>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>领域事件</tag>
        <tag>event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[评论设计]]></title>
    <url>%2F2016%2F01%2F05%2F%E8%AF%84%E8%AE%BA%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[本文主要分享了我在设计评论模块中的一些心得，希望对读者有些许帮助。 需求分析现阶段评论做的最好的我想应该是网易新闻（app）里面的评论模块了，其“盖楼”的方式让人印象深刻，评论已经成为该app的核心功能之一了。市面上大部分app的评论模块设计的还是相对简单的，这是可以理解的，因为评论模块不是这些app的核心功能之一。 在设计评论模块前可以和pd或者boss沟通，我们的评论功能是核心功能之一吗？实际上，90%的app采用简单的评论设计就可以了，也就是采用一问一答，类似于如下的设计。 这种设计十分简单、直接，也满足了用户评论、回复的基本要求，对于没有大量用户评论或者评论不是核心功能的app来说就够用了。暂且把这种场景称之为场景A。 如果你是新闻类或者咨询类的app，有着大量的用户评论，那么设计“盖楼”的效果还是可取的，这样能帮助用户找到该条评论或者回复的上下文情景。但是根据“盖楼”的显示效果不同，设计上也是有很大的差别的。如果是以评论为主的显示方式，类似于下面的显示方式。 这里可以把评论分为评论和回复，所有的回复均挂在评论下面，类似于树状结构。把这种场景称之为场景B 最后就是类似于网易新闻的评论设计了，贴一张截图 这种场景下设计最为复杂，因为回复和评论是同等级的，回复还可以引用完整的回复路径，就是可以溯源到最开始的评论上。这种场景我将至称为场景C。 数据库设计由于我 一直使用mysql，我就以mysql为例谈一下针对上面三种场景的设计。 场景A这种场景下一般评论数量较少，评论不为活跃，可以把不区分评论和回复，而统一看成评论。区别在于有的评论是直接评论主题(每个评论都挂在某个主题下，如文章、帖子等)，而有些评论是@其他用户的，为了能cover这两张场景，使用一张表就可以达到效果，评论表如下设计： 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id to_uid 评论目标用户id 为了能复用评论模块，我们引入一个topic_type字段来区分主题的类别。 from_uid表示评论人的id，通过该id我们可以检索到评论人的相关信息。 to_uid 是评论目标人的id，如果没有目标人，则该字段为空。 出于性能的考虑，往往我们会冗余评人的相关信息到评论表中，比如评论人的nick、头像等，目标用户也是如此。这样一来我们就只用查询单表就可以达到显示的效果。 有时，目标用户有多个，那么可以将to_uid字段修改为to_uids，保存时用分隔符来分割用户id，而目标用户的信息再去查询缓存或者数据库。也可以简单的将多个目标用户的信息一起存成json格式，可以应付简单的展现需求。 场景B在以评论为主的树形显示的情况下，数据库的设计十分灵活，可以使用单表，添加一个parent_id字段来指向父评论。如果数据库本身支持嵌套查询，那么还是比较方便的，SqlServer、Oracle都支持，但是mysql不支持，那就只能通过存储过程来实现。在互联网应用中，能不使用触发器 ｀存储过程`的话，尽量不要去使用，因为其对性能有影响。 我们还可以将评论拆分为评论表 和 回复表，评论挂在各种主题下面，而回复都挂在评论下面。 评论表的设计如下： 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id 回复表的设计如下： 表字段 字段说明 id 主键 comment_id 评论ID reply_id 回复目标id reply_type 回复类型 content 回复内容 from_uid 回复用户id to_uid 目标用户id 由于我们拆分了评论和回复，那么评论表就不再需要目标用户字段了，因为评论均是用户对主题的评论，评论表的设计更佳简洁了。 回复表我添加了一个comment_id字段来表示该回复挂在的根评论id，这样设计也是出于性能方面的考虑，我们可以直接通过评论id一次性的捞出该评论下的所有回复，然后通过程序来编排回复的显示结构。通过适当的冗余来提高性能也是常用的优化手段之一。这里给出一段我通过来评论id来查找并组织所有回复的代码： 1234567891011121314151617181920212223242526272829303132333435public List&lt;ReplyDTO&gt; getReplyListByRid(Long rid) &#123;List&lt;ReplyDO&gt; replyDOList = replyDAO.queryReplyByCid(rid); if (replyDOList == null || replyDOList.size() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;ReplyDTO&gt; replyDTOList = new ArrayList&lt;&gt;(); List&lt;ReplyDTO&gt; parentList = new ArrayList&lt;&gt;(); for (ReplyDO replyDO : replyDOList) &#123; ReplyDTO replyDTO = convertReplyToDTO(replyDO); if (replyDTO.getReplyType() == ReplyType.COMMENT) &#123; replyDTOList.add(replyDTO); parentList.add(replyDTO); &#125; else &#123; boolean foundParent = false; if (replyDTOList.size() &gt; 0) &#123; for (ReplyDTO parent : parentList) &#123; if (parent.getId().equals(replyDTO.getReplyId())) &#123; if (parent.getNext() == null) &#123; parent.setNext(new ArrayList&lt;ReplyDTO&gt;()); &#125; parent.getNext().add(replyDTO); parentList.add(replyDTO); foundParent = true; break; &#125; &#125; &#125; if (!foundParent) &#123; throw new RuntimeException(&quot;sort reply error,should not go here.&quot;); &#125; &#125; &#125; return replyDTOList; &#125; reply_type表示回复的类型，因为回复可以是针对评论的回复(comment)，也可以是针对回复的回复(reply)， 通过这个字段来区分两种情景。 reply_id表示回复目标的id，如果reply_type是comment的话，那么reply_id＝commit_id，如果reply_type是reply的话，这表示这条回复的父回复。 在数据结构的设计上，我在replyDTO中设计了一个List&lt;ReplyDTO&gt; next属性，这样在形成了一个树形的结构，类似如下结构。 客户端可以直接根据该结构来进行树形结构的显示。 场景c要达到网易新闻中评论的效果我还没有特别好的建议。这种场景中评论和回复是同级显示的，回复不在显示结构上不用挂在一个评论下面。双表的设计在这里就不太合适了，因为涉及到评论和回复的混排，使用双表则会导致查询的逻辑过于复杂。所以建议还是采用单表的设计，不区分评论和回复会简化应用层的逻辑。我们统一都看成评论，而有些评论是可以引用其他评论的。本人推荐采用闭包表的设计，例如： comment表设计 表字段 字段说明 id 主键 topic_id 主题ID topic_type 主题type content 评论内容 from_uid 评论用户id parent_children表 表字段 字段说明 id 主键 parent_id 父id child_id 子id comment表保存所有评论内容，而parent_children表则记录评论表中各个评论的父子关系。 查询时往往会按照时间排序，我们可以直接按id或者创建时间降序排列查询comment表即可。如果用户想查询一条评论的完整引用，则可以通过parent_children来找到对应的路径。向上查找到评论只需要可执行： select parent_id from parent_children where child_id=${id} and parent_id != ${id} 向下查找所有的子孙评论可执行： select child_id from parent_children where parent_id = ${id} and parent_id != ${id} 闭包表在查询时非常方便，但是插入的性能稍差，因为除了插入评论表以外，还需要把该条评论所有的父子关系插入到父子关系表中。插入性能会随着评论层级的加深而线性下降。 海量数据优化如果你的系统每天都会有成千上万条评论，那么单表的设计肯定是不行，优化的方式也有很多。 分库分表。分库分表是最为常用也最有效的优化方式，建议按照主题来分库分表。这样同一个主题下面的评论就会落到同一张表里，避免了跨表查询。 适当的数据冗余。如果你需要显示评论人的相关信息，那么在插入评论时就把这些信息写入评论表中，避免多次查询。实际上，如果是纪录数据，都可以冗余对应的数据信息，因为它们的数据的实时行和一致性要求并不高，用户不会因为评论中的头像没更新而撕了你，哈哈。 附加幂等数据只允许单项操作。如果pd要求你能给评论点赞，那么你可以告诉他只能点赞，不能取消。因为从幂等性的要求来说，每个赞都是一条记录。评论的赞数如果都从点赞表中统计得出，那么性能开销会十分巨大，而且点赞如此轻量级的一个操作一定会加剧点赞表的竞争操作。所以建议直接在评论表中添加一个like_count的计数器，该字段只增不减。 热门评论加缓存。类似于网易新闻的热门评论，读取频度非常高，可以专门开接口给客户端，同时该接口做缓存。 参考文献： 逻辑数据库设计 - 单纯的树(递归关系数据) 在数据库中存储层级结构 What are the Options for Storing Hierarchical Data in a Relational Database]]></content>
      <categories>
        <category>架构设计</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>评论系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Debug:Tomcat deploy twice]]></title>
    <url>%2F2015%2F10%2F30%2FTomcat%20deploy%20twice%2F</url>
    <content type="text"><![CDATA[最近写了一个分布式时间调度系统，用于调度集群类的定时任务程序。架构如下： 有一个集中化的Scheduler来调度集群中所有的job,集群中的job只负责实现具体job内容，而Trigger的定义和管理均在Scheduler中实现。Trigger通过MQ将触发消息发送到集群中的某台机器上。 在部署Scheduler的过程中观察日志如下出现以下奇怪的现象： 我们发现在同一时刻Scheduler对一个Job触发了两次，而在集群的某台机器上发现一个Job被触发了4次： 当我在自己的机器上始终无法复现该问题。由于是同一个war包，故排出了代码的问题。不同之处在于，我本机启动的方式是用jetty的插件直接启动的，而服务器上则是用的是tomcat容器。经过一番排查发现，是tomcat重复部署的问题，tomcat的官方文档有如下说明: Any Context Descriptors will be deployed first. 因为我想讲应用直接部署在/下，所以在server.xml中的localhost节点下加入了context的配置。根据tomcat的官方文档，如果host下面有context的配置则会先部署，而后容器再部署一次。也就是说，应用被部署了两次。这也就解释了为什么scheduler会触发两次，而job会触发4次了。 解决的方法是将deployOnStart设置为false，autoDeploy设置为false。 参考： http://stackoverflow.com/questions/7223108/quartz-job-runs-twice-when-deployed-on-tomcat-6-ubuntu-10-04lts]]></content>
      <categories>
        <category>踩过的那些坑</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>部署</tag>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btrace Sample Scripts]]></title>
    <url>%2F2015%2F10%2F19%2FDebug-Tomcat-deploy-twice%2F</url>
    <content type="text"><![CDATA[Btrace is very powerful tool for online debugging, here is the sample scripts in tar btrace. The scripts are very useful, so I decide to upload them. Here is the scripts below: AWTEventTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AWTEventTracer.java AllCalls1.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls1.java AllCalls1Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls1Sampled.java AllCalls2.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls2.java AllCalls2Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls2Sampled.java AllCalls3.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls3.java AllCalls3Sampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllCalls3Sampled.java AllLines.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllLines.java AllMethods.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllMethods.java AllMethodsSampled.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllMethodsSampled.java AllSync.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-AllSync.java ArgArray.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ArgArray.java Classload.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Classload.java CommandArg.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-CommandArg.java DTraceInline.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-DTraceInline.java DTraceRefDemo.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-DTraceRefDemo.java Deadlock.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Deadlock.java FileTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-FileTracker.java FinalizeTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-FinalizeTracker.java HistoOnEvent.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-HistoOnEvent.java Histogram.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Histogram.java HistogramBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-HistogramBean.java JInfo.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JInfo.java JMap.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JMap.java JStack.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JStack.java JdbcQueries.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-JdbcQueries.java LogTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-LogTracer.java MemAlerter.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-MemAlerter.java Memory.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Memory.java MultiClass.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-MultiClass.java NewArray.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-NewArray.java NewComponent.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-NewComponent.java OnThrow.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-OnThrow.java ProbeExit.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ProbeExit.java Profiling.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Profiling.java Sizeof.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Sizeof.java SocketTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SocketTracker.java SocketTracker1.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SocketTracker1.java SubtypeTracer.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SubtypeTracer.java SysProp.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-SysProp.java Test.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Test.java ThreadBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadBean.java ThreadCounter.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadCounter.java ThreadCounterBean.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadCounterBean.java ThreadStart.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-ThreadStart.java Timers.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-Timers.java URLTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-URLTracker.java WebServiceTracker.java : http://7xnmye.com1.z0.glb.clouddn.com/btrace-WebServiceTracker.java You can access them with curl or wget, wish you happy debugging!]]></content>
      <categories>
        <category>debug</category>
      </categories>
      <tags>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Autoconfig打包Java WEB应用]]></title>
    <url>%2F2015%2F10%2F17%2F%E5%88%A9%E7%94%A8Autoconfig%E6%89%93%E5%8C%85Java-WEB%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介： 本文主要介绍常用的后台应用打包的几种方式 后端应用上线前都需要经过重新打包，可千万别小看了这个阶段，这个是非常非常重要的！如果打错了包或者使用错了配置文件，结果可能是毁灭性的！ 我们都知道每个软件项目或者公司都会维护几套隔离环境，例如以前在阿里就会有日常测试、日常、预发和线上几个环境，还有根据特殊需要配置的独立环境，如性能环境等等。 当然，对于小公司或者创业公司来说不需要准备这么多套环境，但至少是需要测试和线上两套环境的。多套环境的可以有效的隔离线上和线下，提高开发人员的工作效率，又不至于将不稳定的代码带到线上。其中最重要的一个环节就是打包，我主要介绍两种简单的打包方式。 利用Spring配置现在Java WEB应用可以说90%都使用了Spring框架，而Spring框架早就帮我们考虑了这个问题。我一开始也是使用这个配置方式，在Spring配置文件中引入一下配置： &lt;context:property-placeholder location=”file:${APP_HOME}/config.properties”/&gt; Spring是支持classpath和file的，个人推荐使用file模式来查找外部配置文件，因为这样我们就不必将配置文件引入到工程目录中了，因为工程目录对所有的开发人员都可见，这样会降低配置文件的安全性。引入外部配置文件一个常见的做法就是使用环境变量，我们新建一个APP_HOME的环境变量来区分不同的环境。 在使用配置文件的地方利用placeholder进行配置即可，例如以下方式： 123456&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp2.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;db.driverClass&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;db.url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;db.username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;db.password&#125;&quot;/&gt;&lt;/bean&gt; 在Spring启动以后，它会去查找你配置的外部配置文件，并逐个替换使用的配置中的placeholder。 这种方式的优点就是简单，灵活，但是缺点也是很明显的： 只支持Spring配置文件的替换，不支持其他框架配置文件的替换。 如果你想替换logback.xml中的某个配置，例如日志输出目录或者日志输出级别，它是做不到的。 大规模部署不方便。如果只有一两机器这样部署还是比较方便的，但是如果有几十台甚至上百台这样打包就十分麻烦了。如果改动一个配置项，就需要保持所有机器的同步的，所以一般大一点的公司都会有专门负责配置的服务，例如阿里的ConfigServer。 利用AutoConfig打包AutoConfig 是阿里内部使用的一个打包工具，十分方便，也十分强大，这里有它的介绍：http://openwebx.org/docs/autoconfig.html 下面是我利用AutoConfig打包的步骤： 添加不同环境的配置 为了直接利用Maven打出不同环境的包，我们在需要打包的module的pom中添加下面的配置： 1234&lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.dev&lt;/autoconfig.properties&gt; &lt;env&gt;dev&lt;/env&gt;&lt;/properties&gt; 然后加入profile配置： 1234567891011121314151617181920212223242526&lt;profiles&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.dev&lt;/autoconfig.properties&gt; &lt;env&gt;dev&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.test&lt;/autoconfig.properties&gt; &lt;env&gt;test&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;online&lt;/id&gt; &lt;properties&gt; &lt;autoconfig.properties&gt;antx.properties.online&lt;/autoconfig.properties&gt; &lt;env&gt;online&lt;/env&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 添加autoconfig maven插件支持 123456789101112131415 &lt;plugin&gt; &lt;groupId&gt;com.alibaba.citrus.tool&lt;/groupId&gt; &lt;artifactId&gt;autoconfig-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;configuration&gt; &lt;userProperties&gt;$&#123;user.home&#125;/conf/$&#123;autoconfig.properties&#125;&lt;/userProperties&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;autoconfig&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 其中,userProperties属性就是我们使用的配置文件。 利用Maven进行打包 进入到需要打包的module中，然后执行mvn package -P&lt;env&gt;，其中env代表不同的环境，在上面的配置中env只能为dev、test和online.我们可以将最终的包名也带上环境名称，以区分打出来的不同环境的包，如下配置： &lt;finalName&gt;包名-${env}&lt;/finalName&gt; Tips:如果开发人员使用的是jetty插件来进行本地开发的，那么需要将jetty:run改为jetty:run-war，因为autoconfig是需要执行package才会进行触发的，而jetty:run不会执行package阶段。可以参考一下配置： 1234567891011121314151617&lt;!-- jetty插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;7.6.16.v20140903&lt;/version&gt; &lt;configuration&gt; &lt;webAppSourceDirectory&gt;src/main/webapp&lt;/webAppSourceDirectory&gt; &lt;scanIntervalSeconds&gt;3&lt;/scanIntervalSeconds&gt; &lt;connectors&gt; &lt;connector implementation=&quot;org.eclipse.jetty.server.nio.SelectChannelConnector&quot;&gt; &lt;port&gt;8080&lt;/port&gt; &lt;maxIdleTime&gt;60000&lt;/maxIdleTime&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;war&gt;target/包名-$&#123;env&#125;.war&lt;/war&gt; &lt;/configuration&gt; &lt;/plugin&gt;]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>package</tag>
        <tag>autoconfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java也能玩转WebSocket]]></title>
    <url>%2F2015%2F05%2F30%2FJava%E4%B9%9F%E8%83%BD%E7%8E%A9%E8%BD%ACWebSocket%2F</url>
    <content type="text"><![CDATA[本篇介绍使用Netty来实现Websocket，为实践篇，不涉及原理性讨论。 1. 什么是Websocket? WebSocket 是H5提供的一个基于TCP链接全双工的通信协议，可以简单HTTP协议的长链接升级版。 为什么要用websocket、使用websocket的好处已经websocket的原理这里就不再赘述了，上面的两篇文章都介绍的非常清楚了。 2. 准备工作 升级Nginx Nginx从1.3.13版本开始支持WebSocket协议，由于集团里面使用的是Tengine，所以需要先查看Tengine版本号。使用下面命令即可： /home/admin/cai/bin/nginx-proxy -v 执行完后发现：Tengine version: Tengine/1.4.6 (nginx/1.2.9) ，nginx版本太低。升级Tengine就行，较新的Tengine都以支持Websocket. 升级Tengine命令执行：sudo yum install -b current tengine 会安装最新版的Tengine。 安装配置的过程还是由很多坑的。 接下来就是配置nginx了，配置很简单，按照一下配置即可。 123456location /chat/ &#123; proxy_pass http://127.0.0.1:9999/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;&#125; 如果你想更加灵活的配置可参考: http://nginx.org/en/docs/http/websocket.html 最后，重新加载nginx配置就可以了，sudo sh nginxctl reload。 升级WEB容器 这一步并不是必须的，如果你使用的Websocket的实现依赖于WEB容器，那么就必须升级WEB容器来支持。 JSR356规范制定了Websocket的标准，只要是实现了JSR356规范的容器均支持Websocket。Tomcat从7.0.47版本开始支持JSR356标准，并且要求JDK版本至少为1.7。 由于升级WEB容器带来的变化太多，本人并没有采用这种方式。 3. Java对Websocket的支持 JavaEE 7开始全面支持Websocket协议 Spring4.0才实现了JavaEE 7标准，那么如果希望Spring直接支持Websocket协议，那么必须将Spring升级到4.0以上。使用Spring框架来支持Websocket的好处就是可以使用它大量的注解和服务，而且可以很好的与现有业务相结合。 WEB容器对Websocket的支持 前面提到了JSR356标准指定了Websocket规范，在这个标准出来后很多WEB容器都纷纷实现了该标准，以支持Websocket。该阶段处于Websocket的初期，各个容器的实现方式也各不相同，如果不想升级到Spring4而又想使用Websocket，那么就可以利用容器的特性了。如果你有这方面的需求可以参考：http://blog.fens.me/java-websocket-intro 、http://redstarofsleep.iteye.com/blog/1488639 利用Netty来实现Websocket Netty是一个Java语言实现的非常高效的基于事件的网络库，感谢师兄告诉我这个框架。我也是刚接触这个框架不久，原理我就不谈了。如果你有Linux下的开发经验一定对这种框架不会陌生，这些框架的底层都经历了select\poll到epoll的转变，在Linux下有Libev\Libevent之类相似的框架，以及Node底层的Libuv也是如此，这方面的资料也是非常多的。 我们要用Netty是不仅是因为它是一个高效的网络库，而且它还是实现了很过高层的网络协议，其中就包括Websocket。Netty对Websocket有很好的支持，而且它对Websocket的处理是原生的，不依赖于底层容器，那么我们就可以在不升级底层容器已经改变Spring框架的基础上来编写基于Websocket的应用了。 4. Netty来创建Websocket链接 启动Websocket服务器 12345678910111213141516171819202122232425262728293031323334353637public class WebSocketServer &#123; private int port; private final EventLoopGroup workGroup = new NioEventLoopGroup(); @Resource private ChannelPipelineInitializer channelPipelineInitializer; private static Logger logger = LoggerFactory.getLogger(WebSocketServer.class); public void init() throws Exception &#123; InnerWebSocketServer wsServer = new InnerWebSocketServer(); new Thread(wsServer).start(); &#125; public void setPort(int port) &#123; this.port = port; &#125; class InnerWebSocketServer implements Runnable &#123; @Override public void run() &#123; try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(workGroup).channel(NioServerSocketChannel.class) .childHandler(channelPipelineInitializer); ChannelFuture future = serverBootstrap.bind(new InetSocketAddress("127.0.0.1",port)).syncUninterruptibly(); logger.info("WebSocket Server is running on " + future.channel().localAddress()); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; logger.error("Start Websocket error:&#123;&#125;.",e.getMessage(),e); &#125; finally &#123; workGroup.shutdownGracefully(); &#125; &#125; &#125; &#125; Tips:注意为了让Netty在Spring初始化的时候启动，我指定了init方法为这个bean的初始化方法。而Netty的监听方法是一个同步调用(sync方法),这会阻碍Spring继续初始化，导致初始化失败。所以我在初始化方法中启动了另外一个线程来完成WebsocketServer的初始化。 注册处理Pipeline Netty的处理请求的方式与Webx的很相似，连名字都叫Pipeline。我们先要注册一系列的Handler来完成对一个Websocket的请求的处理，类似于Spring里面Interceptor的概念。 1234567891011121314151617 @Component public class ChannelPipelineInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Resource private WebSocketFrameHandler webSocketFrameHandler; @Resource private HttpRequestHandler httpRequestHandler; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline=ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(64*1024)); pipeline.addLast(httpRequestHandler); pipeline.addLast(new WebSocketServerProtocolHandler("/ws/")); pipeline.addLast(webSocketFrameHandler); &#125;&#125; Tips:httpRequestHandler和websocketFrameHandler是自己实现的处理Handler。前者会负责对请求做一些基本校验已经获取SESSION的动作，而后者是则是消息处理的Handler，实现了各种事件的处理逻辑，也是跟业务紧密相关的地方。 实现WebSocketFrameHandler 一般情况下我们只用实现SimpleChannelInboundHandler就可以了. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 @Component @ChannelHandler.Sharable public class WebSocketFrameHandler extends SimpleChannelInboundHandler &#123; @Resource private WebSocketHandlerFactory webSocketHandlerFactory; private static Logger logger = LoggerFactory.getLogger(WebSocketFrameHandler.class); @Override @SuppressWarnings("unchecked") protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &#123; WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.read(ctx, msg); &#125; @Override @SuppressWarnings("unchecked") public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; super.channelInactive(ctx); logger.info("Client " + ctx.channel() + " disconnected!"); getWebSocketHandlerByChannel(ctx.channel()).disconnect(ctx); &#125; @Override @SuppressWarnings("unchecked") public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; super.channelActive(ctx); WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.connect(ctx); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt == WebSocketServerProtocolHandler.ServerHandshakeStateEvent.HANDSHAKE_COMPLETE) &#123; logger.info("Client " + ctx.channel() + " connected!"); &#125; &#125; @Override @SuppressWarnings("unchecked") public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; logger.error("Caught WebSocket Error,error:&#123;&#125;.", cause.getMessage(), cause.getStackTrace()); super.exceptionCaught(ctx, cause); WebSocketHandler handler = getWebSocketHandlerByChannel(ctx.channel()); if (handler != null) handler.caughtException(ctx, cause); &#125; @SuppressWarnings("unchecked") private WebSocketHandler getWebSocketHandlerByChannel(Channel channel) &#123; String topic = channel.attr(WebSocketConstants.TOPIC).get(); WSTopicIdentify topicIdentify = WSTopicIdentify.getTopicFromValue(topic); if (topicIdentify == WSTopicIdentify.UNKNOWN) return null; return (WebSocketHandler&lt;ChannelHandlerContext, Object&gt;) webSocketHandlerFactory.getWebSocketHandler(topicIdentify); &#125;&#125; Tips:为了让Websocket与具体业务分离，建议对不同的业务实现自己的WebsocketHandler,而这里总的handler根据业务的标识符路由到不同的业务handler即可。 5. 让Netty更好的于业务结合 与Spring结合 由于业务上基本都是使用Spring框架，为了在Spring中使用Netty，需要将Netty的启动Server配置为一个Bean, 由Spring服务初始化。注意Netty启动会阻塞本身线程的问题。那么跟Netty相关的Pipeline子handler均要定义为bean，这样就可以使用原有的业务系统中的服务了。 按业务路由 考虑到以后会有其他业务使用Websocket的场景，那么我们必须将websocket的能力按照业务进行区分。本人的建议是从URL上来区分业务，不同的业务使用不同URL。去掉通用websocket的前缀后，根据后门的URL来区分业务。ctx.channel().attr(WebSocketConstants.TOPIC).set(msg.getUri().substring(WebSocketConstants.wsUriPrefix.length())); 建议设置一个Websocket的ENUM TOPIC，不同的业务拥有不同的TOPIC，这样就可以根据URL来区分业务了。 6. 后记 使用Netty处理websocket还是非常方便的，加上其本事强大的网络处理能力，使得上层应用无需关系底层实现。虽然和Node.js这样技术比起来还是比较笨重，但随着业务的发展，我相信Java的优势会渐渐体现出来。 使用websocket本事不难，难得是在分布式环境下使用长链接技术。其中涉及到业务状态的保存与恢复、服务器间通信的问题、停机维护的问题、状态跟踪的问题等等，如果业务比较复杂，那么异常处理的情况都会非常复杂。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Tair实现分布式并发锁]]></title>
    <url>%2F2014%2F12%2F23%2F%E5%88%A9%E7%94%A8Tair%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%B1%80%E5%B9%B6%E5%8F%91%E9%94%81%2F</url>
    <content type="text"><![CDATA[最近大量使用到了Tair来控制并发，有点心得，总结如下。 利用Tair实现全局并发锁 现在基本上线上服务器都是集群环境，那么当我们需要对中心化数据（例如:Tair、数据库）的同一内容进行读写时就会碰到并发问题，这是一种非常常见的需求。解决并发问题的方法无非有两种，在并发点控制并发或者在并发源头控制。 图画的有点丑。并发点控制最常用的一种方式就是使用锁，每个需要访问数据的线程都需要先获取锁，然后才能去访问数据库。根据获取锁的策略的不同，又可以根据不同纬度分为乐观锁、悲观锁，忙等、闲等，互斥锁、读写锁等等。 在并发源头控制就是利用第三方的工具，一般是消息队列来将并发访问串行化，然后由统一的数据操作者来访问数据。消息队列的使用不在本文的讨论范文内。比较有名的开源消息队列有,RabbitMQ,ZeroMQ。当然,公司内部也有对应的产品，如Notify,MetaQ。 由于在分布式环境中，要实现全局的并发锁，那么我们必须借助第三方的服务来进行协调。数据库和缓存经常会成为我们的优先选择。出于性能的考虑，一般选用缓存来实现全局并发锁，其中的关键也就是借助Tair的Version控制，相比已经有很多人已经在这样做了。Tair提供了以下API： ResultCode put(int namespace, Object key, Serializable value, int version, int expireTime) 利用该API实现并发控制轻而易举,伪代码如下： 1234567891011 //加锁 public boolean lock(String key, int timeOut) &#123; ResultCode rc = tairManager.put(NAMESPACE, key, DEFAULT_VALUE, INIT_VERSION, timeOut); return rc!=null&amp;&amp;ResultCode.SUCCESS.equals(rc)?true:false; &#125; //解锁 public boolean unlock(String key) &#123; ResultCode rc = tairManager.invalid(NAMESPACE, key);return rc!=null&amp;&amp;ResultCode.SUCCESS.equals(rc)?true:false; &#125; 这主要是利用了Tair的VERSION特性。如果KEY不存在的话，传入一个固定的初始化VERSION，Tair会在保存这个缓存的同时设置这个缓存的VERSION为你传入的VERSION+1；然而KEY如果已经存在，Tair会校验你传入的VERSION是否等于现在这个缓存的VERSION，如果相等则允许修改，否则将失败。 其过程如下图所示： 这是一个很通用的过程，但是却能涵盖大部分的场景。其实理解这个过程非常简单，这里可以把其想象成受精卵形成的过程。虽然有成千上万个精子会进入卵巢，但当第一个精子和卵子结合以后就会形成一层隔离层，以阻止其他精子的进入。而这里的隔离层就类似于TAIR的VERSION。如果想知道更多过程可以参考VERSION的文档。 利用Tair实现全局TOP-N并发锁 全局TOP-N并发锁是我自己想出来的一个名字，有点不明觉厉吧。实际业务中我们可能会遇到这样一种情况，在短时间内会有大量的并发来获取某种资源，但是我们这个资源又有数量限制。例如，抢火车票，在某一时刻将1000张火车票发出去，假如有大量的用户在同一时间来抢这些火车票就会形成并发，同时我们又有着很高的性能要求。以抢火车票为例，下面是我的思考过程。 因为我需要控制并发，要告诉第1001个用户你没有抢到，那么我肯定需要一个计数器来保存火车票发售的实时情况，那么很容易就写出了以下伪代码： 12345678910if(get(ticker_counter)&lt;1000)) &#123; bool lockFlag=lock(key,60); if(lockFlag) &#123; int counter=get(ticker_counter); if(++counter&lt;1000) &#123; set(ticker_counter=counter) &#125; unlock(key); &#125;&#125; 首先获取当前计数器的值，如果&gt;=1000则直接失败返回,表示已经被抢完了，但是如果&lt;1000，表示还没被抢完，则尝试去获取全局锁，如果获取成功则增加计数器的值，注意此时是需要再获取一次计数器的。但是这样会有一个明显的问题，就是当A获取了锁，正在执行增加计数器操作时，B也去尝试获取锁，此时必然是失败的。但是我现在就应该告诉他你已经失败了吗，你没有机会获得这张火车票了吗？显然不是。因为我们允许获取的资源是一个范围，那么当没有明确地表示现在资源已经超出这个返回了或者没有资源了，那么现在所有尝试得到资源的线程或者用户都是有机会的。此时，书中的一个概念浮现出来——信号量。这种业务场景正好是信号量技术能够解决的。但是在分布式环境下如何解决这个问题呢。 我想到了Linux环境下编程时的很多技术。其中就有一个很这个业务场景非常相似的API，就是POSIX系列里面的pthread_cond_wait()和pthread_cond_signal()。前者会一直阻塞直到等待的资源变为可用，而后者会唤醒一个正在等待某个资源的线程。如果有有这两个语义的API存在的话就会变得非常简单，伪代码将变为： 123456789if(get(ticker_counter)&lt;1000)) &#123; pthread_cond_wait(); int counter=get(ticker_counter); if(++counter&lt;1000) &#123; set(ticker_counter=counter) &#125; pthread_cond_signal(); &#125; &#125; 只可惜在分布式环境下没有这两个语义的API操作存在，那么久不得不转化思维。之所以我需要这两个语义的API存在是因为我希望在A线程完成工作以后，将这个状态/消息通知到其他在等待的线程，并且这些线程是分布式的。其实这里是可以使用到消息模型的。notify会选择集群中的一台服务器投递消息，这就可以作为唤醒操作。所有的worker一开始都去监听notify的消息，直到其中一个worker收到，然后去checkAndInc(counter)，最后再发出一个消息，如此循环就能达到目的。最后只需要增加一个Trigger,在最开始执行的时候直接去执行，而不用等待notify消息，就能完成完整的流程。但是，如此简单地一个功能，真的要实现的这么复杂吗？当然不行，什么时候都要坚持KISS原则。 其实，我最终的目的很简单，就是增加一个计数器的值，然后达到某一上线时希望能够得到一个错误返回。因为在做以前一个项目时使用到了Tair中计数器的功能，带着侥幸的心理重新去找Tair的API，居然发现了这个重要API: `Result&lt;Integer&gt; incr(int namespace, Serializable key, int value, int defaultValue, int expireTime, int lowBound, int upperBound)` 当我看到这个API的时候感悟良多，在此还是要感谢一下设计这个API的作者，因为这个API的设计就是为这种业务场景而生的。这个incr()操作可以指定一个范围段，如果value值不在这个范围段中就会报错。有个这个API那么伪代码就简化成以下： 12result = tairManager.incr(NAMESPACE, key, 1, 0, 60, 0, 1000); return ResultCode.SUCCESS.equals(result.getRc())? true : false 这个多么的简洁和优雅,而且又有着很高的性能。如果有着类似的业务场景，推荐大家不妨试一下这个API。 一点思考 现在分布式计算越来越受到重视，随着去IOE的深入，大型机的时代一去不复返。但是分布式计算的流行使得程序员思考问题的方式也在发生改变，以前在单机上运行很好地系统，拿到分布式环境下可能就会出现各种问题。虽然整体架构发生了很大的变化，但是单机时代的很多思想还是值得我们去借鉴的。就比如信号量计算，PV操作。以前这些技术靠操作系统去实现就好了，但是在分布式环境下就很难实现这些以前看似很自然的功能。从某种程度上，这又为我们的中间件技术指明了发展的道路。如果哪一天业务程序员能在分布式环境中像在单机环境里编程，那分布式技术的发展就达到了一个新的高度。]]></content>
      <tags>
        <tag>distributed lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#网络编程初步之TCP]]></title>
    <url>%2F2011%2F10%2F03%2FC%23%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%AD%A5%E4%B9%8BTCP%2F</url>
    <content type="text"><![CDATA[阅读背景：本文针对有C#的初学者而写的，主要讲解如何利用C#进行网络编程。如果你已经有一些网络编程的经验（只需要懂得网络编程的基本常识即可），并且理解C#的基本语法，那么这篇文章可以很快地带你进入C#网络编程的世界。如果你的基础不好，也不要紧，我相信这篇文章也会有你需要的内容。 网络编程基础复习： 图1. TCP编程基本模型 相信很多人看到图1应该不会陌生，这是一个利用TCP进行通信的经典模型图。我想大家都应该把这张图记在心中。 在此我就不讲述上图中每个API的意思了，百度一下，你就知道。我想说的是，难道你不觉得这么编程很累吗? 我们需要去调用每个API函数，然后每个判断返回值是多少，如果你忘记了哪个API的参数形式还得去查MSDN，这种时间花费是巨大的，尤其当你做应用层的快速开发时。 图2是利用UDP通信时的编程基本模型，这个模型较为简单，但是应用极为广泛，相比TCP而言，我本人觉得利用UDP通信是一门更为高深的技术，因为它是无连接的， 换言之，它的效率与灵活度就更高些。 图2. UDP编程基本模型 在此我补充一点，关于何时利用TCP通信、何时利用UDP通信的问题。他们的特性其实已经决定了他们的适用范围。 在进行大数据量、持续连接时，我们使用TCP，例如FTP协议；而在进行小规模数据、突发性高的通信时，我们使用UDP，例如聊天程序。 但是，这并不是绝对的事情。例如流媒体通信，它是大数量、持续的通信，但是使用的是UDP协议，为什么呢？ ——因为我们不关心丢失的帧，人的肉眼是无法识别出少量的帧丢失的。那么使用UDP通信就可以大幅度提高效率，降低网络负载。 C#之TCP编程如何创建一个套接字? 我们先来看看利用Winsock2是如何建立一个套接字的： 首先，我们要加载套接字库，然后再建立套接字。大致代码如下： WORD wVersion=MAKEWORD(2,2); WSADATA wsaData; if(WSAStartup(wVersion,&amp;wsaData)) { WSACleanup(); returnFALSE; } m_sock=WSASocket(AF_INET,SOCK_DGRAM,IPPROTO_UDP,NULL,0,0); if(m_sock==INVALID_SOCKET) { MessageBox(&quot;创建套接字失败！&quot;); return FALSE; } 难道你不觉得利用Winsock2创建一个套接字很费劲吗？如果你在Linux环境中变成倒是可以省掉加载套接字的部分， 但是却只能反复的调用API，这样也是很费时的事情。那我们再看看看利用C#是如何帮你简化工作的。这里我会介绍TCPClient类。 以上是从MSDN上截取的一段话，可见我们利用TCPClient还处理与TCP通信相关的操作。TCPClient有四个构造函数，每个构造函数的用法是有不同的。这里我补充一个知识，那就是端地址在C#中描述。 我们知道，我们用一个IP地址和一个端口号就可以表示一个端地址。在C#中我们利用IPEndPoint类来表示一个端地址，本人经常利用如下的构造函数来创建一个IPEndPoint类。 IPEndPoint localEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); 这样来表示一个端地址是不是比创建一个struct sockaddr_in的结构体来的快呢？ 如何绑定一个端地址？ 我们已经创建了一个端地址，也构造了套接字（TCPClient类），那么如何将二者绑定起来呢?也许你已经发现了，在建立TCPClient的时候我们其实就可以绑定端地址了。 如果你使用的TCPClient tcp_Client=new TCPClient()的构造函数来创建的TCPClient,那么系统会认为你没有人为的制定端地址，而会自动帮你制定端地址，在创建客户端的TCPClient时我们常常这样做， 因为我们不关心客户端的端地址。如果是服务器监听呢？在服务器监听时我们会使用例外一个类，叫做TCPListener，接下来我会讲到。我们可以利用TCPClient(IPEndPoint)来构造一个绑定到固定端地址的TCPClient类。例如： TcpClient tcp_Client = new TcpClient(localEP); 如何监听套接字？ 到现在为此我们还没讨论如何监听一个套接字。在传统的socket编程中，我们创建一个套接字，然后把它绑定到一个端地址，而后调用Listen()来监听套接字。而在C#中，我们利用TCPListener来帮我们完成这些工作。让我们先来看看如何在C#监听套接字。 IPEndPointlocalEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); TcpListenerListener = new TcpListener(localEP); Listener.Start(10); 我们首先创建需要绑定的端地址，而后创建监听类，并利用其构造函数将其绑定到端地址，然后调用Start(int number)方法来真正实施监听。这与我们传统的socket编程不同。以前我们都是先创建一个socket，然后再创建一个sockaddr_in的结构体。我想你应该开始感受到了C#的优势了，它帮我们省去了很多低级、繁琐的工作，让我们能够真正专注于我们的软件架构和设计思想。 如何接受客户端连接？ 接听套接字后面自然就是接受TCP连接了。我们利用下面一句话来完成此工作： TcpClient remoteClient =Listener.AcceptTcpClient(); 类似于accept函数来返回一个socket,利用TCPListener类的AcceptTcpClient方法我们可以得到一个与客户端建立了连接的TCPClient类， 而由TCPClient类来处理以后与客户端的通信工作。我想你应该开始理解为什么会存在TCPClient和TCPListener两个类了。 这两个类的存在有着更加明细的区分，让监听和后续的通信真正分开，让程序员也更加容易理解和使用了。 这里我还得补充一点：监听是一个非阻塞的操作Listener.Start()，而接受连接是一个阻塞操作Listener.AcceptTcpClient。 说了这么多，还不如来个实例来的明确。接下来，我会通过一个简单的控制台聊天程序来如何使用这些。先贴代码吧！ 服务器端： using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Net; using System.Net.Sockets; namespace Demo { class Program { static void Main(string[]args) { byte[]SendBuf = Encoding.UTF8.GetBytes(&quot;Hello,Client!&quot;); //发给客户端的消息； IPEndPointlocalEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;),6666); //本地端地址 TcpListenerListener = new TcpListener(localEP); //建立监听类，并绑定到指定的端地址 Listener.Start(10); //开始监听 Console.WriteLine(&quot;Server is listening...&quot;); TcpClientremoteClient = Listener.AcceptTcpClient(); //等待连接（阻塞） Console.WriteLine(&quot;Client:{0} connected!&quot;,remoteClient.Client.RemoteEndPoint.ToString()) ; //打印客户端连接信息； remoteClient.Client.Send(SendBuf); //发送欢迎信息； remoteClient.Close(); //关闭连接； } } } 客户端: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Net; using System.Net.Sockets; namespace Demo_Client { class Program { static void Main(string[] args) { byte[] RecvBuf=new byte[1024]; //申请接收缓存； int RecvBytes = 0; //接收字节数； string recvmsg=null; //接收消息； IPEndPoint remoteEP = new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6666); //远程服务器端地址； TcpClient remoteServer = new TcpClient(); //创建TCPClient类来与服务器通信； remoteServer.Connect(remoteEP); //调用connect方法连接远端服务器； Console.WriteLine(&quot;I&apos;m using {0}.&quot;, remoteServer.Client.LocalEndPoint); //打印自己使用的端地址； RecvBytes=remoteServer.Client.Receive(RecvBuf); //接受服务器发送过来的消息； recvmsg=Encoding.UTF8.GetString(RecvBuf,0,RecvBytes); //将接受到的字节码转化为string类型； Console.WriteLine(&quot;Server says:{0}.&quot;, recvmsg); //打印欢迎信息； } } } 在C#网络编程中，我们要用到两个名空间，分别是System.Net和System.Net.Socket。 可能有人会有这样的疑惑，干嘛要申请一个Byte数组。我们知道，在传统socket编程中，我们都是用char来发送或者接受消息的， 其实char和Byte[]是同源的。他们都是一个Byte，而使用Byte[]能更易于人们理解和转化为其他类型。我们知道网络间传输的字节流，而Byte[]刚好符合了这个思想。 如果对以上类的用法不理解或者不熟悉的话，建议查看MSDN，上面讲解的很详细。 现在看看运行效果： 图3 运行效果（左为服务器，右为客户端） 好啦，到这里我们C#网络编程初步之TCP基本上算告一段落了，我只讲解了最为基础的部分，仅做抛砖引玉的作用。每个类的使用千变万化，希望你能找到最适合自己使用方法。现在你可以对比以前类似程序的代码了，看看我前面有没有说错。而且，越到后来你会越来越体会到C#人性化的一面。 后期的博文中，我会更新C#网络编程初步之UDP.本人更喜欢利用UDP来进行通信，至于为什么我已经说过了。以后，我会逐步写一些网络编程的高级内容，例如异步通信、多线程编程，并关注程序员经常遇到的一些棘手问题，比如TCP边界的确定等等。有机会，我也会同大家讨论网络编程中常用的软件设计思想与架构。 （本文图1、图2来自互联网，有部分信息来自MSDN。如需转载本文，请注明出处！谢谢）]]></content>
      <categories>
        <category>C#</category>
      </categories>
      <tags>
        <tag>C# tcp udp network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超小型局域网组建的方案]]></title>
    <url>%2F2011%2F09%2F03%2F%E8%B6%85%E5%B0%8F%E5%9E%8B%E5%B1%80%E5%9F%9F%E7%BD%91%E7%BB%84%E5%BB%BA%E7%9A%84%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[生活中我们经常会遇到需要组建一个超小型局域网共享上网的问题，比如在学校组建一个小型局域网共享上网，或者组建一个家庭网络共享上网等，在此过程中会碰到很多小问题，本人故撰此文，望能减少一些不必要的麻烦。 在学校上网，可以通过校园网，也可以通过电信宽带或者ADSL拨号上网（通过电话线上网）等。通过校园网上网，经济实惠，当然网速也是惊人的，尤其是喜欢玩游戏的同学就更悲剧了。通过校园网上网没有什么灵活性和扩展性，故在此不讲了。就以通过电信上网为例来进行分析与组建。如果你们寝室或出租屋有宽带接入，那么恭喜你了，你可以省下一个“猫”钱。4台PC以下共享上网的话，那必需购置一台4孔的交换机，一般在40~50元左右，然后购置网线若干，就是普通的直连线，一块钱一米的那种。(像我们学校水晶头都收钱，悲剧！)至此，所需的硬件就准备好了。 然后就是子网划分了，由于是超小型局域网，在这里可以使用C类IP私有地址，即192.168.A.B ,子网掩码为255.255.255.0，网关为192.168.A.1 。（网关最后一位可以改变，但一旦确定就不应更改。） 注意：0=&lt;A&lt;=254，A一旦确定也不应更改，1=&lt;B&lt;=254随着不同的PC应不同，不应重复。显然，该子网划分可允许254台PC接入，完全满足超小型局域网组建的需要。子网划分完之后就是将相应的IP地址填入本地网络适配器中，可参照下图。 到此局域网以组建完毕，可以进行局域网的对战、文件交互等操作，如果想连上Internet,那就继续往下看吧！DNS应填写你所在区的DNS服务器的IP地址，例如你在湘大，可以填写首选DNS：208.67.222.222，备用DNS：202.67.220.220.填写完之后就单击确定。 在此强调，除IP地址最后一位外，其余的在不同PC配置时均不要更改，切记！ 接下来就是一些必要软件的安装，既然是通过电信上网，那就要装星空极速。然后在填入电信给你的上网账号就可以上网了，当然此时还只有你一个人能上网。其实有条件的同学可以包电信的“我的一家”这种上网业务，它允许多台PC共用一个账号上网。湖南电信这边上网是绑定MAC地址的，理应只允许一个账号让一台PC机上网，其实这是很不合理的。废话少说，要想多台PC共享上网，可以让交换机拨号，当然你买的交换机要支持拨号这种功能，具体操作可以上网BAIDU一下。也可以选择共享上网软件，在此我推荐湘大学长自己做的一款软件，拼卡啦，这是我用过的最好用的共享上网软件，简单，方便，我也感到蛮自豪的。在湘大上网用这款软件完全没问题，不过在其他地方上不上的了我就不知道了。关于这款软件的使用方法可以参照http://www.xiaorsz.com/lan-internet-sharing-software-pinkala-download/ 。在此说明一下，一台PC通过星空极速拨号上网后，然后在通过拼卡啦创建共享，其余的PC通过拼卡啦加入共享即可都上网了。网络上还有很多其他的共享上网软件，比如CCPROXY，不过需要一台PC充当服务器，像拼卡啦这样实现服务器切换这么方便的，我还没发现。好啦，现在我们已经可以多机共享上网啦！ 如果你是包年的用户，或者不计流量的那种，建议使用交换机、路由器、猫自动拨号上网，很方便，插上网线就能上！如果有流量限制，且共享上网的PC较多，（比如我原来寝室的6台PC共用一个账号上网的那些耻人们，呵呵，开个玩笑！）建议用共享软件上网，虽然每次都要拨号，不过可以省流量！如果你住在南苑，600块钱一年的那种难寝室，那就只用通过ADSL上网了，有得上就行！那你得乖乖的买个猫，二手的也行。把电话线连接分线器，分线器一端连接座机，一段连接猫。然后猫在连接交换机的普通以太网口，有的交换接有个WAN接口，不要连那个。然后PC在连接到交换机即可，其他配制方法同上。因为是共享上网，电信本着能赚就赚的原则肯定是不允许的。你会发现优势网页打不开但是QQ却登的上，这是因为电信查封了你们的80（HTTP服务使用的）端口，这是一个知名端口，而QQ是用随机端口，它就没办法了。此时，让那台拨号的PC端口重连一下就又可以打开网页了，因为这是换了个公网IP。好啦，写到这里也就结束了。我省略了很多细节，大家都可以Baidu的到，希望对想共享上网的同学有所帮助。 如果有其他的方案也可以留言，互相交流！]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>network engineering</tag>
      </tags>
  </entry>
</search>